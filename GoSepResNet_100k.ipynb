{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVUS8P7qaPed",
        "outputId": "b848eb58-f304-461b-bfbc-a3bdec34f566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-10 21:12:25--  https://www.lamsade.dauphine.fr/~cazenave/project2026.zip\n",
            "Resolving www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)... 193.48.71.250\n",
            "Connecting to www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)|193.48.71.250|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138578548 (132M) [application/zip]\n",
            "Saving to: â€˜project2026.zipâ€™\n",
            "\n",
            "project2026.zip     100%[===================>] 132.16M  21.2MB/s    in 7.0s    \n",
            "\n",
            "2025-11-10 21:12:33 (18.9 MB/s) - â€˜project2026.zipâ€™ saved [138578548/138578548]\n",
            "\n",
            "Archive:  project2026.zip\n",
            "  inflating: games.data              \n",
            "  inflating: golois.cpython-312-x86_64-linux-gnu.so  \n",
            "total 665408\n",
            "-rw-r--r-- 1 root root 542497580 Oct  7  2022 games.data\n",
            "-rwxr-xr-x 1 root root    284672 Oct  1 15:09 golois.cpython-312-x86_64-linux-gnu.so\n",
            "-rw-r--r-- 1 root root 138578548 Oct  1 20:02 project2026.zip\n",
            "drwxr-xr-x 1 root root      4096 Nov  7 14:30 sample_data\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.lamsade.dauphine.fr/~cazenave/project2026.zip\n",
        "!unzip project2026.zip\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCBpX74JaPee"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fDLUTeCDaPee"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# ğŸ“¦ IMPORTS GÃ‰NÃ‰RAUX\n",
        "# ================================================================\n",
        "import os, gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from google.colab import files  # pour le tÃ©lÃ©chargement auto\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import golois  # Librairie C++ fournie (jeu de donnÃ©es Go)\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow import keras\n",
        "import gc\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "# Utilitaires internes (si tu veux factoriser ton code)\n",
        "# from utils.model_blocks import dw_conv_block, se_block, attention_residual_block\n",
        "# from utils.training_utils import moving_average, save_plots\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# âœ… GO-SEPARABLE RESNET â€” ~100k params (â‰ˆ99 932) â€” golois compatible\n",
        "# ================================================================\n",
        "import os, gc, shutil, numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from datetime import datetime\n",
        "import golois\n",
        "\n",
        "# -----------------------------\n",
        "# GPU safety (Colab)\n",
        "# -----------------------------\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        print(\"âœ… GPU activÃ© (memory growth).\")\n",
        "    except Exception as e:\n",
        "        print(\"âš ï¸ GPU memory growth non appliquÃ©:\", e)\n",
        "else:\n",
        "    print(\"âš ï¸ Aucun GPU dÃ©tectÃ© â€” CPU utilisÃ©.\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ”§ PARAMÃˆTRES\n",
        "# ================================================================\n",
        "trainer = \"AdamH\"\n",
        "base_title = \"GoSepResNet_100k\"\n",
        "date_str = datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "planes = 31\n",
        "moves  = 361\n",
        "N      = 10000\n",
        "epochs = 60\n",
        "batch  = 128\n",
        "\n",
        "# ğŸ¯ Calibrage prÃ©cis pour ~100k\n",
        "filters            = 110          # nb de canaux dans le backbone\n",
        "num_blocks         = 3            # nb de blocs rÃ©siduels\n",
        "se_reduction       = 10           # squeeze ratio\n",
        "value_dense_units  = 64\n",
        "\n",
        "l2_reg        = 1e-4\n",
        "learning_rate = 1e-4\n",
        "label_smooth  = 0.10\n",
        "\n",
        "# ------------------------------------------------\n",
        "# ğŸ“ Dossier de sortie\n",
        "# ------------------------------------------------\n",
        "model_name  = f\"{date_str}_{trainer}_{base_title}_ep{epochs}_bs{batch}_lr{learning_rate}\"\n",
        "output_root = \"output\"\n",
        "output_dir  = os.path.join(output_root, model_name)\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"ğŸ§¾ ModÃ¨le : {model_name}\")\n",
        "print(f\"ğŸ“‚ Dossier : {output_dir}\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ“Š BUFFERS (mock init) â€” golois les remplit ensuite\n",
        "# ================================================================\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy     = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value      = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end        = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "groups     = np.zeros((N, 19, 19, 1), dtype='float32')\n",
        "\n",
        "print(\"ğŸ” Test golois.getValidation()â€¦\")\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "print(\"âœ… golois prÃªt.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ§± BLOCS\n",
        "# ================================================================\n",
        "BN = lambda: layers.BatchNormalization(momentum=0.95, epsilon=1e-5)\n",
        "\n",
        "def sep_conv_block(x, filters, l2_reg, stride=1):\n",
        "    \"\"\"SeparableConv2D (depthwise + pointwise) + BN + ReLU (sans bias).\"\"\"\n",
        "    x = layers.SeparableConv2D(\n",
        "        filters,\n",
        "        kernel_size=3,\n",
        "        strides=stride,\n",
        "        padding='same',\n",
        "        activation=None,\n",
        "        depthwise_regularizer=regularizers.l2(l2_reg),\n",
        "        pointwise_regularizer=regularizers.l2(l2_reg),\n",
        "        use_bias=False\n",
        "    )(x)\n",
        "    x = BN()(x)   # BN ajoute 4F params (2 trainables + 2 non-trainables)\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def se_block(x, reduction=10):\n",
        "    \"\"\"Squeeze-Excite (lÃ©ger)\"\"\"\n",
        "    c = int(x.shape[-1])\n",
        "    s = layers.GlobalAveragePooling2D()(x)\n",
        "    s = layers.Dense(max(c // reduction, 1), activation='relu')(s)\n",
        "    s = layers.Dense(c, activation='sigmoid')(s)\n",
        "    s = layers.Reshape((1, 1, c))(s)\n",
        "    return layers.Multiply()([x, s])\n",
        "\n",
        "def residual_separable_block(x, filters, l2_reg, reduction):\n",
        "    \"\"\"Bloc rÃ©siduel : 2x SeparableConv2D + SE + skip.\"\"\"\n",
        "    shortcut = x\n",
        "    x = sep_conv_block(x, filters, l2_reg)\n",
        "    x = sep_conv_block(x, filters, l2_reg)\n",
        "    x = se_block(x, reduction=reduction)\n",
        "    x = layers.Add()([shortcut, x])\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ§  MODÃˆLE\n",
        "# ================================================================\n",
        "inp = keras.Input(shape=(19, 19, planes), name='board')\n",
        "\n",
        "# Stem 1x1 (sans bias) + BN + ReLU\n",
        "x = layers.Conv2D(\n",
        "    filters, 1, padding='same', activation=None,\n",
        "    kernel_regularizer=regularizers.l2(l2_reg),\n",
        "    use_bias=False\n",
        ")(inp)\n",
        "x = BN()(x)\n",
        "x = layers.ReLU()(x)\n",
        "\n",
        "# 3 blocs rÃ©siduels sÃ©parables + SE\n",
        "for i in range(num_blocks):\n",
        "    x = residual_separable_block(x, filters, l2_reg, se_reduction)\n",
        "    if i % 2 == 1:\n",
        "        x = layers.Dropout(0.10)(x)\n",
        "\n",
        "# --- Policy head (âš ï¸ SANS Dense(361) !) ---\n",
        "# 1x1 conv (sans bias) â†’ 361 logits aprÃ¨s flatten â†’ softmax\n",
        "p = layers.Conv2D(1, 1, padding='same', activation=None,\n",
        "                  kernel_regularizer=regularizers.l2(l2_reg),\n",
        "                  use_bias=False)(x)         # params = filters (110)\n",
        "p = layers.Flatten()(p)                      # 19*19 = 361\n",
        "policy_head = layers.Activation('softmax', name='policy')(p)\n",
        "\n",
        "# --- Value head (compact) ---\n",
        "v = layers.GlobalAveragePooling2D()(x)       # vecteur de taille 110\n",
        "v = layers.Dense(value_dense_units, activation='relu',\n",
        "                 kernel_regularizer=regularizers.l2(l2_reg))(v)  # 110*64 + 64 = 7104\n",
        "v = layers.Dropout(0.15)(v)\n",
        "value_head = layers.Dense(1, activation='tanh', name='value')(v)  # 64*1 + 1 = 65\n",
        "\n",
        "model = keras.Model(inputs=inp, outputs=[policy_head, value_head])\n",
        "model.summary()\n",
        "\n",
        "# ------------------------------------------------\n",
        "# ğŸ”¢ VÃ©rification stricte du budget de params\n",
        "# Estimation thÃ©orique (incluant BN trainables + non-trainables):\n",
        "# - Stem: Conv1x1 (31*110=3410) + BN (4*110=440)  -> 3850\n",
        "# - Par bloc (x3):\n",
        "#     2Ã—(SepConv: 110*110 + 9*110 = 12100 + 990; BN: 4*110 = 440) = 2Ã—(130? + 440) = 2Ã—(130? wait) = 2Ã—(13090+440)=2Ã—13530=27060\n",
        "#     SE: (110â†’11â†’110) = 1221 + 1320 = 2541\n",
        "#     Total bloc â‰ˆ 27060 + 2541 = 29601\n",
        "#   3 blocs â‰ˆ 88803\n",
        "# - Policy 1x1 (sans bias): 110\n",
        "# - Value: 110â†’64 (7104) + 64â†’1 (65) = 7169\n",
        "# TOTAL â‰ˆ 3850 + 88803 + 110 + 7169 = 99 932\n",
        "# ------------------------------------------------\n",
        "total_params = model.count_params()\n",
        "print(f\"ğŸ”¢ Total params (Keras): {total_params}\")\n",
        "assert 95_000 <= total_params <= 105_000, f\"âŒ Hors cible: {total_params} (attendu â‰ˆ100k)\"\n",
        "\n",
        "# ================================================================\n",
        "# âš™ï¸ COMPILE + CALLBACKS\n",
        "# ================================================================\n",
        "optimizer    = keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
        "policy_loss  = keras.losses.CategoricalCrossentropy(label_smoothing=label_smooth)\n",
        "value_loss   = keras.losses.MeanSquaredError()\n",
        "metrics_dict = {'policy': ['categorical_accuracy'], 'value': ['mae']}\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss={'policy': policy_loss, 'value': value_loss},\n",
        "              loss_weights={'policy': 1.0, 'value': 1.0},\n",
        "              metrics=metrics_dict)\n",
        "\n",
        "ckpt_path = os.path.join(output_dir, f\"{model_name}_best.keras\")\n",
        "csv_path  = os.path.join(output_dir, f\"{model_name}_training_log.csv\")\n",
        "\n",
        "callbacks_common = [\n",
        "    keras.callbacks.ModelCheckpoint(filepath=ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
        "    keras.callbacks.CSVLogger(csv_path, append=True),\n",
        "]\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ‹ï¸â€â™‚ï¸ ENTRAÃNEMENT (val tous les 5 epochs)\n",
        "# ================================================================\n",
        "history_all = {\n",
        "    \"loss\": [], \"policy_categorical_accuracy\": [], \"value_mae\": [],\n",
        "    \"val_epochs\": [], \"val_loss\": [], \"val_policy_categorical_accuracy\": [], \"val_value_mae\": []\n",
        "}\n",
        "\n",
        "for i in range(1, epochs + 1):\n",
        "    print(f\"\\n--- Ã‰poque {i}/{epochs} ---\")\n",
        "    golois.getBatch(input_data, policy, value, end, groups, i * N)\n",
        "\n",
        "    do_val = (i % 5 == 0) or (i == epochs)\n",
        "    val_data, callbacks = None, []\n",
        "    if do_val:\n",
        "        golois.getValidation(input_data, policy, value, end)\n",
        "        val_data = (input_data, [policy, value])\n",
        "        callbacks = callbacks_common\n",
        "\n",
        "    hist = model.fit(\n",
        "        input_data, [policy, value],\n",
        "        epochs=1, batch_size=batch, verbose=1,\n",
        "        validation_data=val_data,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    history_all[\"loss\"].append(hist.history.get(\"loss\", [None])[0])\n",
        "    history_all[\"policy_categorical_accuracy\"].append(hist.history.get(\"policy_categorical_accuracy\", [None])[0])\n",
        "    history_all[\"value_mae\"].append(hist.history.get(\"value_mae\", [None])[0])\n",
        "\n",
        "    if do_val:\n",
        "        history_all[\"val_epochs\"].append(i)\n",
        "        history_all[\"val_loss\"].append(hist.history.get(\"val_loss\", [None])[0])\n",
        "        history_all[\"val_policy_categorical_accuracy\"].append(hist.history.get(\"val_policy_categorical_accuracy\", [None])[0])\n",
        "        history_all[\"val_value_mae\"].append(hist.history.get(\"val_value_mae\", [None])[0])\n",
        "\n",
        "    if i % 5 == 0:\n",
        "        gc.collect()\n",
        "        print(\"ğŸ§¹ GC.\")\n",
        "\n",
        "final_path = os.path.join(output_dir, f\"{model_name}_final.keras\")\n",
        "model.save(final_path)\n",
        "print(f\"\\nğŸ’¾ Sauvegardes :\\n - Best: {ckpt_path}\\n - Final: {final_path}\")\n",
        "print(\"âœ… EntraÃ®nement terminÃ©.\")\n"
      ],
      "metadata": {
        "id": "CUG5_rtpxD5A",
        "outputId": "2952f74c-d985-49b4-d7eb-0b01f93cb220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GPU activÃ© (memory growth).\n",
            "ğŸ§¾ ModÃ¨le : 20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001\n",
            "ğŸ“‚ Dossier : output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001\n",
            "ğŸ” Test golois.getValidation()â€¦\n",
            "âœ… golois prÃªt.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ board (\u001b[38;5;33mInputLayer\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m31\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_40 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚      \u001b[38;5;34m3,410\u001b[0m â”‚ board[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ conv2d_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_52 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_53 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_81 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        â”‚      \u001b[38;5;34m1,221\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_82 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ dense_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_46          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m110\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mReshape\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_26         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ reshape_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_41 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ multiply_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_54 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_55 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_83 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        â”‚      \u001b[38;5;34m1,221\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_84 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ dense_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_47          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m110\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mReshape\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_27         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ reshape_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_42 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ multiply_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_31          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_56 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ dropout_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_57 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_85 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        â”‚      \u001b[38;5;34m1,221\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_86 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ dense_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_48          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m110\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mReshape\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_28         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ reshape_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_43 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ multiply_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_41 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m1\u001b[0m) â”‚        \u001b[38;5;34m110\u001b[0m â”‚ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_87 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m7,104\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_12          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m361\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mFlatten\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_32          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ policy (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m361\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ value (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m65\u001b[0m â”‚ dropout_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ board (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,410</span> â”‚ board[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ conv2d_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_52 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_53 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,221</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ dense_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_46          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_26         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ reshape_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ multiply_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_54 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_55 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,221</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ dense_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_47          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_27         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ reshape_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ multiply_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_31          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_56 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ dropout_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_57 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,221</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ dense_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_48          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_28         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ reshape_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ multiply_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> â”‚ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_12          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">361</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_32          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ policy (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">361</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ value (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚ dropout_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,932\u001b[0m (390.36 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,932</span> (390.36 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,392\u001b[0m (384.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,392</span> (384.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,540\u001b[0m (6.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,540</span> (6.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¢ Total params (Keras): 99932\n",
            "\n",
            "--- Ã‰poque 1/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 277ms/step - loss: 6.8163 - policy_categorical_accuracy: 0.0066 - policy_loss: 5.8116 - value_loss: 0.9240 - value_mae: 0.8007\n",
            "\n",
            "--- Ã‰poque 2/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 5.5876 - policy_categorical_accuracy: 0.0247 - policy_loss: 5.3321 - value_loss: 0.1751 - value_mae: 0.3407\n",
            "\n",
            "--- Ã‰poque 3/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 5.3237 - policy_categorical_accuracy: 0.0444 - policy_loss: 5.0902 - value_loss: 0.1534 - value_mae: 0.3229\n",
            "\n",
            "--- Ã‰poque 4/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 5.0296 - policy_categorical_accuracy: 0.0855 - policy_loss: 4.8063 - value_loss: 0.1433 - value_mae: 0.3158\n",
            "\n",
            "--- Ã‰poque 5/60 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.8702 - policy_categorical_accuracy: 0.1076 - policy_loss: 4.6578 - value_loss: 0.1326 - value_mae: 0.3027\n",
            "Epoch 1: val_loss improved from inf to 4.60657, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 172ms/step - loss: 4.8691 - policy_categorical_accuracy: 0.1078 - policy_loss: 4.6567 - value_loss: 0.1326 - value_mae: 0.3027 - val_loss: 4.6066 - val_policy_categorical_accuracy: 0.1480 - val_policy_loss: 4.4037 - val_value_loss: 0.1187 - val_value_mae: 0.2854\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 6/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.7320 - policy_categorical_accuracy: 0.1283 - policy_loss: 4.5253 - value_loss: 0.1271 - value_mae: 0.2960\n",
            "\n",
            "--- Ã‰poque 7/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.6687 - policy_categorical_accuracy: 0.1387 - policy_loss: 4.4605 - value_loss: 0.1290 - value_mae: 0.3008\n",
            "\n",
            "--- Ã‰poque 8/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 4.6130 - policy_categorical_accuracy: 0.1546 - policy_loss: 4.4078 - value_loss: 0.1259 - value_mae: 0.2957\n",
            "\n",
            "--- Ã‰poque 9/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.5689 - policy_categorical_accuracy: 0.1569 - policy_loss: 4.3654 - value_loss: 0.1242 - value_mae: 0.2929\n",
            "\n",
            "--- Ã‰poque 10/60 ---\n",
            "\u001b[1m76/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.4851 - policy_categorical_accuracy: 0.1661 - policy_loss: 4.2842 - value_loss: 0.1220 - value_mae: 0.2919\n",
            "Epoch 1: val_loss improved from 4.60657 to 4.30499, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 4.4838 - policy_categorical_accuracy: 0.1666 - policy_loss: 4.2828 - value_loss: 0.1220 - value_mae: 0.2919 - val_loss: 4.3050 - val_policy_categorical_accuracy: 0.2006 - val_policy_loss: 4.1012 - val_value_loss: 0.1174 - val_value_mae: 0.2836\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 11/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.4618 - policy_categorical_accuracy: 0.1779 - policy_loss: 4.2579 - value_loss: 0.1252 - value_mae: 0.2973\n",
            "\n",
            "--- Ã‰poque 12/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.4218 - policy_categorical_accuracy: 0.1808 - policy_loss: 4.2191 - value_loss: 0.1240 - value_mae: 0.2938\n",
            "\n",
            "--- Ã‰poque 13/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 4.3532 - policy_categorical_accuracy: 0.1953 - policy_loss: 4.1545 - value_loss: 0.1202 - value_mae: 0.2875\n",
            "\n",
            "--- Ã‰poque 14/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.3363 - policy_categorical_accuracy: 0.2054 - policy_loss: 4.1396 - value_loss: 0.1182 - value_mae: 0.2861\n",
            "\n",
            "--- Ã‰poque 15/60 ---\n",
            "\u001b[1m76/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.2310 - policy_categorical_accuracy: 0.2221 - policy_loss: 4.0297 - value_loss: 0.1230 - value_mae: 0.2938\n",
            "Epoch 1: val_loss improved from 4.30499 to 4.13452, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 4.2325 - policy_categorical_accuracy: 0.2218 - policy_loss: 4.0314 - value_loss: 0.1229 - value_mae: 0.2937 - val_loss: 4.1345 - val_policy_categorical_accuracy: 0.2417 - val_policy_loss: 3.9317 - val_value_loss: 0.1168 - val_value_mae: 0.2828\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 16/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 4.2985 - policy_categorical_accuracy: 0.2067 - policy_loss: 4.0996 - value_loss: 0.1210 - value_mae: 0.2896\n",
            "\n",
            "--- Ã‰poque 17/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 4.2931 - policy_categorical_accuracy: 0.1987 - policy_loss: 4.0952 - value_loss: 0.1198 - value_mae: 0.2876\n",
            "\n",
            "--- Ã‰poque 18/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 4.2652 - policy_categorical_accuracy: 0.2149 - policy_loss: 4.0651 - value_loss: 0.1221 - value_mae: 0.2929\n",
            "\n",
            "--- Ã‰poque 19/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 4.2195 - policy_categorical_accuracy: 0.2172 - policy_loss: 4.0244 - value_loss: 0.1174 - value_mae: 0.2836\n",
            "\n",
            "--- Ã‰poque 20/60 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.1183 - policy_categorical_accuracy: 0.2451 - policy_loss: 3.9236 - value_loss: 0.1170 - value_mae: 0.2862\n",
            "Epoch 1: val_loss improved from 4.13452 to 4.01496, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 4.1186 - policy_categorical_accuracy: 0.2451 - policy_loss: 3.9239 - value_loss: 0.1171 - value_mae: 0.2863 - val_loss: 4.0150 - val_policy_categorical_accuracy: 0.2647 - val_policy_loss: 3.8133 - val_value_loss: 0.1165 - val_value_mae: 0.2828\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 21/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 4.1636 - policy_categorical_accuracy: 0.2257 - policy_loss: 3.9663 - value_loss: 0.1198 - value_mae: 0.2883\n",
            "\n",
            "--- Ã‰poque 22/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.1638 - policy_categorical_accuracy: 0.2325 - policy_loss: 3.9671 - value_loss: 0.1194 - value_mae: 0.2882\n",
            "\n",
            "--- Ã‰poque 23/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 4.1563 - policy_categorical_accuracy: 0.2315 - policy_loss: 3.9599 - value_loss: 0.1189 - value_mae: 0.2864\n",
            "\n",
            "--- Ã‰poque 24/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 4.1167 - policy_categorical_accuracy: 0.2432 - policy_loss: 3.9213 - value_loss: 0.1181 - value_mae: 0.2874\n",
            "\n",
            "--- Ã‰poque 25/60 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.0318 - policy_categorical_accuracy: 0.2581 - policy_loss: 3.8354 - value_loss: 0.1193 - value_mae: 0.2871\n",
            "Epoch 1: val_loss improved from 4.01496 to 3.92017, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 4.0321 - policy_categorical_accuracy: 0.2581 - policy_loss: 3.8356 - value_loss: 0.1193 - value_mae: 0.2871 - val_loss: 3.9202 - val_policy_categorical_accuracy: 0.2855 - val_policy_loss: 3.7204 - val_value_loss: 0.1153 - val_value_mae: 0.2811\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 26/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 4.0986 - policy_categorical_accuracy: 0.2471 - policy_loss: 3.9059 - value_loss: 0.1159 - value_mae: 0.2832\n",
            "\n",
            "--- Ã‰poque 27/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 4.0332 - policy_categorical_accuracy: 0.2562 - policy_loss: 3.8349 - value_loss: 0.1213 - value_mae: 0.2910\n",
            "\n",
            "--- Ã‰poque 28/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.0301 - policy_categorical_accuracy: 0.2608 - policy_loss: 3.8340 - value_loss: 0.1192 - value_mae: 0.2859\n",
            "\n",
            "--- Ã‰poque 29/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.0399 - policy_categorical_accuracy: 0.2589 - policy_loss: 3.8472 - value_loss: 0.1159 - value_mae: 0.2826\n",
            "\n",
            "--- Ã‰poque 30/60 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.9593 - policy_categorical_accuracy: 0.2758 - policy_loss: 3.7663 - value_loss: 0.1164 - value_mae: 0.2844\n",
            "Epoch 1: val_loss improved from 3.92017 to 3.84261, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 3.9587 - policy_categorical_accuracy: 0.2759 - policy_loss: 3.7658 - value_loss: 0.1164 - value_mae: 0.2844 - val_loss: 3.8426 - val_policy_categorical_accuracy: 0.2999 - val_policy_loss: 3.6445 - val_value_loss: 0.1146 - val_value_mae: 0.2806\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 31/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 4.0091 - policy_categorical_accuracy: 0.2659 - policy_loss: 3.8181 - value_loss: 0.1145 - value_mae: 0.2799\n",
            "\n",
            "--- Ã‰poque 32/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 4.0120 - policy_categorical_accuracy: 0.2622 - policy_loss: 3.8169 - value_loss: 0.1190 - value_mae: 0.2869\n",
            "\n",
            "--- Ã‰poque 33/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 3.9607 - policy_categorical_accuracy: 0.2713 - policy_loss: 3.7667 - value_loss: 0.1176 - value_mae: 0.2844\n",
            "\n",
            "--- Ã‰poque 34/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.9735 - policy_categorical_accuracy: 0.2614 - policy_loss: 3.7817 - value_loss: 0.1154 - value_mae: 0.2826\n",
            "\n",
            "--- Ã‰poque 35/60 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.8909 - policy_categorical_accuracy: 0.2919 - policy_loss: 3.6953 - value_loss: 0.1196 - value_mae: 0.2891\n",
            "Epoch 1: val_loss improved from 3.84261 to 3.78283, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 3.8906 - policy_categorical_accuracy: 0.2919 - policy_loss: 3.6951 - value_loss: 0.1195 - value_mae: 0.2890 - val_loss: 3.7828 - val_policy_categorical_accuracy: 0.3131 - val_policy_loss: 3.5868 - val_value_loss: 0.1139 - val_value_mae: 0.2799\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 36/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.9375 - policy_categorical_accuracy: 0.2726 - policy_loss: 3.7458 - value_loss: 0.1157 - value_mae: 0.2833\n",
            "\n",
            "--- Ã‰poque 37/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 3.9513 - policy_categorical_accuracy: 0.2745 - policy_loss: 3.7579 - value_loss: 0.1176 - value_mae: 0.2855\n",
            "\n",
            "--- Ã‰poque 38/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.9792 - policy_categorical_accuracy: 0.2643 - policy_loss: 3.7877 - value_loss: 0.1156 - value_mae: 0.2830\n",
            "\n",
            "--- Ã‰poque 39/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 3.9694 - policy_categorical_accuracy: 0.2699 - policy_loss: 3.7776 - value_loss: 0.1161 - value_mae: 0.2828\n",
            "\n",
            "--- Ã‰poque 40/60 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.8252 - policy_categorical_accuracy: 0.3036 - policy_loss: 3.6334 - value_loss: 0.1161 - value_mae: 0.2840\n",
            "Epoch 1: val_loss improved from 3.78283 to 3.73152, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 3.8254 - policy_categorical_accuracy: 0.3034 - policy_loss: 3.6336 - value_loss: 0.1161 - value_mae: 0.2840 - val_loss: 3.7315 - val_policy_categorical_accuracy: 0.3208 - val_policy_loss: 3.5364 - val_value_loss: 0.1133 - val_value_mae: 0.2785\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 41/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.9078 - policy_categorical_accuracy: 0.2769 - policy_loss: 3.7164 - value_loss: 0.1159 - value_mae: 0.2813\n",
            "\n",
            "--- Ã‰poque 42/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 3.9059 - policy_categorical_accuracy: 0.2807 - policy_loss: 3.7147 - value_loss: 0.1158 - value_mae: 0.2846\n",
            "\n",
            "--- Ã‰poque 43/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.8381 - policy_categorical_accuracy: 0.2936 - policy_loss: 3.6490 - value_loss: 0.1139 - value_mae: 0.2804\n",
            "\n",
            "--- Ã‰poque 44/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.8465 - policy_categorical_accuracy: 0.2836 - policy_loss: 3.6568 - value_loss: 0.1144 - value_mae: 0.2805\n",
            "\n",
            "--- Ã‰poque 45/60 ---\n",
            "\u001b[1m76/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.7720 - policy_categorical_accuracy: 0.3138 - policy_loss: 3.5814 - value_loss: 0.1155 - value_mae: 0.2835\n",
            "Epoch 1: val_loss improved from 3.73152 to 3.68418, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 3.7724 - policy_categorical_accuracy: 0.3136 - policy_loss: 3.5817 - value_loss: 0.1155 - value_mae: 0.2835 - val_loss: 3.6842 - val_policy_categorical_accuracy: 0.3288 - val_policy_loss: 3.4909 - val_value_loss: 0.1122 - val_value_mae: 0.2774\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 46/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.8973 - policy_categorical_accuracy: 0.2792 - policy_loss: 3.7059 - value_loss: 0.1163 - value_mae: 0.2833\n",
            "\n",
            "--- Ã‰poque 47/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 3.8191 - policy_categorical_accuracy: 0.2984 - policy_loss: 3.6267 - value_loss: 0.1174 - value_mae: 0.2855\n",
            "\n",
            "--- Ã‰poque 48/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.8309 - policy_categorical_accuracy: 0.2937 - policy_loss: 3.6404 - value_loss: 0.1155 - value_mae: 0.2820\n",
            "\n",
            "--- Ã‰poque 49/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.8071 - policy_categorical_accuracy: 0.3012 - policy_loss: 3.6178 - value_loss: 0.1146 - value_mae: 0.2813\n",
            "\n",
            "--- Ã‰poque 50/60 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.7547 - policy_categorical_accuracy: 0.3179 - policy_loss: 3.5647 - value_loss: 0.1154 - value_mae: 0.2830\n",
            "Epoch 1: val_loss improved from 3.68418 to 3.64921, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 3.7544 - policy_categorical_accuracy: 0.3180 - policy_loss: 3.5644 - value_loss: 0.1154 - value_mae: 0.2830 - val_loss: 3.6492 - val_policy_categorical_accuracy: 0.3337 - val_policy_loss: 3.4570 - val_value_loss: 0.1114 - val_value_mae: 0.2763\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 51/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 3.8255 - policy_categorical_accuracy: 0.2913 - policy_loss: 3.6385 - value_loss: 0.1124 - value_mae: 0.2781\n",
            "\n",
            "--- Ã‰poque 52/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.8172 - policy_categorical_accuracy: 0.2902 - policy_loss: 3.6320 - value_loss: 0.1107 - value_mae: 0.2754\n",
            "\n",
            "--- Ã‰poque 53/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 3.8572 - policy_categorical_accuracy: 0.2782 - policy_loss: 3.6707 - value_loss: 0.1119 - value_mae: 0.2767\n",
            "\n",
            "--- Ã‰poque 54/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 3.8012 - policy_categorical_accuracy: 0.2858 - policy_loss: 3.6151 - value_loss: 0.1117 - value_mae: 0.2764\n",
            "\n",
            "--- Ã‰poque 55/60 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.6931 - policy_categorical_accuracy: 0.3331 - policy_loss: 3.5050 - value_loss: 0.1139 - value_mae: 0.2809\n",
            "Epoch 1: val_loss improved from 3.64921 to 3.61510, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 3.6934 - policy_categorical_accuracy: 0.3329 - policy_loss: 3.5054 - value_loss: 0.1139 - value_mae: 0.2809 - val_loss: 3.6151 - val_policy_categorical_accuracy: 0.3380 - val_policy_loss: 3.4251 - val_value_loss: 0.1101 - val_value_mae: 0.2743\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 56/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 3.8012 - policy_categorical_accuracy: 0.3010 - policy_loss: 3.6141 - value_loss: 0.1133 - value_mae: 0.2802\n",
            "\n",
            "--- Ã‰poque 57/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 3.7779 - policy_categorical_accuracy: 0.2986 - policy_loss: 3.5889 - value_loss: 0.1149 - value_mae: 0.2824\n",
            "\n",
            "--- Ã‰poque 58/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 3.7775 - policy_categorical_accuracy: 0.2952 - policy_loss: 3.5933 - value_loss: 0.1101 - value_mae: 0.2747\n",
            "\n",
            "--- Ã‰poque 59/60 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 3.7494 - policy_categorical_accuracy: 0.3165 - policy_loss: 3.5630 - value_loss: 0.1126 - value_mae: 0.2785\n",
            "\n",
            "--- Ã‰poque 60/60 ---\n",
            "\u001b[1m76/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.6875 - policy_categorical_accuracy: 0.3222 - policy_loss: 3.5017 - value_loss: 0.1120 - value_mae: 0.2779\n",
            "Epoch 1: val_loss improved from 3.61510 to 3.58742, saving model to output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 3.6871 - policy_categorical_accuracy: 0.3223 - policy_loss: 3.5012 - value_loss: 0.1120 - value_mae: 0.2779 - val_loss: 3.5874 - val_policy_categorical_accuracy: 0.3432 - val_policy_loss: 3.3985 - val_value_loss: 0.1091 - val_value_mae: 0.2728\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "ğŸ’¾ Sauvegardes :\n",
            " - Best: output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            " - Final: output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_final.keras\n",
            "âœ… EntraÃ®nement terminÃ©.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3hvbz6raPeg"
      },
      "source": [
        "# Sauvegarde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "UVmBNNsraPeg",
        "outputId": "c6aeaf1f-206e-4c83-ca8e-46231d54449d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ModÃ¨les sauvegardÃ©s :\n",
            " - output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001.h5\n",
            " - output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001.keras\n",
            "ğŸ“˜ Historique sauvegardÃ© : output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001/history.json\n",
            "\n",
            "âœ… Fichiers et graphiques enregistrÃ©s dans : output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001\n",
            "ğŸ“¦ Dossier compressÃ© : output/20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_166a404b-82e6-4640-82a1-b48431db964f\", \"20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001.zip\", 7250021)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ TÃ©lÃ©chargement du dossier complet lancÃ© avec succÃ¨s âœ…\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "#  SAUVEGARDE + VISUALISATION +  LISSAGE + ZIP DOWNLOAD\n",
        "# ================================================================\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# ğŸ”¹ CrÃ©ation du dossier (si manquant)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ğŸ”¹ Sauvegarde du modÃ¨le (.h5 & .keras)\n",
        "h5_path = os.path.join(output_dir, f\"{model_name}.h5\")\n",
        "keras_path = os.path.join(output_dir, f\"{model_name}.keras\")\n",
        "hist_json = os.path.join(output_dir, \"history.json\")\n",
        "\n",
        "model.save(h5_path)\n",
        "model.save(keras_path)\n",
        "print(f\"âœ… ModÃ¨les sauvegardÃ©s :\\n - {h5_path}\\n - {keras_path}\")\n",
        "\n",
        "# ğŸ”¹ Sauvegarde de lâ€™historique complet\n",
        "with open(hist_json, \"w\") as f:\n",
        "    json.dump(history_all, f)\n",
        "print(f\"ğŸ“˜ Historique sauvegardÃ© : {hist_json}\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ“Š VISUALISATION DES COURBES\n",
        "# ================================================================\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "\n",
        "def save_plot(fig, name):\n",
        "    fig.savefig(os.path.join(output_dir, name), dpi=300, bbox_inches='tight')\n",
        "\n",
        "epochs_range = range(1, len(history_all.get(\"loss\", [])) + 1)\n",
        "\n",
        "# --- 1ï¸âƒ£ Courbe de perte (Loss)\n",
        "if history_all.get(\"loss\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"loss\"], label='Training Loss', linewidth=2)\n",
        "    if history_all.get(\"val_loss\"):\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_loss\"], label='Validation Loss', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Loss\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Loss\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"loss_curve.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 2ï¸âƒ£ Policy Accuracy\n",
        "if history_all.get(\"policy_categorical_accuracy\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"policy_categorical_accuracy\"], label='Policy Accuracy', linewidth=2)\n",
        "    if history_all.get(\"val_policy_categorical_accuracy\"):\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_policy_categorical_accuracy\"], '--', label='Val Policy Acc', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Policy Accuracy\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"policy_accuracy.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 3ï¸âƒ£ Top-5 Accuracy\n",
        "if history_all.get(\"policy_top5\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"policy_top5\"], label='Top-5 Accuracy', linewidth=2)\n",
        "    if history_all.get(\"val_policy_top5\"):  # âœ… clÃ© optionnelle\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_policy_top5\"], '--', label='Val Top-5', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Top-5 Accuracy\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"top5_accuracy.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 4ï¸âƒ£ Value MAE\n",
        "if history_all.get(\"value_mae\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"value_mae\"], label='Value MAE', linewidth=2)\n",
        "    if history_all.get(\"val_value_mae\"):\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_value_mae\"], '--', label='Val Value MAE', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Value MAE\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"MAE\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"value_mae.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ“ˆ LISSAGE (Policy Accuracy)\n",
        "# ================================================================\n",
        "def moving_average(data, window=5):\n",
        "    data = np.array(data)\n",
        "    if len(data) < window:\n",
        "        return data\n",
        "    return np.convolve(data, np.ones(window)/window, mode='valid')\n",
        "\n",
        "if history_all.get(\"policy_categorical_accuracy\"):\n",
        "    smooth_acc = moving_average(history_all[\"policy_categorical_accuracy\"], 5)\n",
        "    epochs_smooth = np.arange(5, len(history_all[\"policy_categorical_accuracy\"]) + 1)\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(range(1, len(history_all[\"policy_categorical_accuracy\"]) + 1),\n",
        "            history_all[\"policy_categorical_accuracy\"], alpha=0.4, label='Brut', linewidth=1.5)\n",
        "    ax.plot(epochs_smooth, smooth_acc, color='red', linewidth=2.5,\n",
        "            label='Moyenne glissante (5)')\n",
        "    ax.set_title(f\"{model_name} - Policy Accuracy (LissÃ©e)\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.8)\n",
        "    save_plot(fig, \"policy_acc_smooth.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ§¾ EXPORT DU RÃ‰SUMÃ‰ DES MÃ‰TRIQUES\n",
        "# ================================================================\n",
        "summary_path = os.path.join(output_dir, \"metrics_summary.txt\")\n",
        "with open(summary_path, \"w\") as f:\n",
        "    f.write(f\"Model: {model_name}\\n\")\n",
        "    f.write(f\"Epochs: {len(history_all.get('loss', []))}\\n\\n\")\n",
        "    if history_all.get(\"loss\"):\n",
        "        f.write(f\"Final Training Loss: {history_all['loss'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"val_loss\"):\n",
        "        f.write(f\"Final Validation Loss: {history_all['val_loss'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"policy_categorical_accuracy\"):\n",
        "        f.write(f\"Final Policy Accuracy: {history_all['policy_categorical_accuracy'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"val_policy_categorical_accuracy\"):\n",
        "        f.write(f\"Final Val Policy Accuracy: {history_all['val_policy_categorical_accuracy'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"value_mae\"):\n",
        "        f.write(f\"Final Value MAE: {history_all['value_mae'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"val_value_mae\"):\n",
        "        f.write(f\"Final Val Value MAE: {history_all['val_value_mae'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"policy_top5\"):\n",
        "        f.write(f\"Final Policy Top-5: {history_all['policy_top5'][-1]:.4f}\\n\")\n",
        "\n",
        "print(f\"\\nâœ… Fichiers et graphiques enregistrÃ©s dans : {output_dir}\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ“¦ ZIP + TÃ‰LÃ‰CHARGEMENT AUTOMATIQUE\n",
        "# ================================================================\n",
        "zip_path = f\"{output_dir}.zip\"\n",
        "shutil.make_archive(output_dir, 'zip', output_dir)\n",
        "print(f\"ğŸ“¦ Dossier compressÃ© : {zip_path}\")\n",
        "\n",
        "try:\n",
        "    files.download(zip_path)\n",
        "    print(f\"ğŸ“¥ TÃ©lÃ©chargement du dossier complet lancÃ© avec succÃ¨s âœ…\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ TÃ©lÃ©chargement automatique ignorÃ© ({e})\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}