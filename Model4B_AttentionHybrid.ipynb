{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zVUS8P7qaPed",
        "outputId": "64706c57-7a2c-4f15-b475-c06053afa8a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-22 12:23:00--  https://www.lamsade.dauphine.fr/~cazenave/project2026.zip\n",
            "Resolving www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)... 193.48.71.250\n",
            "Connecting to www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)|193.48.71.250|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138578548 (132M) [application/zip]\n",
            "Saving to: â€˜project2026.zipâ€™\n",
            "\n",
            "project2026.zip     100%[===================>] 132.16M  23.0MB/s    in 6.6s    \n",
            "\n",
            "2025-11-22 12:23:08 (19.9 MB/s) - â€˜project2026.zipâ€™ saved [138578548/138578548]\n",
            "\n",
            "Archive:  project2026.zip\n",
            "  inflating: games.data              \n",
            "  inflating: golois.cpython-312-x86_64-linux-gnu.so  \n",
            "total 665408\n",
            "-rw-r--r-- 1 root root 542497580 Oct  7  2022 games.data\n",
            "-rwxr-xr-x 1 root root    284672 Oct  1 15:09 golois.cpython-312-x86_64-linux-gnu.so\n",
            "-rw-r--r-- 1 root root 138578548 Oct  1 20:02 project2026.zip\n",
            "drwxr-xr-x 1 root root      4096 Nov 20 14:30 sample_data\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.lamsade.dauphine.fr/~cazenave/project2026.zip\n",
        "!unzip project2026.zip\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCBpX74JaPee"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fDLUTeCDaPee"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# ğŸ“¦ IMPORTS GÃ‰NÃ‰RAUX\n",
        "# ================================================================\n",
        "import os, gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from google.colab import files  # pour le tÃ©lÃ©chargement auto\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import golois  # Librairie C++ fournie (jeu de donnÃ©es Go)\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow import keras\n",
        "import gc\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "# Utilitaires internes (si tu veux factoriser ton code)\n",
        "# from utils.model_blocks import dw_conv_block, se_block, attention_residual_block\n",
        "# from utils.training_utils import moving_average, save_plots\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# âœ… GO-ALPHA HYBRID ~99k PARAMS â€” 60 EPOCHS â€” GOLOIS COMPAT\n",
        "# ================================================================\n",
        "import os, gc, shutil, numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from datetime import datetime\n",
        "import golois\n",
        "\n",
        "# -----------------------------\n",
        "# Runtime / GPU safety (Colab)\n",
        "# -----------------------------\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        print(\"âœ… GPU activÃ© (memory growth).\")\n",
        "    except Exception as e:\n",
        "        print(\"âš ï¸ GPU memory growth non appliquÃ©:\", e)\n",
        "else:\n",
        "    print(\"âš ï¸ Aucun GPU dÃ©tectÃ© â€” CPU utilisÃ©.\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ”§ PARAMS\n",
        "# ================================================================\n",
        "trainer = \"AdamH\"\n",
        "base_title = \"Model4B_AttentionHybrid\"\n",
        "date_str = datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "planes = 31            # 31 plans d'entrÃ©e (Go)\n",
        "moves  = 361           # 19x19\n",
        "N      = 10000         # taille buffer (prof)\n",
        "epochs = 1000          # â† demandÃ©\n",
        "batch  = 128\n",
        "\n",
        "# ğŸ”¥ capacitÃ© du modÃ¨le (â‰ˆ99k params)\n",
        "filters            = 110\n",
        "se_reduction       = 10\n",
        "value_dense_units  = 64\n",
        "\n",
        "# RÃ©gularisation / Optim\n",
        "l2_reg        = 1e-4\n",
        "learning_rate = 1e-4\n",
        "label_smooth  = 0.05\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ“ OUTPUT DIR\n",
        "# ================================================================\n",
        "model_name  = f\"{date_str}_{trainer}_{base_title}_ep{epochs}_bs{batch}_lr{learning_rate}_l2{l2_reg}\"\n",
        "output_root = \"output\"\n",
        "output_dir  = os.path.join(output_root, model_name)\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"ğŸ§¾ ModÃ¨le : {model_name}\")\n",
        "print(f\"ğŸ“‚ Dossier de sortie : {output_dir}\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ“Š DATA BUFFERS (mock init) â€” golois remplit ensuite\n",
        "# ================================================================\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy     = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value      = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end        = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "groups     = np.zeros((N, 19, 19, 1), dtype='float32')\n",
        "\n",
        "print(\"ğŸ” Test golois.getValidation()â€¦\")\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "print(\"âœ… golois prÃªt.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ§  MODEL â€” ATTENTION HYBRID (â‰ˆ99k)\n",
        "# ================================================================\n",
        "def dw_conv_block(x, filters, l2_reg, stride=1):\n",
        "    x = layers.SeparableConv2D(\n",
        "        filters, kernel_size=3, strides=stride, padding='same', activation='relu',\n",
        "        depthwise_regularizer=regularizers.l2(l2_reg),\n",
        "        pointwise_regularizer=regularizers.l2(l2_reg),\n",
        "        use_bias=False\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def se_block(x, reduction=10):\n",
        "    c = int(x.shape[-1])\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(max(c // reduction, 1), activation='relu')(se)\n",
        "    se = layers.Dense(c, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, c))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "def attention_residual_block(x, filters, l2_reg, reduction):\n",
        "    shortcut = x\n",
        "    x = dw_conv_block(x, filters, l2_reg)\n",
        "    x = dw_conv_block(x, filters, l2_reg)\n",
        "    x = se_block(x, reduction=reduction)\n",
        "    x = layers.Add()([shortcut, x])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "inp = keras.Input(shape=(19, 19, planes), name='board')\n",
        "\n",
        "# Stem\n",
        "x = layers.Conv2D(filters, 1, activation='relu', padding='same',\n",
        "                  kernel_regularizer=regularizers.l2(l2_reg),\n",
        "                  use_bias=False)(inp)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# 3 blocs rÃ©siduels avec SE + DW conv\n",
        "for i in range(3):\n",
        "    x = attention_residual_block(x, filters, l2_reg, reduction=se_reduction)\n",
        "    if i % 2 == 1:\n",
        "        x = layers.Dropout(0.10)(x)\n",
        "\n",
        "# --- Policy Head ---\n",
        "p = layers.Conv2D(1, 1, activation='relu', padding='same',\n",
        "                  kernel_regularizer=regularizers.l2(l2_reg),\n",
        "                  use_bias=False)(x)\n",
        "p = layers.Flatten()(p)\n",
        "policy_head = layers.Activation('softmax', name='policy')(p)\n",
        "\n",
        "# --- Value Head ---\n",
        "v = layers.GlobalAveragePooling2D()(x)\n",
        "v = layers.Dense(value_dense_units, activation='relu',\n",
        "                 kernel_regularizer=regularizers.l2(l2_reg))(v)\n",
        "v = layers.Dropout(0.15)(v)\n",
        "value_head = layers.Dense(1, activation='sigmoid',\n",
        "                          name='value',\n",
        "                          kernel_regularizer=regularizers.l2(l2_reg))(v)\n",
        "\n",
        "model = keras.Model(inputs=inp, outputs=[policy_head, value_head])\n",
        "model.summary()\n",
        "\n",
        "# Sanity check: ~99k params\n",
        "total_params = model.count_params()\n",
        "print(f\"ğŸ”¢ Total params: {total_params}\")\n",
        "assert 90_000 <= total_params < 110_000, f\"âŒ Total params hors cible: {total_params} (attendu ~99k)\"\n",
        "\n",
        "# ================================================================\n",
        "# âš™ï¸ COMPILE + CALLBACKS\n",
        "# ================================================================\n",
        "optimizer    = keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
        "policy_loss  = keras.losses.CategoricalCrossentropy(label_smoothing=label_smooth)\n",
        "value_loss   = keras.losses.MeanSquaredError()\n",
        "metrics_dict = {'policy': ['categorical_accuracy'], 'value': ['mae']}\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss={'policy': policy_loss, 'value': value_loss},\n",
        "              loss_weights={'policy': 1.0, 'value': 1.0},\n",
        "              metrics=metrics_dict)\n",
        "\n",
        "ckpt_path   = os.path.join(output_dir, f\"{model_name}_best.keras\")\n",
        "csv_path    = os.path.join(output_dir, f\"{model_name}_training_log.csv\")\n",
        "\n",
        "# Ces callbacks ne seront actifs que sur les epochs avec validation (tous les 5)\n",
        "common_callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=ckpt_path, monitor='val_loss',\n",
        "        save_best_only=True, verbose=1),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.5, patience=2,\n",
        "        min_lr=1e-6, verbose=1),                     # â†“ LR si val_loss stagne\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=6,\n",
        "        restore_best_weights=True, verbose=1),\n",
        "    keras.callbacks.CSVLogger(csv_path, append=True)\n",
        "]\n",
        "\n",
        "# Pour suivre (optionnel)\n",
        "history_all = {\n",
        "    \"loss\": [], \"policy_categorical_accuracy\": [], \"policy_top5\": [],\n",
        "    \"value_mae\": [], \"val_epochs\": [],\n",
        "    \"val_loss\": [], \"val_policy_categorical_accuracy\": [], \"val_value_mae\": []\n",
        "}\n",
        "top5_metric = keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ‹ï¸â€â™‚ï¸ TRAIN LOOP (style prof) + VALIDATION/CKPT tous les 5\n",
        "# ================================================================\n",
        "for i in range(1, epochs + 1):\n",
        "    print(f\"\\n--- Ã‰poque {i}/{epochs} ---\")\n",
        "\n",
        "    # Remplissage buffer par golois\n",
        "    golois.getBatch(input_data, policy, value, end, groups, i * N)\n",
        "\n",
        "    # Val tous les 5 epochs (et derniÃ¨re)\n",
        "    do_val = (i % 5 == 0) or (i == epochs)\n",
        "    validation_data = None\n",
        "    callbacks = []\n",
        "    if do_val:\n",
        "        golois.getValidation(input_data, policy, value, end)\n",
        "        validation_data = (input_data, [policy, value])\n",
        "        callbacks = common_callbacks\n",
        "\n",
        "    # Fit 1 epoch\n",
        "    hist = model.fit(\n",
        "        input_data, [policy, value],\n",
        "        epochs=1, batch_size=batch, verbose=1,\n",
        "        validation_data=validation_data,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Log metrics\n",
        "    history_all[\"loss\"].append(hist.history.get(\"loss\", [None])[0])\n",
        "    history_all[\"policy_categorical_accuracy\"].append(\n",
        "        hist.history.get(\"policy_categorical_accuracy\", [None])[0]\n",
        "    )\n",
        "    # calc top5 manuellement (sur batch complet)\n",
        "    preds_policy = model.predict(input_data, batch_size=batch, verbose=0)[0]\n",
        "    history_all[\"policy_top5\"].append(\n",
        "        float(top5_metric(policy, preds_policy).numpy())\n",
        "    )\n",
        "    history_all[\"value_mae\"].append(hist.history.get(\"value_mae\", [None])[0])\n",
        "\n",
        "    if do_val:\n",
        "        history_all[\"val_epochs\"].append(i)\n",
        "        history_all[\"val_loss\"].append(hist.history.get(\"val_loss\", [None])[0])\n",
        "        history_all[\"val_policy_categorical_accuracy\"].append(\n",
        "            hist.history.get(\"val_policy_categorical_accuracy\", [None])[0]\n",
        "        )\n",
        "        history_all[\"val_value_mae\"].append(hist.history.get(\"val_value_mae\", [None])[0])\n",
        "\n",
        "    # GC rÃ©gulier\n",
        "    if i % 5 == 0:\n",
        "        gc.collect()\n",
        "        print(\"ğŸ§¹ GC.\")\n",
        "\n",
        "# Sauvegarde finale et rÃ©sumÃ©\n",
        "final_path = os.path.join(output_dir, f\"{model_name}_final.keras\")\n",
        "model.save(final_path)\n",
        "print(f\"\\nğŸ’¾ Sauvegardes :\\n - Best: {ckpt_path}\\n - Final: {final_path}\")\n",
        "print(\"âœ… EntraÃ®nement terminÃ©.\")\n"
      ],
      "metadata": {
        "id": "FDw9kgirhHln",
        "outputId": "ab6cb7b6-4e14-4f55-e337-9461d62e2ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GPU activÃ© (memory growth).\n",
            "ğŸ§¾ ModÃ¨le : 20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001\n",
            "ğŸ“‚ Dossier de sortie : output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001\n",
            "ğŸ” Test golois.getValidation()â€¦\n",
            "âœ… golois prÃªt.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ board (\u001b[38;5;33mInputLayer\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m31\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚      \u001b[38;5;34m3,410\u001b[0m â”‚ board[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_1  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        â”‚      \u001b[38;5;34m1,221\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (\u001b[38;5;33mReshape\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m110\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply (\u001b[38;5;33mMultiply\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add (\u001b[38;5;33mAdd\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_2  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_3  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        â”‚      \u001b[38;5;34m1,221\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m110\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_1          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_4  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_5  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚     \u001b[38;5;34m13,090\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚        \u001b[38;5;34m440\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        â”‚      \u001b[38;5;34m1,221\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m110\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_2          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_2 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_2        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m110\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m1\u001b[0m) â”‚        \u001b[38;5;34m110\u001b[0m â”‚ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m7,104\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m361\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ policy (\u001b[38;5;33mActivation\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m361\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ value (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m65\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ board (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,410</span> â”‚ board[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_1  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,221</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_2  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_3  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,221</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_1          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_4  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ separable_conv2d_5  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,090</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span> â”‚ separable_conv2dâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,221</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ multiply_2          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_2        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> â”‚ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,104</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">361</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ policy (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">361</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ value (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,932\u001b[0m (390.36 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,932</span> (390.36 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,392\u001b[0m (384.34 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,392</span> (384.34 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,540\u001b[0m (6.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,540</span> (6.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¢ Total params: 99932\n",
            "\n",
            "--- Ã‰poque 1/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 188ms/step - loss: 6.1864 - policy_categorical_accuracy: 0.0048 - policy_loss: 5.9765 - value_loss: 0.1294 - value_mae: 0.3014\n",
            "\n",
            "--- Ã‰poque 2/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 5.6938 - policy_categorical_accuracy: 0.0261 - policy_loss: 5.4928 - value_loss: 0.1209 - value_mae: 0.2871\n",
            "\n",
            "--- Ã‰poque 3/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 5.3001 - policy_categorical_accuracy: 0.0557 - policy_loss: 5.0952 - value_loss: 0.1249 - value_mae: 0.2947\n",
            "\n",
            "--- Ã‰poque 4/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4.9470 - policy_categorical_accuracy: 0.0981 - policy_loss: 4.7458 - value_loss: 0.1215 - value_mae: 0.2912\n",
            "\n",
            "--- Ã‰poque 5/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.7888 - policy_categorical_accuracy: 0.1172 - policy_loss: 4.5888 - value_loss: 0.1205 - value_mae: 0.2898\n",
            "Epoch 1: val_loss improved from inf to 5.89528, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 183ms/step - loss: 4.7869 - policy_categorical_accuracy: 0.1174 - policy_loss: 4.5869 - value_loss: 0.1205 - value_mae: 0.2898 - val_loss: 5.8953 - val_policy_categorical_accuracy: 0.0585 - val_policy_loss: 5.6956 - val_value_loss: 0.1201 - val_value_mae: 0.2905 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 6/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 4.6506 - policy_categorical_accuracy: 0.1365 - policy_loss: 4.4542 - value_loss: 0.1172 - value_mae: 0.2840\n",
            "\n",
            "--- Ã‰poque 7/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4.5873 - policy_categorical_accuracy: 0.1439 - policy_loss: 4.3906 - value_loss: 0.1177 - value_mae: 0.2844\n",
            "\n",
            "--- Ã‰poque 8/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 4.5274 - policy_categorical_accuracy: 0.1456 - policy_loss: 4.3289 - value_loss: 0.1195 - value_mae: 0.2866\n",
            "\n",
            "--- Ã‰poque 9/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 4.4431 - policy_categorical_accuracy: 0.1628 - policy_loss: 4.2482 - value_loss: 0.1163 - value_mae: 0.2830\n",
            "\n",
            "--- Ã‰poque 10/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.3713 - policy_categorical_accuracy: 0.1697 - policy_loss: 4.1737 - value_loss: 0.1189 - value_mae: 0.2877\n",
            "Epoch 1: val_loss improved from 5.89528 to 4.25053, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 4.3699 - policy_categorical_accuracy: 0.1699 - policy_loss: 4.1724 - value_loss: 0.1189 - value_mae: 0.2876 - val_loss: 4.2505 - val_policy_categorical_accuracy: 0.1972 - val_policy_loss: 4.0492 - val_value_loss: 0.1172 - val_value_mae: 0.2843 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 11/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.3370 - policy_categorical_accuracy: 0.1764 - policy_loss: 4.1385 - value_loss: 0.1199 - value_mae: 0.2894\n",
            "\n",
            "--- Ã‰poque 12/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.3232 - policy_categorical_accuracy: 0.1797 - policy_loss: 4.1287 - value_loss: 0.1160 - value_mae: 0.2832\n",
            "\n",
            "--- Ã‰poque 13/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4.2359 - policy_categorical_accuracy: 0.1903 - policy_loss: 4.0406 - value_loss: 0.1171 - value_mae: 0.2840\n",
            "\n",
            "--- Ã‰poque 14/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.2315 - policy_categorical_accuracy: 0.1910 - policy_loss: 4.0373 - value_loss: 0.1158 - value_mae: 0.2824\n",
            "\n",
            "--- Ã‰poque 15/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.1322 - policy_categorical_accuracy: 0.2051 - policy_loss: 3.9362 - value_loss: 0.1180 - value_mae: 0.2866\n",
            "Epoch 1: val_loss improved from 4.25053 to 3.97134, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 4.1312 - policy_categorical_accuracy: 0.2053 - policy_loss: 3.9350 - value_loss: 0.1180 - value_mae: 0.2866 - val_loss: 3.9713 - val_policy_categorical_accuracy: 0.2398 - val_policy_loss: 3.7700 - val_value_loss: 0.1169 - val_value_mae: 0.2837 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 16/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 4.1385 - policy_categorical_accuracy: 0.2089 - policy_loss: 3.9457 - value_loss: 0.1150 - value_mae: 0.2805\n",
            "\n",
            "--- Ã‰poque 17/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.1587 - policy_categorical_accuracy: 0.1982 - policy_loss: 3.9642 - value_loss: 0.1165 - value_mae: 0.2835\n",
            "\n",
            "--- Ã‰poque 18/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.1053 - policy_categorical_accuracy: 0.2089 - policy_loss: 3.9128 - value_loss: 0.1149 - value_mae: 0.2804\n",
            "\n",
            "--- Ã‰poque 19/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.0837 - policy_categorical_accuracy: 0.2151 - policy_loss: 3.8924 - value_loss: 0.1137 - value_mae: 0.2790\n",
            "\n",
            "--- Ã‰poque 20/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.9388 - policy_categorical_accuracy: 0.2441 - policy_loss: 3.7437 - value_loss: 0.1177 - value_mae: 0.2854\n",
            "Epoch 1: val_loss improved from 3.97134 to 3.81115, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 3.9389 - policy_categorical_accuracy: 0.2440 - policy_loss: 3.7436 - value_loss: 0.1176 - value_mae: 0.2854 - val_loss: 3.8111 - val_policy_categorical_accuracy: 0.2691 - val_policy_loss: 3.6105 - val_value_loss: 0.1165 - val_value_mae: 0.2831 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 21/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.0248 - policy_categorical_accuracy: 0.2133 - policy_loss: 3.8318 - value_loss: 0.1156 - value_mae: 0.2818\n",
            "\n",
            "--- Ã‰poque 22/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.9843 - policy_categorical_accuracy: 0.2287 - policy_loss: 3.7894 - value_loss: 0.1177 - value_mae: 0.2857\n",
            "\n",
            "--- Ã‰poque 23/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.9646 - policy_categorical_accuracy: 0.2319 - policy_loss: 3.7696 - value_loss: 0.1179 - value_mae: 0.2868\n",
            "\n",
            "--- Ã‰poque 24/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.9468 - policy_categorical_accuracy: 0.2403 - policy_loss: 3.7538 - value_loss: 0.1161 - value_mae: 0.2845\n",
            "\n",
            "--- Ã‰poque 25/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.8191 - policy_categorical_accuracy: 0.2684 - policy_loss: 3.6248 - value_loss: 0.1174 - value_mae: 0.2856\n",
            "Epoch 1: val_loss improved from 3.81115 to 3.69499, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 3.8190 - policy_categorical_accuracy: 0.2682 - policy_loss: 3.6245 - value_loss: 0.1174 - value_mae: 0.2855 - val_loss: 3.6950 - val_policy_categorical_accuracy: 0.2884 - val_policy_loss: 3.4952 - val_value_loss: 0.1161 - val_value_mae: 0.2830 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 26/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.9057 - policy_categorical_accuracy: 0.2484 - policy_loss: 3.7148 - value_loss: 0.1139 - value_mae: 0.2799\n",
            "\n",
            "--- Ã‰poque 27/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.8756 - policy_categorical_accuracy: 0.2435 - policy_loss: 3.6817 - value_loss: 0.1174 - value_mae: 0.2848\n",
            "\n",
            "--- Ã‰poque 28/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.8171 - policy_categorical_accuracy: 0.2511 - policy_loss: 3.6244 - value_loss: 0.1158 - value_mae: 0.2822\n",
            "\n",
            "--- Ã‰poque 29/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.8224 - policy_categorical_accuracy: 0.2539 - policy_loss: 3.6305 - value_loss: 0.1155 - value_mae: 0.2828\n",
            "\n",
            "--- Ã‰poque 30/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.7253 - policy_categorical_accuracy: 0.2804 - policy_loss: 3.5341 - value_loss: 0.1147 - value_mae: 0.2823\n",
            "Epoch 1: val_loss improved from 3.69499 to 3.60603, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 3.7253 - policy_categorical_accuracy: 0.2804 - policy_loss: 3.5339 - value_loss: 0.1148 - value_mae: 0.2824 - val_loss: 3.6060 - val_policy_categorical_accuracy: 0.3055 - val_policy_loss: 3.4063 - val_value_loss: 0.1159 - val_value_mae: 0.2827 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 31/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.8102 - policy_categorical_accuracy: 0.2551 - policy_loss: 3.6207 - value_loss: 0.1131 - value_mae: 0.2783\n",
            "\n",
            "--- Ã‰poque 32/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.7886 - policy_categorical_accuracy: 0.2600 - policy_loss: 3.5966 - value_loss: 0.1158 - value_mae: 0.2827\n",
            "\n",
            "--- Ã‰poque 33/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.7744 - policy_categorical_accuracy: 0.2680 - policy_loss: 3.5841 - value_loss: 0.1141 - value_mae: 0.2799\n",
            "\n",
            "--- Ã‰poque 34/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.7494 - policy_categorical_accuracy: 0.2644 - policy_loss: 3.5572 - value_loss: 0.1161 - value_mae: 0.2842\n",
            "\n",
            "--- Ã‰poque 35/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.6289 - policy_categorical_accuracy: 0.2958 - policy_loss: 3.4372 - value_loss: 0.1156 - value_mae: 0.2823\n",
            "Epoch 1: val_loss improved from 3.60603 to 3.52861, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 3.6295 - policy_categorical_accuracy: 0.2957 - policy_loss: 3.4376 - value_loss: 0.1156 - value_mae: 0.2824 - val_loss: 3.5286 - val_policy_categorical_accuracy: 0.3189 - val_policy_loss: 3.3297 - val_value_loss: 0.1155 - val_value_mae: 0.2821 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 36/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.7634 - policy_categorical_accuracy: 0.2703 - policy_loss: 3.5708 - value_loss: 0.1167 - value_mae: 0.2848\n",
            "\n",
            "--- Ã‰poque 37/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.7126 - policy_categorical_accuracy: 0.2755 - policy_loss: 3.5205 - value_loss: 0.1162 - value_mae: 0.2837\n",
            "\n",
            "--- Ã‰poque 38/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.7158 - policy_categorical_accuracy: 0.2675 - policy_loss: 3.5235 - value_loss: 0.1165 - value_mae: 0.2852\n",
            "\n",
            "--- Ã‰poque 39/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.7132 - policy_categorical_accuracy: 0.2724 - policy_loss: 3.5224 - value_loss: 0.1150 - value_mae: 0.2813\n",
            "\n",
            "--- Ã‰poque 40/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.5834 - policy_categorical_accuracy: 0.3062 - policy_loss: 3.3929 - value_loss: 0.1148 - value_mae: 0.2815\n",
            "Epoch 1: val_loss improved from 3.52861 to 3.47319, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 3.5833 - policy_categorical_accuracy: 0.3061 - policy_loss: 3.3929 - value_loss: 0.1149 - value_mae: 0.2815 - val_loss: 3.4732 - val_policy_categorical_accuracy: 0.3253 - val_policy_loss: 3.2747 - val_value_loss: 0.1152 - val_value_mae: 0.2818 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 41/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.7088 - policy_categorical_accuracy: 0.2785 - policy_loss: 3.5174 - value_loss: 0.1159 - value_mae: 0.2829\n",
            "\n",
            "--- Ã‰poque 42/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.6865 - policy_categorical_accuracy: 0.2691 - policy_loss: 3.4951 - value_loss: 0.1160 - value_mae: 0.2842\n",
            "\n",
            "--- Ã‰poque 43/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.6188 - policy_categorical_accuracy: 0.2872 - policy_loss: 3.4299 - value_loss: 0.1137 - value_mae: 0.2799\n",
            "\n",
            "--- Ã‰poque 44/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5992 - policy_categorical_accuracy: 0.2848 - policy_loss: 3.4100 - value_loss: 0.1138 - value_mae: 0.2791\n",
            "\n",
            "--- Ã‰poque 45/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.5179 - policy_categorical_accuracy: 0.3153 - policy_loss: 3.3284 - value_loss: 0.1142 - value_mae: 0.2818\n",
            "Epoch 1: val_loss improved from 3.47319 to 3.42251, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 3.5184 - policy_categorical_accuracy: 0.3152 - policy_loss: 3.3290 - value_loss: 0.1142 - value_mae: 0.2818 - val_loss: 3.4225 - val_policy_categorical_accuracy: 0.3318 - val_policy_loss: 3.2251 - val_value_loss: 0.1150 - val_value_mae: 0.2818 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 46/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.6433 - policy_categorical_accuracy: 0.2845 - policy_loss: 3.4527 - value_loss: 0.1152 - value_mae: 0.2819\n",
            "\n",
            "--- Ã‰poque 47/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.6268 - policy_categorical_accuracy: 0.2857 - policy_loss: 3.4365 - value_loss: 0.1152 - value_mae: 0.2824\n",
            "\n",
            "--- Ã‰poque 48/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.6142 - policy_categorical_accuracy: 0.2866 - policy_loss: 3.4223 - value_loss: 0.1170 - value_mae: 0.2863\n",
            "\n",
            "--- Ã‰poque 49/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.6085 - policy_categorical_accuracy: 0.2903 - policy_loss: 3.4170 - value_loss: 0.1164 - value_mae: 0.2859\n",
            "\n",
            "--- Ã‰poque 50/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.4382 - policy_categorical_accuracy: 0.3203 - policy_loss: 3.2490 - value_loss: 0.1143 - value_mae: 0.2815\n",
            "Epoch 1: val_loss improved from 3.42251 to 3.38221, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 3.4392 - policy_categorical_accuracy: 0.3202 - policy_loss: 3.2499 - value_loss: 0.1143 - value_mae: 0.2815 - val_loss: 3.3822 - val_policy_categorical_accuracy: 0.3364 - val_policy_loss: 3.1859 - val_value_loss: 0.1142 - val_value_mae: 0.2807 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 51/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.5993 - policy_categorical_accuracy: 0.2841 - policy_loss: 3.4095 - value_loss: 0.1151 - value_mae: 0.2837\n",
            "\n",
            "--- Ã‰poque 52/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.5936 - policy_categorical_accuracy: 0.2916 - policy_loss: 3.4053 - value_loss: 0.1134 - value_mae: 0.2800\n",
            "\n",
            "--- Ã‰poque 53/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.6477 - policy_categorical_accuracy: 0.2755 - policy_loss: 3.4589 - value_loss: 0.1141 - value_mae: 0.2806\n",
            "\n",
            "--- Ã‰poque 54/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.5747 - policy_categorical_accuracy: 0.2943 - policy_loss: 3.3863 - value_loss: 0.1139 - value_mae: 0.2804\n",
            "\n",
            "--- Ã‰poque 55/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.4395 - policy_categorical_accuracy: 0.3213 - policy_loss: 3.2517 - value_loss: 0.1132 - value_mae: 0.2795\n",
            "Epoch 1: val_loss improved from 3.38221 to 3.34624, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 3.4397 - policy_categorical_accuracy: 0.3212 - policy_loss: 3.2520 - value_loss: 0.1132 - value_mae: 0.2795 - val_loss: 3.3462 - val_policy_categorical_accuracy: 0.3426 - val_policy_loss: 3.1511 - val_value_loss: 0.1136 - val_value_mae: 0.2798 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 56/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.5872 - policy_categorical_accuracy: 0.2953 - policy_loss: 3.3990 - value_loss: 0.1139 - value_mae: 0.2811\n",
            "\n",
            "--- Ã‰poque 57/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.6006 - policy_categorical_accuracy: 0.2842 - policy_loss: 3.4112 - value_loss: 0.1151 - value_mae: 0.2826\n",
            "\n",
            "--- Ã‰poque 58/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.5776 - policy_categorical_accuracy: 0.2890 - policy_loss: 3.3900 - value_loss: 0.1134 - value_mae: 0.2801\n",
            "\n",
            "--- Ã‰poque 59/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.5577 - policy_categorical_accuracy: 0.2989 - policy_loss: 3.3695 - value_loss: 0.1138 - value_mae: 0.2817\n",
            "\n",
            "--- Ã‰poque 60/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.4135 - policy_categorical_accuracy: 0.3270 - policy_loss: 3.2264 - value_loss: 0.1129 - value_mae: 0.2794\n",
            "Epoch 1: val_loss improved from 3.34624 to 3.31592, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 3.4137 - policy_categorical_accuracy: 0.3268 - policy_loss: 3.2265 - value_loss: 0.1129 - value_mae: 0.2794 - val_loss: 3.3159 - val_policy_categorical_accuracy: 0.3437 - val_policy_loss: 3.1224 - val_value_loss: 0.1129 - val_value_mae: 0.2793 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 61/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.5371 - policy_categorical_accuracy: 0.2944 - policy_loss: 3.3485 - value_loss: 0.1145 - value_mae: 0.2832\n",
            "\n",
            "--- Ã‰poque 62/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5156 - policy_categorical_accuracy: 0.3011 - policy_loss: 3.3286 - value_loss: 0.1130 - value_mae: 0.2802\n",
            "\n",
            "--- Ã‰poque 63/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4877 - policy_categorical_accuracy: 0.3020 - policy_loss: 3.3019 - value_loss: 0.1119 - value_mae: 0.2789\n",
            "\n",
            "--- Ã‰poque 64/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5308 - policy_categorical_accuracy: 0.3038 - policy_loss: 3.3444 - value_loss: 0.1125 - value_mae: 0.2789\n",
            "\n",
            "--- Ã‰poque 65/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.3699 - policy_categorical_accuracy: 0.3332 - policy_loss: 3.1835 - value_loss: 0.1126 - value_mae: 0.2788\n",
            "Epoch 1: val_loss improved from 3.31592 to 3.28285, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 3.3702 - policy_categorical_accuracy: 0.3330 - policy_loss: 3.1838 - value_loss: 0.1126 - value_mae: 0.2788 - val_loss: 3.2829 - val_policy_categorical_accuracy: 0.3516 - val_policy_loss: 3.0905 - val_value_loss: 0.1122 - val_value_mae: 0.2784 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 66/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4981 - policy_categorical_accuracy: 0.3099 - policy_loss: 3.3154 - value_loss: 0.1091 - value_mae: 0.2739\n",
            "\n",
            "--- Ã‰poque 67/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5203 - policy_categorical_accuracy: 0.3066 - policy_loss: 3.3385 - value_loss: 0.1083 - value_mae: 0.2715\n",
            "\n",
            "--- Ã‰poque 68/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5316 - policy_categorical_accuracy: 0.2952 - policy_loss: 3.3465 - value_loss: 0.1116 - value_mae: 0.2774\n",
            "\n",
            "--- Ã‰poque 69/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5363 - policy_categorical_accuracy: 0.3016 - policy_loss: 3.3521 - value_loss: 0.1107 - value_mae: 0.2756\n",
            "\n",
            "--- Ã‰poque 70/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.3728 - policy_categorical_accuracy: 0.3299 - policy_loss: 3.1890 - value_loss: 0.1102 - value_mae: 0.2760\n",
            "Epoch 1: val_loss improved from 3.28285 to 3.25765, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.3721 - policy_categorical_accuracy: 0.3299 - policy_loss: 3.1883 - value_loss: 0.1103 - value_mae: 0.2761 - val_loss: 3.2576 - val_policy_categorical_accuracy: 0.3537 - val_policy_loss: 3.0662 - val_value_loss: 0.1113 - val_value_mae: 0.2767 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 71/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4886 - policy_categorical_accuracy: 0.3051 - policy_loss: 3.3047 - value_loss: 0.1104 - value_mae: 0.2750\n",
            "\n",
            "--- Ã‰poque 72/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5007 - policy_categorical_accuracy: 0.3085 - policy_loss: 3.3170 - value_loss: 0.1102 - value_mae: 0.2753\n",
            "\n",
            "--- Ã‰poque 73/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4876 - policy_categorical_accuracy: 0.3079 - policy_loss: 3.3036 - value_loss: 0.1107 - value_mae: 0.2767\n",
            "\n",
            "--- Ã‰poque 74/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4669 - policy_categorical_accuracy: 0.3048 - policy_loss: 3.2863 - value_loss: 0.1071 - value_mae: 0.2700\n",
            "\n",
            "--- Ã‰poque 75/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.3208 - policy_categorical_accuracy: 0.3420 - policy_loss: 3.1361 - value_loss: 0.1115 - value_mae: 0.2781\n",
            "Epoch 1: val_loss improved from 3.25765 to 3.23038, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 3.3209 - policy_categorical_accuracy: 0.3420 - policy_loss: 3.1362 - value_loss: 0.1115 - value_mae: 0.2781 - val_loss: 3.2304 - val_policy_categorical_accuracy: 0.3563 - val_policy_loss: 3.0406 - val_value_loss: 0.1105 - val_value_mae: 0.2757 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 76/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5095 - policy_categorical_accuracy: 0.3065 - policy_loss: 3.3282 - value_loss: 0.1083 - value_mae: 0.2737\n",
            "\n",
            "--- Ã‰poque 77/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5158 - policy_categorical_accuracy: 0.2903 - policy_loss: 3.3317 - value_loss: 0.1111 - value_mae: 0.2769\n",
            "\n",
            "--- Ã‰poque 78/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4634 - policy_categorical_accuracy: 0.3048 - policy_loss: 3.2786 - value_loss: 0.1117 - value_mae: 0.2777\n",
            "\n",
            "--- Ã‰poque 79/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4831 - policy_categorical_accuracy: 0.3069 - policy_loss: 3.3009 - value_loss: 0.1092 - value_mae: 0.2743\n",
            "\n",
            "--- Ã‰poque 80/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.3011 - policy_categorical_accuracy: 0.3431 - policy_loss: 3.1170 - value_loss: 0.1111 - value_mae: 0.2774\n",
            "Epoch 1: val_loss improved from 3.23038 to 3.20579, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.3011 - policy_categorical_accuracy: 0.3430 - policy_loss: 3.1173 - value_loss: 0.1111 - value_mae: 0.2773 - val_loss: 3.2058 - val_policy_categorical_accuracy: 0.3626 - val_policy_loss: 3.0174 - val_value_loss: 0.1098 - val_value_mae: 0.2747 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 81/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4554 - policy_categorical_accuracy: 0.3063 - policy_loss: 3.2745 - value_loss: 0.1082 - value_mae: 0.2709\n",
            "\n",
            "--- Ã‰poque 82/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4971 - policy_categorical_accuracy: 0.3024 - policy_loss: 3.3160 - value_loss: 0.1083 - value_mae: 0.2713\n",
            "\n",
            "--- Ã‰poque 83/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4803 - policy_categorical_accuracy: 0.3017 - policy_loss: 3.2981 - value_loss: 0.1095 - value_mae: 0.2747\n",
            "\n",
            "--- Ã‰poque 84/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4314 - policy_categorical_accuracy: 0.3095 - policy_loss: 3.2504 - value_loss: 0.1082 - value_mae: 0.2719\n",
            "\n",
            "--- Ã‰poque 85/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2485 - policy_categorical_accuracy: 0.3465 - policy_loss: 3.0674 - value_loss: 0.1085 - value_mae: 0.2723\n",
            "Epoch 1: val_loss improved from 3.20579 to 3.18690, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 3.2496 - policy_categorical_accuracy: 0.3463 - policy_loss: 3.0684 - value_loss: 0.1086 - value_mae: 0.2724 - val_loss: 3.1869 - val_policy_categorical_accuracy: 0.3669 - val_policy_loss: 2.9998 - val_value_loss: 0.1093 - val_value_mae: 0.2739 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 86/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4726 - policy_categorical_accuracy: 0.3082 - policy_loss: 3.2914 - value_loss: 0.1085 - value_mae: 0.2734\n",
            "\n",
            "--- Ã‰poque 87/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4244 - policy_categorical_accuracy: 0.3109 - policy_loss: 3.2420 - value_loss: 0.1099 - value_mae: 0.2750\n",
            "\n",
            "--- Ã‰poque 88/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.4454 - policy_categorical_accuracy: 0.3070 - policy_loss: 3.2630 - value_loss: 0.1101 - value_mae: 0.2752\n",
            "\n",
            "--- Ã‰poque 89/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.4758 - policy_categorical_accuracy: 0.3055 - policy_loss: 3.2940 - value_loss: 0.1096 - value_mae: 0.2744\n",
            "\n",
            "--- Ã‰poque 90/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2664 - policy_categorical_accuracy: 0.3492 - policy_loss: 3.0848 - value_loss: 0.1092 - value_mae: 0.2741\n",
            "Epoch 1: val_loss improved from 3.18690 to 3.16120, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.2660 - policy_categorical_accuracy: 0.3492 - policy_loss: 3.0845 - value_loss: 0.1092 - value_mae: 0.2741 - val_loss: 3.1612 - val_policy_categorical_accuracy: 0.3719 - val_policy_loss: 2.9751 - val_value_loss: 0.1088 - val_value_mae: 0.2725 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 91/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5022 - policy_categorical_accuracy: 0.3093 - policy_loss: 3.3219 - value_loss: 0.1080 - value_mae: 0.2704\n",
            "\n",
            "--- Ã‰poque 92/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4694 - policy_categorical_accuracy: 0.3071 - policy_loss: 3.2883 - value_loss: 0.1087 - value_mae: 0.2722\n",
            "\n",
            "--- Ã‰poque 93/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4114 - policy_categorical_accuracy: 0.3243 - policy_loss: 3.2325 - value_loss: 0.1067 - value_mae: 0.2707\n",
            "\n",
            "--- Ã‰poque 94/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4564 - policy_categorical_accuracy: 0.3080 - policy_loss: 3.2765 - value_loss: 0.1076 - value_mae: 0.2712\n",
            "\n",
            "--- Ã‰poque 95/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2285 - policy_categorical_accuracy: 0.3520 - policy_loss: 3.0475 - value_loss: 0.1089 - value_mae: 0.2737\n",
            "Epoch 1: val_loss improved from 3.16120 to 3.14375, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 3.2291 - policy_categorical_accuracy: 0.3519 - policy_loss: 3.0483 - value_loss: 0.1089 - value_mae: 0.2737 - val_loss: 3.1438 - val_policy_categorical_accuracy: 0.3725 - val_policy_loss: 2.9590 - val_value_loss: 0.1081 - val_value_mae: 0.2717 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 96/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4222 - policy_categorical_accuracy: 0.3138 - policy_loss: 3.2417 - value_loss: 0.1084 - value_mae: 0.2722\n",
            "\n",
            "--- Ã‰poque 97/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3967 - policy_categorical_accuracy: 0.3249 - policy_loss: 3.2147 - value_loss: 0.1100 - value_mae: 0.2742\n",
            "\n",
            "--- Ã‰poque 98/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4256 - policy_categorical_accuracy: 0.3122 - policy_loss: 3.2444 - value_loss: 0.1092 - value_mae: 0.2746\n",
            "\n",
            "--- Ã‰poque 99/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.4096 - policy_categorical_accuracy: 0.3115 - policy_loss: 3.2325 - value_loss: 0.1051 - value_mae: 0.2684\n",
            "\n",
            "--- Ã‰poque 100/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.1991 - policy_categorical_accuracy: 0.3504 - policy_loss: 3.0210 - value_loss: 0.1062 - value_mae: 0.2697\n",
            "Epoch 1: val_loss improved from 3.14375 to 3.12546, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.1998 - policy_categorical_accuracy: 0.3505 - policy_loss: 3.0216 - value_loss: 0.1063 - value_mae: 0.2698 - val_loss: 3.1255 - val_policy_categorical_accuracy: 0.3758 - val_policy_loss: 2.9407 - val_value_loss: 0.1080 - val_value_mae: 0.2715 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 101/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4174 - policy_categorical_accuracy: 0.3130 - policy_loss: 3.2386 - value_loss: 0.1071 - value_mae: 0.2700\n",
            "\n",
            "--- Ã‰poque 102/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4219 - policy_categorical_accuracy: 0.3095 - policy_loss: 3.2432 - value_loss: 0.1070 - value_mae: 0.2701\n",
            "\n",
            "--- Ã‰poque 103/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3557 - policy_categorical_accuracy: 0.3175 - policy_loss: 3.1755 - value_loss: 0.1086 - value_mae: 0.2725\n",
            "\n",
            "--- Ã‰poque 104/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3788 - policy_categorical_accuracy: 0.3175 - policy_loss: 3.2013 - value_loss: 0.1058 - value_mae: 0.2684\n",
            "\n",
            "--- Ã‰poque 105/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2282 - policy_categorical_accuracy: 0.3521 - policy_loss: 3.0499 - value_loss: 0.1068 - value_mae: 0.2698\n",
            "Epoch 1: val_loss improved from 3.12546 to 3.10590, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 3.2271 - policy_categorical_accuracy: 0.3524 - policy_loss: 3.0485 - value_loss: 0.1068 - value_mae: 0.2698 - val_loss: 3.1059 - val_policy_categorical_accuracy: 0.3780 - val_policy_loss: 2.9222 - val_value_loss: 0.1073 - val_value_mae: 0.2702 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 106/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4082 - policy_categorical_accuracy: 0.3135 - policy_loss: 3.2290 - value_loss: 0.1076 - value_mae: 0.2708\n",
            "\n",
            "--- Ã‰poque 107/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3664 - policy_categorical_accuracy: 0.3260 - policy_loss: 3.1859 - value_loss: 0.1090 - value_mae: 0.2735\n",
            "\n",
            "--- Ã‰poque 108/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3851 - policy_categorical_accuracy: 0.3114 - policy_loss: 3.2051 - value_loss: 0.1083 - value_mae: 0.2724\n",
            "\n",
            "--- Ã‰poque 109/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4173 - policy_categorical_accuracy: 0.3114 - policy_loss: 3.2365 - value_loss: 0.1093 - value_mae: 0.2746\n",
            "\n",
            "--- Ã‰poque 110/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.1928 - policy_categorical_accuracy: 0.3628 - policy_loss: 3.0137 - value_loss: 0.1078 - value_mae: 0.2708\n",
            "Epoch 1: val_loss improved from 3.10590 to 3.08905, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 3.1923 - policy_categorical_accuracy: 0.3628 - policy_loss: 3.0132 - value_loss: 0.1078 - value_mae: 0.2708 - val_loss: 3.0891 - val_policy_categorical_accuracy: 0.3812 - val_policy_loss: 2.9061 - val_value_loss: 0.1068 - val_value_mae: 0.2694 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 111/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4140 - policy_categorical_accuracy: 0.3105 - policy_loss: 3.2377 - value_loss: 0.1049 - value_mae: 0.2649\n",
            "\n",
            "--- Ã‰poque 112/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4154 - policy_categorical_accuracy: 0.3116 - policy_loss: 3.2366 - value_loss: 0.1076 - value_mae: 0.2708\n",
            "\n",
            "--- Ã‰poque 113/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3805 - policy_categorical_accuracy: 0.3142 - policy_loss: 3.2030 - value_loss: 0.1063 - value_mae: 0.2687\n",
            "\n",
            "--- Ã‰poque 114/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3963 - policy_categorical_accuracy: 0.3157 - policy_loss: 3.2182 - value_loss: 0.1070 - value_mae: 0.2692\n",
            "\n",
            "--- Ã‰poque 115/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.1969 - policy_categorical_accuracy: 0.3537 - policy_loss: 3.0166 - value_loss: 0.1093 - value_mae: 0.2733\n",
            "Epoch 1: val_loss improved from 3.08905 to 3.06948, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 3.1962 - policy_categorical_accuracy: 0.3540 - policy_loss: 3.0160 - value_loss: 0.1092 - value_mae: 0.2732 - val_loss: 3.0695 - val_policy_categorical_accuracy: 0.3827 - val_policy_loss: 2.8870 - val_value_loss: 0.1067 - val_value_mae: 0.2687 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 116/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3400 - policy_categorical_accuracy: 0.3346 - policy_loss: 3.1601 - value_loss: 0.1089 - value_mae: 0.2725\n",
            "\n",
            "--- Ã‰poque 117/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3802 - policy_categorical_accuracy: 0.3232 - policy_loss: 3.2029 - value_loss: 0.1065 - value_mae: 0.2690\n",
            "\n",
            "--- Ã‰poque 118/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3871 - policy_categorical_accuracy: 0.3220 - policy_loss: 3.2123 - value_loss: 0.1038 - value_mae: 0.2650\n",
            "\n",
            "--- Ã‰poque 119/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3690 - policy_categorical_accuracy: 0.3164 - policy_loss: 3.1927 - value_loss: 0.1056 - value_mae: 0.2682\n",
            "\n",
            "--- Ã‰poque 120/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.1278 - policy_categorical_accuracy: 0.3731 - policy_loss: 2.9479 - value_loss: 0.1090 - value_mae: 0.2730\n",
            "Epoch 1: val_loss improved from 3.06948 to 3.05750, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 3.1284 - policy_categorical_accuracy: 0.3730 - policy_loss: 2.9483 - value_loss: 0.1090 - value_mae: 0.2729 - val_loss: 3.0575 - val_policy_categorical_accuracy: 0.3850 - val_policy_loss: 2.8763 - val_value_loss: 0.1063 - val_value_mae: 0.2681 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 121/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3893 - policy_categorical_accuracy: 0.3127 - policy_loss: 3.2135 - value_loss: 0.1047 - value_mae: 0.2653\n",
            "\n",
            "--- Ã‰poque 122/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3518 - policy_categorical_accuracy: 0.3166 - policy_loss: 3.1761 - value_loss: 0.1048 - value_mae: 0.2653\n",
            "\n",
            "--- Ã‰poque 123/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3305 - policy_categorical_accuracy: 0.3245 - policy_loss: 3.1526 - value_loss: 0.1072 - value_mae: 0.2693\n",
            "\n",
            "--- Ã‰poque 124/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3788 - policy_categorical_accuracy: 0.3160 - policy_loss: 3.2033 - value_loss: 0.1048 - value_mae: 0.2659\n",
            "\n",
            "--- Ã‰poque 125/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.1077 - policy_categorical_accuracy: 0.3718 - policy_loss: 2.9323 - value_loss: 0.1048 - value_mae: 0.2660\n",
            "Epoch 1: val_loss improved from 3.05750 to 3.04252, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 3.1084 - policy_categorical_accuracy: 0.3717 - policy_loss: 2.9329 - value_loss: 0.1049 - value_mae: 0.2660 - val_loss: 3.0425 - val_policy_categorical_accuracy: 0.3900 - val_policy_loss: 2.8618 - val_value_loss: 0.1060 - val_value_mae: 0.2671 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 126/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3595 - policy_categorical_accuracy: 0.3229 - policy_loss: 3.1812 - value_loss: 0.1076 - value_mae: 0.2707\n",
            "\n",
            "--- Ã‰poque 127/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3297 - policy_categorical_accuracy: 0.3318 - policy_loss: 3.1562 - value_loss: 0.1029 - value_mae: 0.2635\n",
            "\n",
            "--- Ã‰poque 128/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3285 - policy_categorical_accuracy: 0.3295 - policy_loss: 3.1545 - value_loss: 0.1035 - value_mae: 0.2637\n",
            "\n",
            "--- Ã‰poque 129/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3455 - policy_categorical_accuracy: 0.3284 - policy_loss: 3.1681 - value_loss: 0.1069 - value_mae: 0.2680\n",
            "\n",
            "--- Ã‰poque 130/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.1158 - policy_categorical_accuracy: 0.3739 - policy_loss: 2.9387 - value_loss: 0.1068 - value_mae: 0.2684\n",
            "Epoch 1: val_loss improved from 3.04252 to 3.03287, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 3.1161 - policy_categorical_accuracy: 0.3739 - policy_loss: 2.9389 - value_loss: 0.1068 - value_mae: 0.2684 - val_loss: 3.0329 - val_policy_categorical_accuracy: 0.3917 - val_policy_loss: 2.8523 - val_value_loss: 0.1067 - val_value_mae: 0.2676 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 131/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3086 - policy_categorical_accuracy: 0.3277 - policy_loss: 3.1309 - value_loss: 0.1074 - value_mae: 0.2705\n",
            "\n",
            "--- Ã‰poque 132/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3503 - policy_categorical_accuracy: 0.3329 - policy_loss: 3.1759 - value_loss: 0.1041 - value_mae: 0.2645\n",
            "\n",
            "--- Ã‰poque 133/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.3352 - policy_categorical_accuracy: 0.3180 - policy_loss: 3.1584 - value_loss: 0.1065 - value_mae: 0.2684\n",
            "\n",
            "--- Ã‰poque 134/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3345 - policy_categorical_accuracy: 0.3246 - policy_loss: 3.1602 - value_loss: 0.1042 - value_mae: 0.2642\n",
            "\n",
            "--- Ã‰poque 135/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.1073 - policy_categorical_accuracy: 0.3663 - policy_loss: 2.9289 - value_loss: 0.1082 - value_mae: 0.2696\n",
            "Epoch 1: val_loss improved from 3.03287 to 3.01420, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 3.1072 - policy_categorical_accuracy: 0.3663 - policy_loss: 2.9290 - value_loss: 0.1081 - value_mae: 0.2695 - val_loss: 3.0142 - val_policy_categorical_accuracy: 0.3941 - val_policy_loss: 2.8352 - val_value_loss: 0.1057 - val_value_mae: 0.2664 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 136/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3125 - policy_categorical_accuracy: 0.3301 - policy_loss: 3.1382 - value_loss: 0.1042 - value_mae: 0.2641\n",
            "\n",
            "--- Ã‰poque 137/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2775 - policy_categorical_accuracy: 0.3374 - policy_loss: 3.1015 - value_loss: 0.1058 - value_mae: 0.2665\n",
            "\n",
            "--- Ã‰poque 138/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3289 - policy_categorical_accuracy: 0.3265 - policy_loss: 3.1536 - value_loss: 0.1054 - value_mae: 0.2658\n",
            "\n",
            "--- Ã‰poque 139/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3182 - policy_categorical_accuracy: 0.3369 - policy_loss: 3.1454 - value_loss: 0.1030 - value_mae: 0.2616\n",
            "\n",
            "--- Ã‰poque 140/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0818 - policy_categorical_accuracy: 0.3872 - policy_loss: 2.9052 - value_loss: 0.1067 - value_mae: 0.2680\n",
            "Epoch 1: val_loss improved from 3.01420 to 3.00410, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 3.0823 - policy_categorical_accuracy: 0.3870 - policy_loss: 2.9058 - value_loss: 0.1066 - value_mae: 0.2680 - val_loss: 3.0041 - val_policy_categorical_accuracy: 0.3997 - val_policy_loss: 2.8252 - val_value_loss: 0.1054 - val_value_mae: 0.2658 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 141/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3096 - policy_categorical_accuracy: 0.3321 - policy_loss: 3.1343 - value_loss: 0.1056 - value_mae: 0.2660\n",
            "\n",
            "--- Ã‰poque 142/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3488 - policy_categorical_accuracy: 0.3199 - policy_loss: 3.1712 - value_loss: 0.1077 - value_mae: 0.2703\n",
            "\n",
            "--- Ã‰poque 143/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3326 - policy_categorical_accuracy: 0.3265 - policy_loss: 3.1561 - value_loss: 0.1066 - value_mae: 0.2676\n",
            "\n",
            "--- Ã‰poque 144/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3491 - policy_categorical_accuracy: 0.3219 - policy_loss: 3.1721 - value_loss: 0.1071 - value_mae: 0.2685\n",
            "\n",
            "--- Ã‰poque 145/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0865 - policy_categorical_accuracy: 0.3788 - policy_loss: 2.9118 - value_loss: 0.1050 - value_mae: 0.2665\n",
            "Epoch 1: val_loss improved from 3.00410 to 2.99316, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 3.0863 - policy_categorical_accuracy: 0.3787 - policy_loss: 2.9117 - value_loss: 0.1050 - value_mae: 0.2665 - val_loss: 2.9932 - val_policy_categorical_accuracy: 0.3992 - val_policy_loss: 2.8154 - val_value_loss: 0.1051 - val_value_mae: 0.2655 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 146/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3227 - policy_categorical_accuracy: 0.3264 - policy_loss: 3.1468 - value_loss: 0.1061 - value_mae: 0.2675\n",
            "\n",
            "--- Ã‰poque 147/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3281 - policy_categorical_accuracy: 0.3315 - policy_loss: 3.1538 - value_loss: 0.1047 - value_mae: 0.2652\n",
            "\n",
            "--- Ã‰poque 148/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.2853 - policy_categorical_accuracy: 0.3306 - policy_loss: 3.1125 - value_loss: 0.1030 - value_mae: 0.2620\n",
            "\n",
            "--- Ã‰poque 149/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2946 - policy_categorical_accuracy: 0.3272 - policy_loss: 3.1200 - value_loss: 0.1051 - value_mae: 0.2662\n",
            "\n",
            "--- Ã‰poque 150/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.0643 - policy_categorical_accuracy: 0.3716 - policy_loss: 2.8892 - value_loss: 0.1056 - value_mae: 0.2653\n",
            "Epoch 1: val_loss improved from 2.99316 to 2.97620, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 3.0645 - policy_categorical_accuracy: 0.3719 - policy_loss: 2.8894 - value_loss: 0.1056 - value_mae: 0.2653 - val_loss: 2.9762 - val_policy_categorical_accuracy: 0.4031 - val_policy_loss: 2.7988 - val_value_loss: 0.1051 - val_value_mae: 0.2649 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 151/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2731 - policy_categorical_accuracy: 0.3386 - policy_loss: 3.1019 - value_loss: 0.1019 - value_mae: 0.2596\n",
            "\n",
            "--- Ã‰poque 152/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3132 - policy_categorical_accuracy: 0.3317 - policy_loss: 3.1367 - value_loss: 0.1069 - value_mae: 0.2677\n",
            "\n",
            "--- Ã‰poque 153/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3034 - policy_categorical_accuracy: 0.3308 - policy_loss: 3.1285 - value_loss: 0.1055 - value_mae: 0.2654\n",
            "\n",
            "--- Ã‰poque 154/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2975 - policy_categorical_accuracy: 0.3271 - policy_loss: 3.1236 - value_loss: 0.1047 - value_mae: 0.2629\n",
            "\n",
            "--- Ã‰poque 155/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0352 - policy_categorical_accuracy: 0.3864 - policy_loss: 2.8580 - value_loss: 0.1079 - value_mae: 0.2691\n",
            "Epoch 1: val_loss improved from 2.97620 to 2.96852, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 3.0361 - policy_categorical_accuracy: 0.3861 - policy_loss: 2.8590 - value_loss: 0.1078 - value_mae: 0.2690 - val_loss: 2.9685 - val_policy_categorical_accuracy: 0.4045 - val_policy_loss: 2.7910 - val_value_loss: 0.1051 - val_value_mae: 0.2648 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 156/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2985 - policy_categorical_accuracy: 0.3280 - policy_loss: 3.1228 - value_loss: 0.1061 - value_mae: 0.2673\n",
            "\n",
            "--- Ã‰poque 157/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2738 - policy_categorical_accuracy: 0.3377 - policy_loss: 3.1020 - value_loss: 0.1027 - value_mae: 0.2618\n",
            "\n",
            "--- Ã‰poque 158/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3106 - policy_categorical_accuracy: 0.3270 - policy_loss: 3.1338 - value_loss: 0.1076 - value_mae: 0.2692\n",
            "\n",
            "--- Ã‰poque 159/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2888 - policy_categorical_accuracy: 0.3346 - policy_loss: 3.1147 - value_loss: 0.1051 - value_mae: 0.2645\n",
            "\n",
            "--- Ã‰poque 160/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.0312 - policy_categorical_accuracy: 0.3867 - policy_loss: 2.8552 - value_loss: 0.1069 - value_mae: 0.2690\n",
            "Epoch 1: val_loss improved from 2.96852 to 2.95798, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.0316 - policy_categorical_accuracy: 0.3866 - policy_loss: 2.8556 - value_loss: 0.1068 - value_mae: 0.2688 - val_loss: 2.9580 - val_policy_categorical_accuracy: 0.4025 - val_policy_loss: 2.7809 - val_value_loss: 0.1052 - val_value_mae: 0.2646 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 161/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3037 - policy_categorical_accuracy: 0.3330 - policy_loss: 3.1321 - value_loss: 0.1027 - value_mae: 0.2616\n",
            "\n",
            "--- Ã‰poque 162/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3100 - policy_categorical_accuracy: 0.3284 - policy_loss: 3.1382 - value_loss: 0.1029 - value_mae: 0.2611\n",
            "\n",
            "--- Ã‰poque 163/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2769 - policy_categorical_accuracy: 0.3308 - policy_loss: 3.1020 - value_loss: 0.1057 - value_mae: 0.2661\n",
            "\n",
            "--- Ã‰poque 164/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3411 - policy_categorical_accuracy: 0.3184 - policy_loss: 3.1701 - value_loss: 0.1022 - value_mae: 0.2602\n",
            "\n",
            "--- Ã‰poque 165/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.0357 - policy_categorical_accuracy: 0.3809 - policy_loss: 2.8619 - value_loss: 0.1049 - value_mae: 0.2639\n",
            "Epoch 1: val_loss improved from 2.95798 to 2.94287, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.0355 - policy_categorical_accuracy: 0.3810 - policy_loss: 2.8618 - value_loss: 0.1049 - value_mae: 0.2639 - val_loss: 2.9429 - val_policy_categorical_accuracy: 0.4093 - val_policy_loss: 2.7671 - val_value_loss: 0.1043 - val_value_mae: 0.2632 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 166/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2576 - policy_categorical_accuracy: 0.3427 - policy_loss: 3.0829 - value_loss: 0.1058 - value_mae: 0.2651\n",
            "\n",
            "--- Ã‰poque 167/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2629 - policy_categorical_accuracy: 0.3423 - policy_loss: 3.0902 - value_loss: 0.1038 - value_mae: 0.2628\n",
            "\n",
            "--- Ã‰poque 168/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2980 - policy_categorical_accuracy: 0.3341 - policy_loss: 3.1280 - value_loss: 0.1013 - value_mae: 0.2591\n",
            "\n",
            "--- Ã‰poque 169/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2739 - policy_categorical_accuracy: 0.3400 - policy_loss: 3.1010 - value_loss: 0.1043 - value_mae: 0.2640\n",
            "\n",
            "--- Ã‰poque 170/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.0487 - policy_categorical_accuracy: 0.3760 - policy_loss: 2.8749 - value_loss: 0.1050 - value_mae: 0.2644\n",
            "Epoch 1: val_loss improved from 2.94287 to 2.93189, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 3.0478 - policy_categorical_accuracy: 0.3764 - policy_loss: 2.8743 - value_loss: 0.1050 - value_mae: 0.2644 - val_loss: 2.9319 - val_policy_categorical_accuracy: 0.4086 - val_policy_loss: 2.7554 - val_value_loss: 0.1050 - val_value_mae: 0.2636 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 171/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2734 - policy_categorical_accuracy: 0.3302 - policy_loss: 3.1025 - value_loss: 0.1022 - value_mae: 0.2602\n",
            "\n",
            "--- Ã‰poque 172/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2663 - policy_categorical_accuracy: 0.3459 - policy_loss: 3.0912 - value_loss: 0.1062 - value_mae: 0.2677\n",
            "\n",
            "--- Ã‰poque 173/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2960 - policy_categorical_accuracy: 0.3350 - policy_loss: 3.1241 - value_loss: 0.1034 - value_mae: 0.2634\n",
            "\n",
            "--- Ã‰poque 174/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2418 - policy_categorical_accuracy: 0.3330 - policy_loss: 3.0674 - value_loss: 0.1058 - value_mae: 0.2643\n",
            "\n",
            "--- Ã‰poque 175/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.0319 - policy_categorical_accuracy: 0.3901 - policy_loss: 2.8585 - value_loss: 0.1049 - value_mae: 0.2642\n",
            "Epoch 1: val_loss improved from 2.93189 to 2.91903, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 3.0315 - policy_categorical_accuracy: 0.3900 - policy_loss: 2.8582 - value_loss: 0.1049 - value_mae: 0.2642 - val_loss: 2.9190 - val_policy_categorical_accuracy: 0.4095 - val_policy_loss: 2.7435 - val_value_loss: 0.1041 - val_value_mae: 0.2626 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 176/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3019 - policy_categorical_accuracy: 0.3339 - policy_loss: 3.1298 - value_loss: 0.1035 - value_mae: 0.2615\n",
            "\n",
            "--- Ã‰poque 177/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2866 - policy_categorical_accuracy: 0.3282 - policy_loss: 3.1136 - value_loss: 0.1044 - value_mae: 0.2638\n",
            "\n",
            "--- Ã‰poque 178/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3251 - policy_categorical_accuracy: 0.3271 - policy_loss: 3.1535 - value_loss: 0.1032 - value_mae: 0.2610\n",
            "\n",
            "--- Ã‰poque 179/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.2992 - policy_categorical_accuracy: 0.3267 - policy_loss: 3.1272 - value_loss: 0.1037 - value_mae: 0.2623\n",
            "\n",
            "--- Ã‰poque 180/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.9910 - policy_categorical_accuracy: 0.3915 - policy_loss: 2.8179 - value_loss: 0.1047 - value_mae: 0.2627\n",
            "Epoch 1: val_loss improved from 2.91903 to 2.91023, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.9912 - policy_categorical_accuracy: 0.3915 - policy_loss: 2.8179 - value_loss: 0.1047 - value_mae: 0.2628 - val_loss: 2.9102 - val_policy_categorical_accuracy: 0.4116 - val_policy_loss: 2.7344 - val_value_loss: 0.1040 - val_value_mae: 0.2625 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 181/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2437 - policy_categorical_accuracy: 0.3432 - policy_loss: 3.0728 - value_loss: 0.1028 - value_mae: 0.2607\n",
            "\n",
            "--- Ã‰poque 182/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2943 - policy_categorical_accuracy: 0.3298 - policy_loss: 3.1222 - value_loss: 0.1040 - value_mae: 0.2633\n",
            "\n",
            "--- Ã‰poque 183/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2189 - policy_categorical_accuracy: 0.3546 - policy_loss: 3.0461 - value_loss: 0.1047 - value_mae: 0.2642\n",
            "\n",
            "--- Ã‰poque 184/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.2671 - policy_categorical_accuracy: 0.3397 - policy_loss: 3.0942 - value_loss: 0.1046 - value_mae: 0.2648\n",
            "\n",
            "--- Ã‰poque 185/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.9848 - policy_categorical_accuracy: 0.3936 - policy_loss: 2.8121 - value_loss: 0.1045 - value_mae: 0.2633\n",
            "Epoch 1: val_loss improved from 2.91023 to 2.89749, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.9850 - policy_categorical_accuracy: 0.3936 - policy_loss: 2.8122 - value_loss: 0.1045 - value_mae: 0.2633 - val_loss: 2.8975 - val_policy_categorical_accuracy: 0.4169 - val_policy_loss: 2.7206 - val_value_loss: 0.1051 - val_value_mae: 0.2632 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 186/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2814 - policy_categorical_accuracy: 0.3293 - policy_loss: 3.1101 - value_loss: 0.1030 - value_mae: 0.2604\n",
            "\n",
            "--- Ã‰poque 187/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2721 - policy_categorical_accuracy: 0.3280 - policy_loss: 3.0997 - value_loss: 0.1042 - value_mae: 0.2630\n",
            "\n",
            "--- Ã‰poque 188/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2197 - policy_categorical_accuracy: 0.3468 - policy_loss: 3.0501 - value_loss: 0.1015 - value_mae: 0.2597\n",
            "\n",
            "--- Ã‰poque 189/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.2754 - policy_categorical_accuracy: 0.3371 - policy_loss: 3.1027 - value_loss: 0.1048 - value_mae: 0.2631\n",
            "\n",
            "--- Ã‰poque 190/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.9858 - policy_categorical_accuracy: 0.3955 - policy_loss: 2.8149 - value_loss: 0.1030 - value_mae: 0.2615\n",
            "Epoch 1: val_loss improved from 2.89749 to 2.88856, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.9857 - policy_categorical_accuracy: 0.3955 - policy_loss: 2.8147 - value_loss: 0.1030 - value_mae: 0.2616 - val_loss: 2.8886 - val_policy_categorical_accuracy: 0.4152 - val_policy_loss: 2.7130 - val_value_loss: 0.1037 - val_value_mae: 0.2621 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 191/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2808 - policy_categorical_accuracy: 0.3351 - policy_loss: 3.1101 - value_loss: 0.1028 - value_mae: 0.2618\n",
            "\n",
            "--- Ã‰poque 192/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2427 - policy_categorical_accuracy: 0.3370 - policy_loss: 3.0722 - value_loss: 0.1027 - value_mae: 0.2596\n",
            "\n",
            "--- Ã‰poque 193/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2702 - policy_categorical_accuracy: 0.3370 - policy_loss: 3.0967 - value_loss: 0.1057 - value_mae: 0.2647\n",
            "\n",
            "--- Ã‰poque 194/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.2983 - policy_categorical_accuracy: 0.3239 - policy_loss: 3.1293 - value_loss: 0.1011 - value_mae: 0.2593\n",
            "\n",
            "--- Ã‰poque 195/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.9483 - policy_categorical_accuracy: 0.3989 - policy_loss: 2.7782 - value_loss: 0.1023 - value_mae: 0.2600\n",
            "Epoch 1: val_loss improved from 2.88856 to 2.87800, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.9491 - policy_categorical_accuracy: 0.3989 - policy_loss: 2.7791 - value_loss: 0.1024 - value_mae: 0.2601 - val_loss: 2.8780 - val_policy_categorical_accuracy: 0.4180 - val_policy_loss: 2.7035 - val_value_loss: 0.1037 - val_value_mae: 0.2617 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 196/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2815 - policy_categorical_accuracy: 0.3299 - policy_loss: 3.1100 - value_loss: 0.1039 - value_mae: 0.2617\n",
            "\n",
            "--- Ã‰poque 197/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.2540 - policy_categorical_accuracy: 0.3388 - policy_loss: 3.0835 - value_loss: 0.1024 - value_mae: 0.2590\n",
            "\n",
            "--- Ã‰poque 198/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2447 - policy_categorical_accuracy: 0.3419 - policy_loss: 3.0738 - value_loss: 0.1031 - value_mae: 0.2615\n",
            "\n",
            "--- Ã‰poque 199/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2830 - policy_categorical_accuracy: 0.3338 - policy_loss: 3.1111 - value_loss: 0.1044 - value_mae: 0.2641\n",
            "\n",
            "--- Ã‰poque 200/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.9606 - policy_categorical_accuracy: 0.4045 - policy_loss: 2.7892 - value_loss: 0.1038 - value_mae: 0.2618\n",
            "Epoch 1: val_loss improved from 2.87800 to 2.86835, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.9606 - policy_categorical_accuracy: 0.4043 - policy_loss: 2.7893 - value_loss: 0.1038 - value_mae: 0.2618 - val_loss: 2.8684 - val_policy_categorical_accuracy: 0.4179 - val_policy_loss: 2.6943 - val_value_loss: 0.1034 - val_value_mae: 0.2620 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 201/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2586 - policy_categorical_accuracy: 0.3316 - policy_loss: 3.0886 - value_loss: 0.1023 - value_mae: 0.2584\n",
            "\n",
            "--- Ã‰poque 202/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.2336 - policy_categorical_accuracy: 0.3362 - policy_loss: 3.0632 - value_loss: 0.1029 - value_mae: 0.2614\n",
            "\n",
            "--- Ã‰poque 203/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2689 - policy_categorical_accuracy: 0.3385 - policy_loss: 3.0965 - value_loss: 0.1050 - value_mae: 0.2631\n",
            "\n",
            "--- Ã‰poque 204/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.2117 - policy_categorical_accuracy: 0.3474 - policy_loss: 3.0397 - value_loss: 0.1048 - value_mae: 0.2642\n",
            "\n",
            "--- Ã‰poque 205/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.9470 - policy_categorical_accuracy: 0.4048 - policy_loss: 2.7755 - value_loss: 0.1041 - value_mae: 0.2626\n",
            "Epoch 1: val_loss improved from 2.86835 to 2.85643, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 2.9471 - policy_categorical_accuracy: 0.4046 - policy_loss: 2.7757 - value_loss: 0.1041 - value_mae: 0.2626 - val_loss: 2.8564 - val_policy_categorical_accuracy: 0.4252 - val_policy_loss: 2.6814 - val_value_loss: 0.1039 - val_value_mae: 0.2619 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 206/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2613 - policy_categorical_accuracy: 0.3446 - policy_loss: 3.0930 - value_loss: 0.1008 - value_mae: 0.2572\n",
            "\n",
            "--- Ã‰poque 207/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.2576 - policy_categorical_accuracy: 0.3341 - policy_loss: 3.0849 - value_loss: 0.1051 - value_mae: 0.2634\n",
            "\n",
            "--- Ã‰poque 208/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2783 - policy_categorical_accuracy: 0.3378 - policy_loss: 3.1083 - value_loss: 0.1026 - value_mae: 0.2606\n",
            "\n",
            "--- Ã‰poque 209/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2279 - policy_categorical_accuracy: 0.3490 - policy_loss: 3.0559 - value_loss: 0.1047 - value_mae: 0.2637\n",
            "\n",
            "--- Ã‰poque 210/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.9702 - policy_categorical_accuracy: 0.3986 - policy_loss: 2.7991 - value_loss: 0.1039 - value_mae: 0.2613\n",
            "Epoch 1: val_loss improved from 2.85643 to 2.84312, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.9692 - policy_categorical_accuracy: 0.3989 - policy_loss: 2.7980 - value_loss: 0.1039 - value_mae: 0.2614 - val_loss: 2.8431 - val_policy_categorical_accuracy: 0.4268 - val_policy_loss: 2.6694 - val_value_loss: 0.1031 - val_value_mae: 0.2608 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 211/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2242 - policy_categorical_accuracy: 0.3397 - policy_loss: 3.0538 - value_loss: 0.1033 - value_mae: 0.2621\n",
            "\n",
            "--- Ã‰poque 212/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2383 - policy_categorical_accuracy: 0.3437 - policy_loss: 3.0682 - value_loss: 0.1028 - value_mae: 0.2593\n",
            "\n",
            "--- Ã‰poque 213/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2145 - policy_categorical_accuracy: 0.3388 - policy_loss: 3.0420 - value_loss: 0.1055 - value_mae: 0.2654\n",
            "\n",
            "--- Ã‰poque 214/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2508 - policy_categorical_accuracy: 0.3407 - policy_loss: 3.0821 - value_loss: 0.1014 - value_mae: 0.2580\n",
            "\n",
            "--- Ã‰poque 215/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.9407 - policy_categorical_accuracy: 0.4051 - policy_loss: 2.7686 - value_loss: 0.1050 - value_mae: 0.2636\n",
            "Epoch 1: val_loss improved from 2.84312 to 2.83668, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.9403 - policy_categorical_accuracy: 0.4051 - policy_loss: 2.7682 - value_loss: 0.1049 - value_mae: 0.2636 - val_loss: 2.8367 - val_policy_categorical_accuracy: 0.4261 - val_policy_loss: 2.6634 - val_value_loss: 0.1031 - val_value_mae: 0.2606 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 216/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2328 - policy_categorical_accuracy: 0.3417 - policy_loss: 3.0600 - value_loss: 0.1058 - value_mae: 0.2640\n",
            "\n",
            "--- Ã‰poque 217/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2177 - policy_categorical_accuracy: 0.3477 - policy_loss: 3.0486 - value_loss: 0.1021 - value_mae: 0.2604\n",
            "\n",
            "--- Ã‰poque 218/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2297 - policy_categorical_accuracy: 0.3307 - policy_loss: 3.0598 - value_loss: 0.1028 - value_mae: 0.2602\n",
            "\n",
            "--- Ã‰poque 219/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2534 - policy_categorical_accuracy: 0.3374 - policy_loss: 3.0834 - value_loss: 0.1030 - value_mae: 0.2608\n",
            "\n",
            "--- Ã‰poque 220/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.9607 - policy_categorical_accuracy: 0.3943 - policy_loss: 2.7890 - value_loss: 0.1048 - value_mae: 0.2635\n",
            "Epoch 1: val_loss improved from 2.83668 to 2.82735, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.9599 - policy_categorical_accuracy: 0.3946 - policy_loss: 2.7884 - value_loss: 0.1047 - value_mae: 0.2634 - val_loss: 2.8273 - val_policy_categorical_accuracy: 0.4299 - val_policy_loss: 2.6542 - val_value_loss: 0.1029 - val_value_mae: 0.2604 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 221/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2635 - policy_categorical_accuracy: 0.3359 - policy_loss: 3.0930 - value_loss: 0.1036 - value_mae: 0.2611\n",
            "\n",
            "--- Ã‰poque 222/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2304 - policy_categorical_accuracy: 0.3466 - policy_loss: 3.0621 - value_loss: 0.1014 - value_mae: 0.2580\n",
            "\n",
            "--- Ã‰poque 223/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2695 - policy_categorical_accuracy: 0.3210 - policy_loss: 3.1018 - value_loss: 0.1008 - value_mae: 0.2578\n",
            "\n",
            "--- Ã‰poque 224/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1982 - policy_categorical_accuracy: 0.3430 - policy_loss: 3.0270 - value_loss: 0.1045 - value_mae: 0.2632\n",
            "\n",
            "--- Ã‰poque 225/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.9308 - policy_categorical_accuracy: 0.4051 - policy_loss: 2.7589 - value_loss: 0.1051 - value_mae: 0.2640\n",
            "Epoch 1: val_loss improved from 2.82735 to 2.82019, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 2.9301 - policy_categorical_accuracy: 0.4053 - policy_loss: 2.7583 - value_loss: 0.1051 - value_mae: 0.2639 - val_loss: 2.8202 - val_policy_categorical_accuracy: 0.4302 - val_policy_loss: 2.6465 - val_value_loss: 0.1034 - val_value_mae: 0.2608 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 226/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2201 - policy_categorical_accuracy: 0.3442 - policy_loss: 3.0469 - value_loss: 0.1063 - value_mae: 0.2650\n",
            "\n",
            "--- Ã‰poque 227/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2585 - policy_categorical_accuracy: 0.3295 - policy_loss: 3.0864 - value_loss: 0.1054 - value_mae: 0.2638\n",
            "\n",
            "--- Ã‰poque 228/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2134 - policy_categorical_accuracy: 0.3419 - policy_loss: 3.0457 - value_loss: 0.1010 - value_mae: 0.2560\n",
            "\n",
            "--- Ã‰poque 229/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2106 - policy_categorical_accuracy: 0.3436 - policy_loss: 3.0418 - value_loss: 0.1021 - value_mae: 0.2596\n",
            "\n",
            "--- Ã‰poque 230/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.9233 - policy_categorical_accuracy: 0.4045 - policy_loss: 2.7514 - value_loss: 0.1052 - value_mae: 0.2640\n",
            "Epoch 1: val_loss improved from 2.82019 to 2.81262, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.9225 - policy_categorical_accuracy: 0.4047 - policy_loss: 2.7506 - value_loss: 0.1052 - value_mae: 0.2639 - val_loss: 2.8126 - val_policy_categorical_accuracy: 0.4298 - val_policy_loss: 2.6399 - val_value_loss: 0.1027 - val_value_mae: 0.2604 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 231/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2689 - policy_categorical_accuracy: 0.3326 - policy_loss: 3.1015 - value_loss: 0.1008 - value_mae: 0.2558\n",
            "\n",
            "--- Ã‰poque 232/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2112 - policy_categorical_accuracy: 0.3427 - policy_loss: 3.0399 - value_loss: 0.1047 - value_mae: 0.2637\n",
            "\n",
            "--- Ã‰poque 233/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2555 - policy_categorical_accuracy: 0.3364 - policy_loss: 3.0870 - value_loss: 0.1020 - value_mae: 0.2597\n",
            "\n",
            "--- Ã‰poque 234/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2373 - policy_categorical_accuracy: 0.3398 - policy_loss: 3.0692 - value_loss: 0.1015 - value_mae: 0.2576\n",
            "\n",
            "--- Ã‰poque 235/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.9166 - policy_categorical_accuracy: 0.4093 - policy_loss: 2.7457 - value_loss: 0.1044 - value_mae: 0.2630\n",
            "Epoch 1: val_loss improved from 2.81262 to 2.79682, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.9160 - policy_categorical_accuracy: 0.4093 - policy_loss: 2.7452 - value_loss: 0.1044 - value_mae: 0.2629 - val_loss: 2.7968 - val_policy_categorical_accuracy: 0.4333 - val_policy_loss: 2.6245 - val_value_loss: 0.1026 - val_value_mae: 0.2597 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 236/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2129 - policy_categorical_accuracy: 0.3441 - policy_loss: 3.0431 - value_loss: 0.1035 - value_mae: 0.2614\n",
            "\n",
            "--- Ã‰poque 237/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2405 - policy_categorical_accuracy: 0.3357 - policy_loss: 3.0729 - value_loss: 0.1014 - value_mae: 0.2595\n",
            "\n",
            "--- Ã‰poque 238/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2341 - policy_categorical_accuracy: 0.3422 - policy_loss: 3.0659 - value_loss: 0.1018 - value_mae: 0.2580\n",
            "\n",
            "--- Ã‰poque 239/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2287 - policy_categorical_accuracy: 0.3455 - policy_loss: 3.0609 - value_loss: 0.1015 - value_mae: 0.2579\n",
            "\n",
            "--- Ã‰poque 240/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.8911 - policy_categorical_accuracy: 0.4167 - policy_loss: 2.7217 - value_loss: 0.1031 - value_mae: 0.2601\n",
            "Epoch 1: val_loss improved from 2.79682 to 2.79284, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.8909 - policy_categorical_accuracy: 0.4166 - policy_loss: 2.7216 - value_loss: 0.1031 - value_mae: 0.2602 - val_loss: 2.7928 - val_policy_categorical_accuracy: 0.4351 - val_policy_loss: 2.6210 - val_value_loss: 0.1028 - val_value_mae: 0.2604 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 241/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1992 - policy_categorical_accuracy: 0.3465 - policy_loss: 3.0345 - value_loss: 0.0986 - value_mae: 0.2538\n",
            "\n",
            "--- Ã‰poque 242/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2341 - policy_categorical_accuracy: 0.3387 - policy_loss: 3.0636 - value_loss: 0.1041 - value_mae: 0.2628\n",
            "\n",
            "--- Ã‰poque 243/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2358 - policy_categorical_accuracy: 0.3333 - policy_loss: 3.0666 - value_loss: 0.1029 - value_mae: 0.2601\n",
            "\n",
            "--- Ã‰poque 244/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2402 - policy_categorical_accuracy: 0.3376 - policy_loss: 3.0734 - value_loss: 0.1006 - value_mae: 0.2565\n",
            "\n",
            "--- Ã‰poque 245/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.8708 - policy_categorical_accuracy: 0.4156 - policy_loss: 2.7022 - value_loss: 0.1025 - value_mae: 0.2602\n",
            "Epoch 1: val_loss improved from 2.79284 to 2.78769, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 2.8710 - policy_categorical_accuracy: 0.4155 - policy_loss: 2.7024 - value_loss: 0.1025 - value_mae: 0.2602 - val_loss: 2.7877 - val_policy_categorical_accuracy: 0.4367 - val_policy_loss: 2.6161 - val_value_loss: 0.1024 - val_value_mae: 0.2600 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 246/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2525 - policy_categorical_accuracy: 0.3399 - policy_loss: 3.0864 - value_loss: 0.0999 - value_mae: 0.2549\n",
            "\n",
            "--- Ã‰poque 247/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2184 - policy_categorical_accuracy: 0.3352 - policy_loss: 3.0487 - value_loss: 0.1036 - value_mae: 0.2605\n",
            "\n",
            "--- Ã‰poque 248/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1862 - policy_categorical_accuracy: 0.3544 - policy_loss: 3.0176 - value_loss: 0.1025 - value_mae: 0.2601\n",
            "\n",
            "--- Ã‰poque 249/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1941 - policy_categorical_accuracy: 0.3537 - policy_loss: 3.0260 - value_loss: 0.1021 - value_mae: 0.2595\n",
            "\n",
            "--- Ã‰poque 250/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.8690 - policy_categorical_accuracy: 0.4152 - policy_loss: 2.6993 - value_loss: 0.1037 - value_mae: 0.2616\n",
            "Epoch 1: val_loss improved from 2.78769 to 2.77308, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.8691 - policy_categorical_accuracy: 0.4152 - policy_loss: 2.6995 - value_loss: 0.1037 - value_mae: 0.2615 - val_loss: 2.7731 - val_policy_categorical_accuracy: 0.4403 - val_policy_loss: 2.6017 - val_value_loss: 0.1023 - val_value_mae: 0.2598 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 251/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1919 - policy_categorical_accuracy: 0.3520 - policy_loss: 3.0205 - value_loss: 0.1053 - value_mae: 0.2613\n",
            "\n",
            "--- Ã‰poque 252/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2268 - policy_categorical_accuracy: 0.3420 - policy_loss: 3.0587 - value_loss: 0.1020 - value_mae: 0.2589\n",
            "\n",
            "--- Ã‰poque 253/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2128 - policy_categorical_accuracy: 0.3388 - policy_loss: 3.0417 - value_loss: 0.1050 - value_mae: 0.2643\n",
            "\n",
            "--- Ã‰poque 254/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1930 - policy_categorical_accuracy: 0.3461 - policy_loss: 3.0262 - value_loss: 0.1010 - value_mae: 0.2569\n",
            "\n",
            "--- Ã‰poque 255/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.8732 - policy_categorical_accuracy: 0.4124 - policy_loss: 2.7049 - value_loss: 0.1025 - value_mae: 0.2595\n",
            "Epoch 1: val_loss improved from 2.77308 to 2.76790, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.8729 - policy_categorical_accuracy: 0.4125 - policy_loss: 2.7045 - value_loss: 0.1025 - value_mae: 0.2595 - val_loss: 2.7679 - val_policy_categorical_accuracy: 0.4406 - val_policy_loss: 2.5966 - val_value_loss: 0.1028 - val_value_mae: 0.2602 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 256/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2096 - policy_categorical_accuracy: 0.3408 - policy_loss: 3.0414 - value_loss: 0.1024 - value_mae: 0.2602\n",
            "\n",
            "--- Ã‰poque 257/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1968 - policy_categorical_accuracy: 0.3529 - policy_loss: 3.0249 - value_loss: 0.1059 - value_mae: 0.2650\n",
            "\n",
            "--- Ã‰poque 258/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2000 - policy_categorical_accuracy: 0.3424 - policy_loss: 3.0352 - value_loss: 0.0989 - value_mae: 0.2546\n",
            "\n",
            "--- Ã‰poque 259/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2264 - policy_categorical_accuracy: 0.3457 - policy_loss: 3.0614 - value_loss: 0.0991 - value_mae: 0.2545\n",
            "\n",
            "--- Ã‰poque 260/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.8518 - policy_categorical_accuracy: 0.4225 - policy_loss: 2.6838 - value_loss: 0.1023 - value_mae: 0.2591\n",
            "Epoch 1: val_loss improved from 2.76790 to 2.75672, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.8519 - policy_categorical_accuracy: 0.4224 - policy_loss: 2.6840 - value_loss: 0.1023 - value_mae: 0.2591 - val_loss: 2.7567 - val_policy_categorical_accuracy: 0.4432 - val_policy_loss: 2.5861 - val_value_loss: 0.1024 - val_value_mae: 0.2593 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 261/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1638 - policy_categorical_accuracy: 0.3577 - policy_loss: 2.9940 - value_loss: 0.1042 - value_mae: 0.2618\n",
            "\n",
            "--- Ã‰poque 262/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1706 - policy_categorical_accuracy: 0.3438 - policy_loss: 3.0022 - value_loss: 0.1027 - value_mae: 0.2589\n",
            "\n",
            "--- Ã‰poque 263/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2366 - policy_categorical_accuracy: 0.3349 - policy_loss: 3.0658 - value_loss: 0.1050 - value_mae: 0.2636\n",
            "\n",
            "--- Ã‰poque 264/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1822 - policy_categorical_accuracy: 0.3448 - policy_loss: 3.0146 - value_loss: 0.1022 - value_mae: 0.2593\n",
            "\n",
            "--- Ã‰poque 265/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.8515 - policy_categorical_accuracy: 0.4231 - policy_loss: 2.6825 - value_loss: 0.1034 - value_mae: 0.2612\n",
            "Epoch 1: val_loss improved from 2.75672 to 2.75442, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.8515 - policy_categorical_accuracy: 0.4229 - policy_loss: 2.6826 - value_loss: 0.1034 - value_mae: 0.2612 - val_loss: 2.7544 - val_policy_categorical_accuracy: 0.4431 - val_policy_loss: 2.5843 - val_value_loss: 0.1023 - val_value_mae: 0.2598 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 266/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1770 - policy_categorical_accuracy: 0.3484 - policy_loss: 3.0092 - value_loss: 0.1020 - value_mae: 0.2598\n",
            "\n",
            "--- Ã‰poque 267/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1471 - policy_categorical_accuracy: 0.3598 - policy_loss: 2.9768 - value_loss: 0.1048 - value_mae: 0.2624\n",
            "\n",
            "--- Ã‰poque 268/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1731 - policy_categorical_accuracy: 0.3449 - policy_loss: 3.0062 - value_loss: 0.1014 - value_mae: 0.2573\n",
            "\n",
            "--- Ã‰poque 269/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2255 - policy_categorical_accuracy: 0.3395 - policy_loss: 3.0575 - value_loss: 0.1027 - value_mae: 0.2585\n",
            "\n",
            "--- Ã‰poque 270/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.8421 - policy_categorical_accuracy: 0.4248 - policy_loss: 2.6737 - value_loss: 0.1030 - value_mae: 0.2601\n",
            "Epoch 1: val_loss improved from 2.75442 to 2.74441, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.8421 - policy_categorical_accuracy: 0.4247 - policy_loss: 2.6735 - value_loss: 0.1030 - value_mae: 0.2602 - val_loss: 2.7444 - val_policy_categorical_accuracy: 0.4478 - val_policy_loss: 2.5742 - val_value_loss: 0.1024 - val_value_mae: 0.2592 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 271/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2008 - policy_categorical_accuracy: 0.3513 - policy_loss: 3.0343 - value_loss: 0.1008 - value_mae: 0.2570\n",
            "\n",
            "--- Ã‰poque 272/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1570 - policy_categorical_accuracy: 0.3562 - policy_loss: 2.9896 - value_loss: 0.1021 - value_mae: 0.2582\n",
            "\n",
            "--- Ã‰poque 273/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2153 - policy_categorical_accuracy: 0.3356 - policy_loss: 3.0481 - value_loss: 0.1020 - value_mae: 0.2601\n",
            "\n",
            "--- Ã‰poque 274/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1831 - policy_categorical_accuracy: 0.3507 - policy_loss: 3.0150 - value_loss: 0.1026 - value_mae: 0.2604\n",
            "\n",
            "--- Ã‰poque 275/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.8509 - policy_categorical_accuracy: 0.4167 - policy_loss: 2.6833 - value_loss: 0.1023 - value_mae: 0.2587\n",
            "Epoch 1: val_loss improved from 2.74441 to 2.73939, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 2.8501 - policy_categorical_accuracy: 0.4169 - policy_loss: 2.6828 - value_loss: 0.1023 - value_mae: 0.2587 - val_loss: 2.7394 - val_policy_categorical_accuracy: 0.4482 - val_policy_loss: 2.5696 - val_value_loss: 0.1023 - val_value_mae: 0.2593 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 276/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2120 - policy_categorical_accuracy: 0.3365 - policy_loss: 3.0427 - value_loss: 0.1041 - value_mae: 0.2624\n",
            "\n",
            "--- Ã‰poque 277/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2147 - policy_categorical_accuracy: 0.3399 - policy_loss: 3.0487 - value_loss: 0.1008 - value_mae: 0.2559\n",
            "\n",
            "--- Ã‰poque 278/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1977 - policy_categorical_accuracy: 0.3448 - policy_loss: 3.0291 - value_loss: 0.1033 - value_mae: 0.2599\n",
            "\n",
            "--- Ã‰poque 279/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1715 - policy_categorical_accuracy: 0.3460 - policy_loss: 3.0077 - value_loss: 0.0986 - value_mae: 0.2547\n",
            "\n",
            "--- Ã‰poque 280/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.8048 - policy_categorical_accuracy: 0.4375 - policy_loss: 2.6383 - value_loss: 0.1013 - value_mae: 0.2578\n",
            "Epoch 1: val_loss improved from 2.73939 to 2.72917, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.8058 - policy_categorical_accuracy: 0.4369 - policy_loss: 2.6391 - value_loss: 0.1013 - value_mae: 0.2578 - val_loss: 2.7292 - val_policy_categorical_accuracy: 0.4488 - val_policy_loss: 2.5593 - val_value_loss: 0.1021 - val_value_mae: 0.2590 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 281/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1678 - policy_categorical_accuracy: 0.3540 - policy_loss: 3.0002 - value_loss: 0.1025 - value_mae: 0.2601\n",
            "\n",
            "--- Ã‰poque 282/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2013 - policy_categorical_accuracy: 0.3508 - policy_loss: 3.0334 - value_loss: 0.1026 - value_mae: 0.2598\n",
            "\n",
            "--- Ã‰poque 283/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2194 - policy_categorical_accuracy: 0.3444 - policy_loss: 3.0537 - value_loss: 0.1008 - value_mae: 0.2564\n",
            "\n",
            "--- Ã‰poque 284/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1969 - policy_categorical_accuracy: 0.3451 - policy_loss: 3.0306 - value_loss: 0.1012 - value_mae: 0.2570\n",
            "\n",
            "--- Ã‰poque 285/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.8290 - policy_categorical_accuracy: 0.4273 - policy_loss: 2.6610 - value_loss: 0.1030 - value_mae: 0.2604\n",
            "Epoch 1: val_loss improved from 2.72917 to 2.72738, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.8289 - policy_categorical_accuracy: 0.4272 - policy_loss: 2.6608 - value_loss: 0.1030 - value_mae: 0.2604 - val_loss: 2.7274 - val_policy_categorical_accuracy: 0.4505 - val_policy_loss: 2.5576 - val_value_loss: 0.1020 - val_value_mae: 0.2594 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 286/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1789 - policy_categorical_accuracy: 0.3507 - policy_loss: 3.0128 - value_loss: 0.1012 - value_mae: 0.2572\n",
            "\n",
            "--- Ã‰poque 287/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1877 - policy_categorical_accuracy: 0.3466 - policy_loss: 3.0211 - value_loss: 0.1016 - value_mae: 0.2562\n",
            "\n",
            "--- Ã‰poque 288/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2105 - policy_categorical_accuracy: 0.3420 - policy_loss: 3.0448 - value_loss: 0.1008 - value_mae: 0.2575\n",
            "\n",
            "--- Ã‰poque 289/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1704 - policy_categorical_accuracy: 0.3565 - policy_loss: 3.0029 - value_loss: 0.1025 - value_mae: 0.2593\n",
            "\n",
            "--- Ã‰poque 290/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.8147 - policy_categorical_accuracy: 0.4295 - policy_loss: 2.6471 - value_loss: 0.1027 - value_mae: 0.2600\n",
            "Epoch 1: val_loss improved from 2.72738 to 2.71827, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.8147 - policy_categorical_accuracy: 0.4294 - policy_loss: 2.6472 - value_loss: 0.1027 - value_mae: 0.2600 - val_loss: 2.7183 - val_policy_categorical_accuracy: 0.4487 - val_policy_loss: 2.5492 - val_value_loss: 0.1018 - val_value_mae: 0.2588 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 291/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1996 - policy_categorical_accuracy: 0.3490 - policy_loss: 3.0319 - value_loss: 0.1028 - value_mae: 0.2600\n",
            "\n",
            "--- Ã‰poque 292/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2308 - policy_categorical_accuracy: 0.3406 - policy_loss: 3.0608 - value_loss: 0.1052 - value_mae: 0.2630\n",
            "\n",
            "--- Ã‰poque 293/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1443 - policy_categorical_accuracy: 0.3517 - policy_loss: 2.9764 - value_loss: 0.1030 - value_mae: 0.2604\n",
            "\n",
            "--- Ã‰poque 294/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2114 - policy_categorical_accuracy: 0.3449 - policy_loss: 3.0466 - value_loss: 0.0999 - value_mae: 0.2554\n",
            "\n",
            "--- Ã‰poque 295/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.8179 - policy_categorical_accuracy: 0.4301 - policy_loss: 2.6509 - value_loss: 0.1023 - value_mae: 0.2597\n",
            "Epoch 1: val_loss improved from 2.71827 to 2.70338, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.8175 - policy_categorical_accuracy: 0.4302 - policy_loss: 2.6504 - value_loss: 0.1023 - value_mae: 0.2597 - val_loss: 2.7034 - val_policy_categorical_accuracy: 0.4527 - val_policy_loss: 2.5342 - val_value_loss: 0.1017 - val_value_mae: 0.2581 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 296/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2096 - policy_categorical_accuracy: 0.3459 - policy_loss: 3.0416 - value_loss: 0.1033 - value_mae: 0.2601\n",
            "\n",
            "--- Ã‰poque 297/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.2163 - policy_categorical_accuracy: 0.3402 - policy_loss: 3.0520 - value_loss: 0.0996 - value_mae: 0.2542\n",
            "\n",
            "--- Ã‰poque 298/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1732 - policy_categorical_accuracy: 0.3516 - policy_loss: 3.0038 - value_loss: 0.1046 - value_mae: 0.2641\n",
            "\n",
            "--- Ã‰poque 299/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1897 - policy_categorical_accuracy: 0.3425 - policy_loss: 3.0227 - value_loss: 0.1023 - value_mae: 0.2585\n",
            "\n",
            "--- Ã‰poque 300/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.7987 - policy_categorical_accuracy: 0.4281 - policy_loss: 2.6322 - value_loss: 0.1019 - value_mae: 0.2600\n",
            "Epoch 1: val_loss improved from 2.70338 to 2.69438, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.7987 - policy_categorical_accuracy: 0.4282 - policy_loss: 2.6322 - value_loss: 0.1019 - value_mae: 0.2600 - val_loss: 2.6944 - val_policy_categorical_accuracy: 0.4518 - val_policy_loss: 2.5256 - val_value_loss: 0.1017 - val_value_mae: 0.2581 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 301/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2024 - policy_categorical_accuracy: 0.3393 - policy_loss: 3.0373 - value_loss: 0.1007 - value_mae: 0.2571\n",
            "\n",
            "--- Ã‰poque 302/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1663 - policy_categorical_accuracy: 0.3522 - policy_loss: 2.9998 - value_loss: 0.1018 - value_mae: 0.2582\n",
            "\n",
            "--- Ã‰poque 303/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1939 - policy_categorical_accuracy: 0.3524 - policy_loss: 3.0261 - value_loss: 0.1032 - value_mae: 0.2595\n",
            "\n",
            "--- Ã‰poque 304/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1326 - policy_categorical_accuracy: 0.3555 - policy_loss: 2.9645 - value_loss: 0.1035 - value_mae: 0.2611\n",
            "\n",
            "--- Ã‰poque 305/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.7816 - policy_categorical_accuracy: 0.4322 - policy_loss: 2.6170 - value_loss: 0.1002 - value_mae: 0.2563\n",
            "Epoch 1: val_loss improved from 2.69438 to 2.69116, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.7821 - policy_categorical_accuracy: 0.4321 - policy_loss: 2.6173 - value_loss: 0.1002 - value_mae: 0.2564 - val_loss: 2.6912 - val_policy_categorical_accuracy: 0.4550 - val_policy_loss: 2.5223 - val_value_loss: 0.1012 - val_value_mae: 0.2584 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 306/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1599 - policy_categorical_accuracy: 0.3499 - policy_loss: 2.9951 - value_loss: 0.1001 - value_mae: 0.2560\n",
            "\n",
            "--- Ã‰poque 307/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1559 - policy_categorical_accuracy: 0.3487 - policy_loss: 2.9882 - value_loss: 0.1033 - value_mae: 0.2623\n",
            "\n",
            "--- Ã‰poque 308/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2126 - policy_categorical_accuracy: 0.3418 - policy_loss: 3.0443 - value_loss: 0.1039 - value_mae: 0.2614\n",
            "\n",
            "--- Ã‰poque 309/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1752 - policy_categorical_accuracy: 0.3414 - policy_loss: 3.0100 - value_loss: 0.1009 - value_mae: 0.2578\n",
            "\n",
            "--- Ã‰poque 310/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.7854 - policy_categorical_accuracy: 0.4299 - policy_loss: 2.6181 - value_loss: 0.1029 - value_mae: 0.2590\n",
            "Epoch 1: val_loss improved from 2.69116 to 2.68319, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.7854 - policy_categorical_accuracy: 0.4300 - policy_loss: 2.6180 - value_loss: 0.1029 - value_mae: 0.2590 - val_loss: 2.6832 - val_policy_categorical_accuracy: 0.4587 - val_policy_loss: 2.5150 - val_value_loss: 0.1013 - val_value_mae: 0.2571 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 311/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1958 - policy_categorical_accuracy: 0.3440 - policy_loss: 3.0299 - value_loss: 0.1018 - value_mae: 0.2574\n",
            "\n",
            "--- Ã‰poque 312/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1259 - policy_categorical_accuracy: 0.3646 - policy_loss: 2.9600 - value_loss: 0.1014 - value_mae: 0.2590\n",
            "\n",
            "--- Ã‰poque 313/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1808 - policy_categorical_accuracy: 0.3421 - policy_loss: 3.0155 - value_loss: 0.1009 - value_mae: 0.2579\n",
            "\n",
            "--- Ã‰poque 314/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1650 - policy_categorical_accuracy: 0.3527 - policy_loss: 2.9995 - value_loss: 0.1011 - value_mae: 0.2573\n",
            "\n",
            "--- Ã‰poque 315/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.7688 - policy_categorical_accuracy: 0.4396 - policy_loss: 2.6008 - value_loss: 0.1037 - value_mae: 0.2610\n",
            "Epoch 1: val_loss improved from 2.68319 to 2.68100, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.7691 - policy_categorical_accuracy: 0.4394 - policy_loss: 2.6012 - value_loss: 0.1036 - value_mae: 0.2609 - val_loss: 2.6810 - val_policy_categorical_accuracy: 0.4576 - val_policy_loss: 2.5120 - val_value_loss: 0.1018 - val_value_mae: 0.2587 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 316/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2151 - policy_categorical_accuracy: 0.3452 - policy_loss: 3.0516 - value_loss: 0.0992 - value_mae: 0.2530\n",
            "\n",
            "--- Ã‰poque 317/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1552 - policy_categorical_accuracy: 0.3503 - policy_loss: 2.9890 - value_loss: 0.1018 - value_mae: 0.2571\n",
            "\n",
            "--- Ã‰poque 318/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1957 - policy_categorical_accuracy: 0.3403 - policy_loss: 3.0312 - value_loss: 0.1002 - value_mae: 0.2566\n",
            "\n",
            "--- Ã‰poque 319/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1956 - policy_categorical_accuracy: 0.3409 - policy_loss: 3.0280 - value_loss: 0.1035 - value_mae: 0.2619\n",
            "\n",
            "--- Ã‰poque 320/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.7807 - policy_categorical_accuracy: 0.4335 - policy_loss: 2.6155 - value_loss: 0.1010 - value_mae: 0.2560\n",
            "Epoch 1: val_loss improved from 2.68100 to 2.66995, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.7803 - policy_categorical_accuracy: 0.4336 - policy_loss: 2.6151 - value_loss: 0.1011 - value_mae: 0.2561 - val_loss: 2.6699 - val_policy_categorical_accuracy: 0.4587 - val_policy_loss: 2.5021 - val_value_loss: 0.1009 - val_value_mae: 0.2575 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 321/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1381 - policy_categorical_accuracy: 0.3534 - policy_loss: 2.9731 - value_loss: 0.1009 - value_mae: 0.2572\n",
            "\n",
            "--- Ã‰poque 322/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1752 - policy_categorical_accuracy: 0.3496 - policy_loss: 3.0127 - value_loss: 0.0984 - value_mae: 0.2529\n",
            "\n",
            "--- Ã‰poque 323/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1568 - policy_categorical_accuracy: 0.3587 - policy_loss: 2.9932 - value_loss: 0.0993 - value_mae: 0.2551\n",
            "\n",
            "--- Ã‰poque 324/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1412 - policy_categorical_accuracy: 0.3502 - policy_loss: 2.9764 - value_loss: 0.1007 - value_mae: 0.2564\n",
            "\n",
            "--- Ã‰poque 325/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.7786 - policy_categorical_accuracy: 0.4311 - policy_loss: 2.6128 - value_loss: 0.1017 - value_mae: 0.2591\n",
            "Epoch 1: val_loss improved from 2.66995 to 2.66905, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.7782 - policy_categorical_accuracy: 0.4312 - policy_loss: 2.6125 - value_loss: 0.1017 - value_mae: 0.2590 - val_loss: 2.6690 - val_policy_categorical_accuracy: 0.4588 - val_policy_loss: 2.4998 - val_value_loss: 0.1023 - val_value_mae: 0.2586 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 326/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1970 - policy_categorical_accuracy: 0.3450 - policy_loss: 3.0332 - value_loss: 0.0998 - value_mae: 0.2555\n",
            "\n",
            "--- Ã‰poque 327/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1745 - policy_categorical_accuracy: 0.3482 - policy_loss: 3.0065 - value_loss: 0.1040 - value_mae: 0.2609\n",
            "\n",
            "--- Ã‰poque 328/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1672 - policy_categorical_accuracy: 0.3505 - policy_loss: 3.0009 - value_loss: 0.1023 - value_mae: 0.2579\n",
            "\n",
            "--- Ã‰poque 329/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1986 - policy_categorical_accuracy: 0.3397 - policy_loss: 3.0352 - value_loss: 0.0997 - value_mae: 0.2566\n",
            "\n",
            "--- Ã‰poque 330/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.7796 - policy_categorical_accuracy: 0.4311 - policy_loss: 2.6132 - value_loss: 0.1025 - value_mae: 0.2595\n",
            "Epoch 1: val_loss improved from 2.66905 to 2.66431, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.7788 - policy_categorical_accuracy: 0.4313 - policy_loss: 2.6124 - value_loss: 0.1024 - value_mae: 0.2594 - val_loss: 2.6643 - val_policy_categorical_accuracy: 0.4589 - val_policy_loss: 2.4970 - val_value_loss: 0.1008 - val_value_mae: 0.2575 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 331/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1752 - policy_categorical_accuracy: 0.3422 - policy_loss: 3.0122 - value_loss: 0.0993 - value_mae: 0.2539\n",
            "\n",
            "--- Ã‰poque 332/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1411 - policy_categorical_accuracy: 0.3506 - policy_loss: 2.9765 - value_loss: 0.1007 - value_mae: 0.2553\n",
            "\n",
            "--- Ã‰poque 333/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1544 - policy_categorical_accuracy: 0.3508 - policy_loss: 2.9884 - value_loss: 0.1022 - value_mae: 0.2589\n",
            "\n",
            "--- Ã‰poque 334/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1825 - policy_categorical_accuracy: 0.3375 - policy_loss: 3.0182 - value_loss: 0.1005 - value_mae: 0.2553\n",
            "\n",
            "--- Ã‰poque 335/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.7588 - policy_categorical_accuracy: 0.4459 - policy_loss: 2.5945 - value_loss: 0.1006 - value_mae: 0.2570\n",
            "Epoch 1: val_loss improved from 2.66431 to 2.64980, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.7588 - policy_categorical_accuracy: 0.4459 - policy_loss: 2.5945 - value_loss: 0.1006 - value_mae: 0.2570 - val_loss: 2.6498 - val_policy_categorical_accuracy: 0.4656 - val_policy_loss: 2.4831 - val_value_loss: 0.1009 - val_value_mae: 0.2576 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 336/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2022 - policy_categorical_accuracy: 0.3427 - policy_loss: 3.0334 - value_loss: 0.1051 - value_mae: 0.2640\n",
            "\n",
            "--- Ã‰poque 337/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1662 - policy_categorical_accuracy: 0.3495 - policy_loss: 2.9988 - value_loss: 0.1036 - value_mae: 0.2610\n",
            "\n",
            "--- Ã‰poque 338/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1459 - policy_categorical_accuracy: 0.3551 - policy_loss: 2.9799 - value_loss: 0.1023 - value_mae: 0.2601\n",
            "\n",
            "--- Ã‰poque 339/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1677 - policy_categorical_accuracy: 0.3457 - policy_loss: 3.0016 - value_loss: 0.1025 - value_mae: 0.2591\n",
            "\n",
            "--- Ã‰poque 340/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.7240 - policy_categorical_accuracy: 0.4531 - policy_loss: 2.5584 - value_loss: 0.1019 - value_mae: 0.2573\n",
            "Epoch 1: val_loss did not improve from 2.64980\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.7249 - policy_categorical_accuracy: 0.4526 - policy_loss: 2.5593 - value_loss: 0.1018 - value_mae: 0.2573 - val_loss: 2.6538 - val_policy_categorical_accuracy: 0.4648 - val_policy_loss: 2.4868 - val_value_loss: 0.1007 - val_value_mae: 0.2572 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 341/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1331 - policy_categorical_accuracy: 0.3608 - policy_loss: 2.9651 - value_loss: 0.1044 - value_mae: 0.2601\n",
            "\n",
            "--- Ã‰poque 342/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1992 - policy_categorical_accuracy: 0.3461 - policy_loss: 3.0324 - value_loss: 0.1030 - value_mae: 0.2610\n",
            "\n",
            "--- Ã‰poque 343/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1513 - policy_categorical_accuracy: 0.3571 - policy_loss: 2.9896 - value_loss: 0.0981 - value_mae: 0.2530\n",
            "\n",
            "--- Ã‰poque 344/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1815 - policy_categorical_accuracy: 0.3443 - policy_loss: 3.0173 - value_loss: 0.1006 - value_mae: 0.2561\n",
            "\n",
            "--- Ã‰poque 345/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.7505 - policy_categorical_accuracy: 0.4378 - policy_loss: 2.5854 - value_loss: 0.1015 - value_mae: 0.2577\n",
            "Epoch 1: val_loss improved from 2.64980 to 2.64031, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.7502 - policy_categorical_accuracy: 0.4379 - policy_loss: 2.5852 - value_loss: 0.1015 - value_mae: 0.2577 - val_loss: 2.6403 - val_policy_categorical_accuracy: 0.4670 - val_policy_loss: 2.4735 - val_value_loss: 0.1010 - val_value_mae: 0.2570 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 346/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1410 - policy_categorical_accuracy: 0.3561 - policy_loss: 2.9781 - value_loss: 0.0997 - value_mae: 0.2547\n",
            "\n",
            "--- Ã‰poque 347/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1391 - policy_categorical_accuracy: 0.3545 - policy_loss: 2.9737 - value_loss: 0.1019 - value_mae: 0.2575\n",
            "\n",
            "--- Ã‰poque 348/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1587 - policy_categorical_accuracy: 0.3444 - policy_loss: 2.9946 - value_loss: 0.1006 - value_mae: 0.2569\n",
            "\n",
            "--- Ã‰poque 349/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1400 - policy_categorical_accuracy: 0.3591 - policy_loss: 2.9738 - value_loss: 0.1027 - value_mae: 0.2597\n",
            "\n",
            "--- Ã‰poque 350/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.7428 - policy_categorical_accuracy: 0.4406 - policy_loss: 2.5770 - value_loss: 0.1023 - value_mae: 0.2594\n",
            "Epoch 1: val_loss improved from 2.64031 to 2.63091, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 2.7424 - policy_categorical_accuracy: 0.4406 - policy_loss: 2.5766 - value_loss: 0.1023 - value_mae: 0.2593 - val_loss: 2.6309 - val_policy_categorical_accuracy: 0.4710 - val_policy_loss: 2.4649 - val_value_loss: 0.1003 - val_value_mae: 0.2562 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 351/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1622 - policy_categorical_accuracy: 0.3577 - policy_loss: 2.9964 - value_loss: 0.1024 - value_mae: 0.2583\n",
            "\n",
            "--- Ã‰poque 352/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1121 - policy_categorical_accuracy: 0.3570 - policy_loss: 2.9468 - value_loss: 0.1020 - value_mae: 0.2590\n",
            "\n",
            "--- Ã‰poque 353/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1337 - policy_categorical_accuracy: 0.3575 - policy_loss: 2.9713 - value_loss: 0.0990 - value_mae: 0.2551\n",
            "\n",
            "--- Ã‰poque 354/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1774 - policy_categorical_accuracy: 0.3428 - policy_loss: 3.0143 - value_loss: 0.0998 - value_mae: 0.2563\n",
            "\n",
            "--- Ã‰poque 355/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.7443 - policy_categorical_accuracy: 0.4385 - policy_loss: 2.5791 - value_loss: 0.1018 - value_mae: 0.2588\n",
            "Epoch 1: val_loss improved from 2.63091 to 2.61837, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.7437 - policy_categorical_accuracy: 0.4387 - policy_loss: 2.5787 - value_loss: 0.1017 - value_mae: 0.2588 - val_loss: 2.6184 - val_policy_categorical_accuracy: 0.4747 - val_policy_loss: 2.4526 - val_value_loss: 0.1004 - val_value_mae: 0.2567 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 356/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1571 - policy_categorical_accuracy: 0.3551 - policy_loss: 2.9953 - value_loss: 0.0985 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 357/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1490 - policy_categorical_accuracy: 0.3509 - policy_loss: 2.9829 - value_loss: 0.1028 - value_mae: 0.2589\n",
            "\n",
            "--- Ã‰poque 358/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1562 - policy_categorical_accuracy: 0.3445 - policy_loss: 2.9891 - value_loss: 0.1036 - value_mae: 0.2613\n",
            "\n",
            "--- Ã‰poque 359/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1091 - policy_categorical_accuracy: 0.3494 - policy_loss: 2.9465 - value_loss: 0.0996 - value_mae: 0.2558\n",
            "\n",
            "--- Ã‰poque 360/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.7548 - policy_categorical_accuracy: 0.4377 - policy_loss: 2.5913 - value_loss: 0.1002 - value_mae: 0.2562\n",
            "Epoch 1: val_loss improved from 2.61837 to 2.61733, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.7535 - policy_categorical_accuracy: 0.4381 - policy_loss: 2.5902 - value_loss: 0.1003 - value_mae: 0.2563 - val_loss: 2.6173 - val_policy_categorical_accuracy: 0.4738 - val_policy_loss: 2.4509 - val_value_loss: 0.1008 - val_value_mae: 0.2568 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 361/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1529 - policy_categorical_accuracy: 0.3536 - policy_loss: 2.9868 - value_loss: 0.1028 - value_mae: 0.2585\n",
            "\n",
            "--- Ã‰poque 362/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1871 - policy_categorical_accuracy: 0.3502 - policy_loss: 3.0191 - value_loss: 0.1048 - value_mae: 0.2627\n",
            "\n",
            "--- Ã‰poque 363/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1717 - policy_categorical_accuracy: 0.3494 - policy_loss: 3.0099 - value_loss: 0.0989 - value_mae: 0.2542\n",
            "\n",
            "--- Ã‰poque 364/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1468 - policy_categorical_accuracy: 0.3466 - policy_loss: 2.9830 - value_loss: 0.1007 - value_mae: 0.2560\n",
            "\n",
            "--- Ã‰poque 365/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.7111 - policy_categorical_accuracy: 0.4481 - policy_loss: 2.5489 - value_loss: 0.0991 - value_mae: 0.2534\n",
            "Epoch 1: val_loss improved from 2.61733 to 2.60779, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.7113 - policy_categorical_accuracy: 0.4480 - policy_loss: 2.5491 - value_loss: 0.0992 - value_mae: 0.2535 - val_loss: 2.6078 - val_policy_categorical_accuracy: 0.4781 - val_policy_loss: 2.4416 - val_value_loss: 0.1007 - val_value_mae: 0.2561 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 366/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1651 - policy_categorical_accuracy: 0.3550 - policy_loss: 3.0006 - value_loss: 0.1015 - value_mae: 0.2569\n",
            "\n",
            "--- Ã‰poque 367/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1630 - policy_categorical_accuracy: 0.3431 - policy_loss: 3.0000 - value_loss: 0.0998 - value_mae: 0.2537\n",
            "\n",
            "--- Ã‰poque 368/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1632 - policy_categorical_accuracy: 0.3473 - policy_loss: 3.0002 - value_loss: 0.1000 - value_mae: 0.2545\n",
            "\n",
            "--- Ã‰poque 369/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1269 - policy_categorical_accuracy: 0.3632 - policy_loss: 2.9614 - value_loss: 0.1025 - value_mae: 0.2575\n",
            "\n",
            "--- Ã‰poque 370/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.7509 - policy_categorical_accuracy: 0.4399 - policy_loss: 2.5863 - value_loss: 0.1016 - value_mae: 0.2568\n",
            "Epoch 1: val_loss improved from 2.60779 to 2.60756, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.7494 - policy_categorical_accuracy: 0.4402 - policy_loss: 2.5849 - value_loss: 0.1016 - value_mae: 0.2568 - val_loss: 2.6076 - val_policy_categorical_accuracy: 0.4757 - val_policy_loss: 2.4421 - val_value_loss: 0.1004 - val_value_mae: 0.2569 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 371/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1857 - policy_categorical_accuracy: 0.3483 - policy_loss: 3.0199 - value_loss: 0.1027 - value_mae: 0.2578\n",
            "\n",
            "--- Ã‰poque 372/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1447 - policy_categorical_accuracy: 0.3546 - policy_loss: 2.9815 - value_loss: 0.1003 - value_mae: 0.2565\n",
            "\n",
            "--- Ã‰poque 373/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1365 - policy_categorical_accuracy: 0.3582 - policy_loss: 2.9723 - value_loss: 0.1014 - value_mae: 0.2582\n",
            "\n",
            "--- Ã‰poque 374/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1495 - policy_categorical_accuracy: 0.3487 - policy_loss: 2.9826 - value_loss: 0.1038 - value_mae: 0.2609\n",
            "\n",
            "--- Ã‰poque 375/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.7234 - policy_categorical_accuracy: 0.4458 - policy_loss: 2.5625 - value_loss: 0.0980 - value_mae: 0.2521\n",
            "Epoch 1: val_loss improved from 2.60756 to 2.59719, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.7229 - policy_categorical_accuracy: 0.4459 - policy_loss: 2.5619 - value_loss: 0.0981 - value_mae: 0.2523 - val_loss: 2.5972 - val_policy_categorical_accuracy: 0.4776 - val_policy_loss: 2.4321 - val_value_loss: 0.1001 - val_value_mae: 0.2561 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 376/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1524 - policy_categorical_accuracy: 0.3460 - policy_loss: 2.9888 - value_loss: 0.1009 - value_mae: 0.2578\n",
            "\n",
            "--- Ã‰poque 377/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2052 - policy_categorical_accuracy: 0.3458 - policy_loss: 3.0426 - value_loss: 0.0996 - value_mae: 0.2535\n",
            "\n",
            "--- Ã‰poque 378/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1629 - policy_categorical_accuracy: 0.3501 - policy_loss: 3.0002 - value_loss: 0.0999 - value_mae: 0.2563\n",
            "\n",
            "--- Ã‰poque 379/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1404 - policy_categorical_accuracy: 0.3527 - policy_loss: 2.9776 - value_loss: 0.0998 - value_mae: 0.2549\n",
            "\n",
            "--- Ã‰poque 380/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.7088 - policy_categorical_accuracy: 0.4490 - policy_loss: 2.5440 - value_loss: 0.1019 - value_mae: 0.2590\n",
            "Epoch 1: val_loss improved from 2.59719 to 2.59321, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.7085 - policy_categorical_accuracy: 0.4489 - policy_loss: 2.5437 - value_loss: 0.1019 - value_mae: 0.2589 - val_loss: 2.5932 - val_policy_categorical_accuracy: 0.4782 - val_policy_loss: 2.4278 - val_value_loss: 0.1005 - val_value_mae: 0.2558 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 381/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1538 - policy_categorical_accuracy: 0.3459 - policy_loss: 2.9894 - value_loss: 0.1016 - value_mae: 0.2575\n",
            "\n",
            "--- Ã‰poque 382/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1533 - policy_categorical_accuracy: 0.3498 - policy_loss: 2.9868 - value_loss: 0.1038 - value_mae: 0.2607\n",
            "\n",
            "--- Ã‰poque 383/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1345 - policy_categorical_accuracy: 0.3538 - policy_loss: 2.9697 - value_loss: 0.1021 - value_mae: 0.2591\n",
            "\n",
            "--- Ã‰poque 384/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1203 - policy_categorical_accuracy: 0.3495 - policy_loss: 2.9587 - value_loss: 0.0988 - value_mae: 0.2540\n",
            "\n",
            "--- Ã‰poque 385/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.7286 - policy_categorical_accuracy: 0.4514 - policy_loss: 2.5656 - value_loss: 0.1003 - value_mae: 0.2554\n",
            "Epoch 1: val_loss improved from 2.59321 to 2.58334, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.7272 - policy_categorical_accuracy: 0.4516 - policy_loss: 2.5640 - value_loss: 0.1004 - value_mae: 0.2555 - val_loss: 2.5833 - val_policy_categorical_accuracy: 0.4804 - val_policy_loss: 2.4194 - val_value_loss: 0.0999 - val_value_mae: 0.2557 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 386/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1561 - policy_categorical_accuracy: 0.3475 - policy_loss: 2.9904 - value_loss: 0.1031 - value_mae: 0.2583\n",
            "\n",
            "--- Ã‰poque 387/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1586 - policy_categorical_accuracy: 0.3555 - policy_loss: 2.9979 - value_loss: 0.0982 - value_mae: 0.2528\n",
            "\n",
            "--- Ã‰poque 388/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1205 - policy_categorical_accuracy: 0.3595 - policy_loss: 2.9562 - value_loss: 0.1017 - value_mae: 0.2566\n",
            "\n",
            "--- Ã‰poque 389/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1544 - policy_categorical_accuracy: 0.3490 - policy_loss: 2.9925 - value_loss: 0.0994 - value_mae: 0.2545\n",
            "\n",
            "--- Ã‰poque 390/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6967 - policy_categorical_accuracy: 0.4556 - policy_loss: 2.5349 - value_loss: 0.0991 - value_mae: 0.2543\n",
            "Epoch 1: val_loss improved from 2.58334 to 2.57566, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.6963 - policy_categorical_accuracy: 0.4555 - policy_loss: 2.5346 - value_loss: 0.0992 - value_mae: 0.2543 - val_loss: 2.5757 - val_policy_categorical_accuracy: 0.4865 - val_policy_loss: 2.4098 - val_value_loss: 0.1007 - val_value_mae: 0.2573 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 391/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1505 - policy_categorical_accuracy: 0.3454 - policy_loss: 2.9879 - value_loss: 0.1000 - value_mae: 0.2557\n",
            "\n",
            "--- Ã‰poque 392/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1102 - policy_categorical_accuracy: 0.3535 - policy_loss: 2.9453 - value_loss: 0.1021 - value_mae: 0.2584\n",
            "\n",
            "--- Ã‰poque 393/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1363 - policy_categorical_accuracy: 0.3570 - policy_loss: 2.9735 - value_loss: 0.1005 - value_mae: 0.2545\n",
            "\n",
            "--- Ã‰poque 394/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1292 - policy_categorical_accuracy: 0.3628 - policy_loss: 2.9663 - value_loss: 0.1005 - value_mae: 0.2558\n",
            "\n",
            "--- Ã‰poque 395/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.7028 - policy_categorical_accuracy: 0.4514 - policy_loss: 2.5380 - value_loss: 0.1024 - value_mae: 0.2604\n",
            "Epoch 1: val_loss improved from 2.57566 to 2.57134, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.7021 - policy_categorical_accuracy: 0.4515 - policy_loss: 2.5374 - value_loss: 0.1024 - value_mae: 0.2603 - val_loss: 2.5713 - val_policy_categorical_accuracy: 0.4858 - val_policy_loss: 2.4071 - val_value_loss: 0.1001 - val_value_mae: 0.2565 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 396/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1631 - policy_categorical_accuracy: 0.3505 - policy_loss: 3.0019 - value_loss: 0.0988 - value_mae: 0.2545\n",
            "\n",
            "--- Ã‰poque 397/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1380 - policy_categorical_accuracy: 0.3506 - policy_loss: 2.9730 - value_loss: 0.1025 - value_mae: 0.2569\n",
            "\n",
            "--- Ã‰poque 398/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1166 - policy_categorical_accuracy: 0.3541 - policy_loss: 2.9568 - value_loss: 0.0974 - value_mae: 0.2514\n",
            "\n",
            "--- Ã‰poque 399/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1105 - policy_categorical_accuracy: 0.3584 - policy_loss: 2.9463 - value_loss: 0.1018 - value_mae: 0.2566\n",
            "\n",
            "--- Ã‰poque 400/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6691 - policy_categorical_accuracy: 0.4631 - policy_loss: 2.5066 - value_loss: 0.1001 - value_mae: 0.2551\n",
            "Epoch 1: val_loss did not improve from 2.57134\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 2.6695 - policy_categorical_accuracy: 0.4628 - policy_loss: 2.5072 - value_loss: 0.1001 - value_mae: 0.2551 - val_loss: 2.5757 - val_policy_categorical_accuracy: 0.4822 - val_policy_loss: 2.4112 - val_value_loss: 0.0998 - val_value_mae: 0.2558 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 401/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0751 - policy_categorical_accuracy: 0.3693 - policy_loss: 2.9157 - value_loss: 0.0969 - value_mae: 0.2504\n",
            "\n",
            "--- Ã‰poque 402/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1297 - policy_categorical_accuracy: 0.3483 - policy_loss: 2.9684 - value_loss: 0.0988 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 403/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1021 - policy_categorical_accuracy: 0.3563 - policy_loss: 2.9393 - value_loss: 0.1006 - value_mae: 0.2549\n",
            "\n",
            "--- Ã‰poque 404/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1398 - policy_categorical_accuracy: 0.3557 - policy_loss: 2.9777 - value_loss: 0.0997 - value_mae: 0.2538\n",
            "\n",
            "--- Ã‰poque 405/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.7124 - policy_categorical_accuracy: 0.4526 - policy_loss: 2.5512 - value_loss: 0.0989 - value_mae: 0.2545\n",
            "Epoch 1: val_loss improved from 2.57134 to 2.55833, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.7106 - policy_categorical_accuracy: 0.4528 - policy_loss: 2.5494 - value_loss: 0.0989 - value_mae: 0.2546 - val_loss: 2.5583 - val_policy_categorical_accuracy: 0.4864 - val_policy_loss: 2.3942 - val_value_loss: 0.0996 - val_value_mae: 0.2550 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 406/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1371 - policy_categorical_accuracy: 0.3550 - policy_loss: 2.9759 - value_loss: 0.0989 - value_mae: 0.2534\n",
            "\n",
            "--- Ã‰poque 407/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1364 - policy_categorical_accuracy: 0.3522 - policy_loss: 2.9737 - value_loss: 0.1003 - value_mae: 0.2538\n",
            "\n",
            "--- Ã‰poque 408/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1515 - policy_categorical_accuracy: 0.3570 - policy_loss: 2.9880 - value_loss: 0.1014 - value_mae: 0.2566\n",
            "\n",
            "--- Ã‰poque 409/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1791 - policy_categorical_accuracy: 0.3350 - policy_loss: 3.0160 - value_loss: 0.1009 - value_mae: 0.2553\n",
            "\n",
            "--- Ã‰poque 410/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6764 - policy_categorical_accuracy: 0.4587 - policy_loss: 2.5158 - value_loss: 0.0984 - value_mae: 0.2539\n",
            "Epoch 1: val_loss did not improve from 2.55833\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.6759 - policy_categorical_accuracy: 0.4586 - policy_loss: 2.5154 - value_loss: 0.0985 - value_mae: 0.2540 - val_loss: 2.5604 - val_policy_categorical_accuracy: 0.4868 - val_policy_loss: 2.3966 - val_value_loss: 0.0994 - val_value_mae: 0.2553 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 411/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1603 - policy_categorical_accuracy: 0.3504 - policy_loss: 2.9967 - value_loss: 0.1014 - value_mae: 0.2571\n",
            "\n",
            "--- Ã‰poque 412/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1274 - policy_categorical_accuracy: 0.3586 - policy_loss: 2.9648 - value_loss: 0.1004 - value_mae: 0.2559\n",
            "\n",
            "--- Ã‰poque 413/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1570 - policy_categorical_accuracy: 0.3488 - policy_loss: 2.9933 - value_loss: 0.1015 - value_mae: 0.2574\n",
            "\n",
            "--- Ã‰poque 414/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1055 - policy_categorical_accuracy: 0.3602 - policy_loss: 2.9438 - value_loss: 0.0997 - value_mae: 0.2535\n",
            "\n",
            "--- Ã‰poque 415/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6572 - policy_categorical_accuracy: 0.4621 - policy_loss: 2.4929 - value_loss: 0.1022 - value_mae: 0.2589\n",
            "Epoch 1: val_loss improved from 2.55833 to 2.55123, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.6572 - policy_categorical_accuracy: 0.4620 - policy_loss: 2.4931 - value_loss: 0.1021 - value_mae: 0.2588 - val_loss: 2.5512 - val_policy_categorical_accuracy: 0.4922 - val_policy_loss: 2.3878 - val_value_loss: 0.0994 - val_value_mae: 0.2550 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 416/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1834 - policy_categorical_accuracy: 0.3441 - policy_loss: 3.0222 - value_loss: 0.0990 - value_mae: 0.2545\n",
            "\n",
            "--- Ã‰poque 417/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1243 - policy_categorical_accuracy: 0.3518 - policy_loss: 2.9614 - value_loss: 0.1008 - value_mae: 0.2556\n",
            "\n",
            "--- Ã‰poque 418/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0812 - policy_categorical_accuracy: 0.3595 - policy_loss: 2.9192 - value_loss: 0.1001 - value_mae: 0.2554\n",
            "\n",
            "--- Ã‰poque 419/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.1221 - policy_categorical_accuracy: 0.3540 - policy_loss: 2.9633 - value_loss: 0.0969 - value_mae: 0.2500\n",
            "\n",
            "--- Ã‰poque 420/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.6553 - policy_categorical_accuracy: 0.4627 - policy_loss: 2.4933 - value_loss: 0.1000 - value_mae: 0.2549\n",
            "Epoch 1: val_loss improved from 2.55123 to 2.54351, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.6551 - policy_categorical_accuracy: 0.4627 - policy_loss: 2.4931 - value_loss: 0.1000 - value_mae: 0.2550 - val_loss: 2.5435 - val_policy_categorical_accuracy: 0.4877 - val_policy_loss: 2.3804 - val_value_loss: 0.0994 - val_value_mae: 0.2555 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 421/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1073 - policy_categorical_accuracy: 0.3621 - policy_loss: 2.9413 - value_loss: 0.1039 - value_mae: 0.2620\n",
            "\n",
            "--- Ã‰poque 422/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1332 - policy_categorical_accuracy: 0.3512 - policy_loss: 2.9693 - value_loss: 0.1019 - value_mae: 0.2581\n",
            "\n",
            "--- Ã‰poque 423/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1335 - policy_categorical_accuracy: 0.3565 - policy_loss: 2.9697 - value_loss: 0.1020 - value_mae: 0.2566\n",
            "\n",
            "--- Ã‰poque 424/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1294 - policy_categorical_accuracy: 0.3515 - policy_loss: 2.9680 - value_loss: 0.0995 - value_mae: 0.2539\n",
            "\n",
            "--- Ã‰poque 425/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.6545 - policy_categorical_accuracy: 0.4579 - policy_loss: 2.4939 - value_loss: 0.0987 - value_mae: 0.2535\n",
            "Epoch 1: val_loss improved from 2.54351 to 2.53647, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.6542 - policy_categorical_accuracy: 0.4581 - policy_loss: 2.4935 - value_loss: 0.0987 - value_mae: 0.2535 - val_loss: 2.5365 - val_policy_categorical_accuracy: 0.4947 - val_policy_loss: 2.3741 - val_value_loss: 0.0992 - val_value_mae: 0.2551 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 426/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1698 - policy_categorical_accuracy: 0.3456 - policy_loss: 3.0072 - value_loss: 0.1007 - value_mae: 0.2568\n",
            "\n",
            "--- Ã‰poque 427/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1552 - policy_categorical_accuracy: 0.3495 - policy_loss: 2.9938 - value_loss: 0.0994 - value_mae: 0.2551\n",
            "\n",
            "--- Ã‰poque 428/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1130 - policy_categorical_accuracy: 0.3541 - policy_loss: 2.9520 - value_loss: 0.0991 - value_mae: 0.2544\n",
            "\n",
            "--- Ã‰poque 429/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1104 - policy_categorical_accuracy: 0.3591 - policy_loss: 2.9531 - value_loss: 0.0957 - value_mae: 0.2493\n",
            "\n",
            "--- Ã‰poque 430/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6480 - policy_categorical_accuracy: 0.4641 - policy_loss: 2.4866 - value_loss: 0.0996 - value_mae: 0.2554\n",
            "Epoch 1: val_loss improved from 2.53647 to 2.53252, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.6477 - policy_categorical_accuracy: 0.4641 - policy_loss: 2.4866 - value_loss: 0.0996 - value_mae: 0.2554 - val_loss: 2.5325 - val_policy_categorical_accuracy: 0.4944 - val_policy_loss: 2.3690 - val_value_loss: 0.0997 - val_value_mae: 0.2548 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 431/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1269 - policy_categorical_accuracy: 0.3645 - policy_loss: 2.9688 - value_loss: 0.0963 - value_mae: 0.2504\n",
            "\n",
            "--- Ã‰poque 432/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1341 - policy_categorical_accuracy: 0.3567 - policy_loss: 2.9708 - value_loss: 0.1015 - value_mae: 0.2575\n",
            "\n",
            "--- Ã‰poque 433/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1109 - policy_categorical_accuracy: 0.3629 - policy_loss: 2.9487 - value_loss: 0.1005 - value_mae: 0.2554\n",
            "\n",
            "--- Ã‰poque 434/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1175 - policy_categorical_accuracy: 0.3572 - policy_loss: 2.9560 - value_loss: 0.0997 - value_mae: 0.2548\n",
            "\n",
            "--- Ã‰poque 435/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6310 - policy_categorical_accuracy: 0.4690 - policy_loss: 2.4704 - value_loss: 0.0989 - value_mae: 0.2524\n",
            "Epoch 1: val_loss improved from 2.53252 to 2.53166, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 2.6309 - policy_categorical_accuracy: 0.4690 - policy_loss: 2.4704 - value_loss: 0.0989 - value_mae: 0.2525 - val_loss: 2.5317 - val_policy_categorical_accuracy: 0.4938 - val_policy_loss: 2.3672 - val_value_loss: 0.0996 - val_value_mae: 0.2541 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 436/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1341 - policy_categorical_accuracy: 0.3566 - policy_loss: 2.9723 - value_loss: 0.1002 - value_mae: 0.2558\n",
            "\n",
            "--- Ã‰poque 437/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1148 - policy_categorical_accuracy: 0.3554 - policy_loss: 2.9548 - value_loss: 0.0983 - value_mae: 0.2524\n",
            "\n",
            "--- Ã‰poque 438/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1332 - policy_categorical_accuracy: 0.3480 - policy_loss: 2.9709 - value_loss: 0.1006 - value_mae: 0.2576\n",
            "\n",
            "--- Ã‰poque 439/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1263 - policy_categorical_accuracy: 0.3541 - policy_loss: 2.9685 - value_loss: 0.0961 - value_mae: 0.2486\n",
            "\n",
            "--- Ã‰poque 440/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6412 - policy_categorical_accuracy: 0.4676 - policy_loss: 2.4794 - value_loss: 0.1002 - value_mae: 0.2557\n",
            "Epoch 1: val_loss improved from 2.53166 to 2.52671, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 2.6410 - policy_categorical_accuracy: 0.4676 - policy_loss: 2.4791 - value_loss: 0.1002 - value_mae: 0.2557 - val_loss: 2.5267 - val_policy_categorical_accuracy: 0.4951 - val_policy_loss: 2.3638 - val_value_loss: 0.0992 - val_value_mae: 0.2545 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 441/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.1537 - policy_categorical_accuracy: 0.3489 - policy_loss: 2.9861 - value_loss: 0.1060 - value_mae: 0.2638\n",
            "\n",
            "--- Ã‰poque 442/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1095 - policy_categorical_accuracy: 0.3574 - policy_loss: 2.9482 - value_loss: 0.0996 - value_mae: 0.2544\n",
            "\n",
            "--- Ã‰poque 443/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1341 - policy_categorical_accuracy: 0.3576 - policy_loss: 2.9737 - value_loss: 0.0987 - value_mae: 0.2531\n",
            "\n",
            "--- Ã‰poque 444/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.1174 - policy_categorical_accuracy: 0.3596 - policy_loss: 2.9563 - value_loss: 0.0997 - value_mae: 0.2547\n",
            "\n",
            "--- Ã‰poque 445/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.6313 - policy_categorical_accuracy: 0.4705 - policy_loss: 2.4685 - value_loss: 0.1012 - value_mae: 0.2574\n",
            "Epoch 1: val_loss improved from 2.52671 to 2.51733, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.6312 - policy_categorical_accuracy: 0.4704 - policy_loss: 2.4685 - value_loss: 0.1012 - value_mae: 0.2573 - val_loss: 2.5173 - val_policy_categorical_accuracy: 0.4984 - val_policy_loss: 2.3521 - val_value_loss: 0.1016 - val_value_mae: 0.2551 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 446/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0985 - policy_categorical_accuracy: 0.3603 - policy_loss: 2.9399 - value_loss: 0.0971 - value_mae: 0.2502\n",
            "\n",
            "--- Ã‰poque 447/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1500 - policy_categorical_accuracy: 0.3548 - policy_loss: 2.9858 - value_loss: 0.1026 - value_mae: 0.2583\n",
            "\n",
            "--- Ã‰poque 448/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.0789 - policy_categorical_accuracy: 0.3681 - policy_loss: 2.9177 - value_loss: 0.0996 - value_mae: 0.2547\n",
            "\n",
            "--- Ã‰poque 449/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1084 - policy_categorical_accuracy: 0.3614 - policy_loss: 2.9448 - value_loss: 0.1020 - value_mae: 0.2572\n",
            "\n",
            "--- Ã‰poque 450/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.6293 - policy_categorical_accuracy: 0.4729 - policy_loss: 2.4687 - value_loss: 0.0992 - value_mae: 0.2541\n",
            "Epoch 1: val_loss did not improve from 2.51733\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.6289 - policy_categorical_accuracy: 0.4729 - policy_loss: 2.4686 - value_loss: 0.0992 - value_mae: 0.2541 - val_loss: 2.5278 - val_policy_categorical_accuracy: 0.4967 - val_policy_loss: 2.3644 - val_value_loss: 0.0993 - val_value_mae: 0.2549 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 451/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1173 - policy_categorical_accuracy: 0.3569 - policy_loss: 2.9568 - value_loss: 0.0990 - value_mae: 0.2553\n",
            "\n",
            "--- Ã‰poque 452/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1018 - policy_categorical_accuracy: 0.3540 - policy_loss: 2.9388 - value_loss: 0.1014 - value_mae: 0.2565\n",
            "\n",
            "--- Ã‰poque 453/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1068 - policy_categorical_accuracy: 0.3616 - policy_loss: 2.9449 - value_loss: 0.1004 - value_mae: 0.2554\n",
            "\n",
            "--- Ã‰poque 454/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1210 - policy_categorical_accuracy: 0.3554 - policy_loss: 2.9616 - value_loss: 0.0981 - value_mae: 0.2519\n",
            "\n",
            "--- Ã‰poque 455/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6034 - policy_categorical_accuracy: 0.4719 - policy_loss: 2.4425 - value_loss: 0.0995 - value_mae: 0.2543\n",
            "Epoch 1: val_loss improved from 2.51733 to 2.50200, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.6036 - policy_categorical_accuracy: 0.4718 - policy_loss: 2.4428 - value_loss: 0.0996 - value_mae: 0.2543 - val_loss: 2.5020 - val_policy_categorical_accuracy: 0.5056 - val_policy_loss: 2.3393 - val_value_loss: 0.0995 - val_value_mae: 0.2545 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 456/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1176 - policy_categorical_accuracy: 0.3617 - policy_loss: 2.9573 - value_loss: 0.0990 - value_mae: 0.2530\n",
            "\n",
            "--- Ã‰poque 457/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1399 - policy_categorical_accuracy: 0.3574 - policy_loss: 2.9803 - value_loss: 0.0985 - value_mae: 0.2526\n",
            "\n",
            "--- Ã‰poque 458/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1449 - policy_categorical_accuracy: 0.3525 - policy_loss: 2.9834 - value_loss: 0.1002 - value_mae: 0.2544\n",
            "\n",
            "--- Ã‰poque 459/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0965 - policy_categorical_accuracy: 0.3660 - policy_loss: 2.9356 - value_loss: 0.0995 - value_mae: 0.2553\n",
            "\n",
            "--- Ã‰poque 460/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6327 - policy_categorical_accuracy: 0.4660 - policy_loss: 2.4726 - value_loss: 0.0989 - value_mae: 0.2533\n",
            "Epoch 1: val_loss did not improve from 2.50200\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.6317 - policy_categorical_accuracy: 0.4662 - policy_loss: 2.4714 - value_loss: 0.0990 - value_mae: 0.2534 - val_loss: 2.5033 - val_policy_categorical_accuracy: 0.4968 - val_policy_loss: 2.3404 - val_value_loss: 0.0989 - val_value_mae: 0.2544 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 461/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1311 - policy_categorical_accuracy: 0.3497 - policy_loss: 2.9694 - value_loss: 0.1006 - value_mae: 0.2554\n",
            "\n",
            "--- Ã‰poque 462/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1495 - policy_categorical_accuracy: 0.3535 - policy_loss: 2.9911 - value_loss: 0.0974 - value_mae: 0.2509\n",
            "\n",
            "--- Ã‰poque 463/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1125 - policy_categorical_accuracy: 0.3581 - policy_loss: 2.9508 - value_loss: 0.1005 - value_mae: 0.2555\n",
            "\n",
            "--- Ã‰poque 464/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1212 - policy_categorical_accuracy: 0.3498 - policy_loss: 2.9597 - value_loss: 0.1004 - value_mae: 0.2543\n",
            "\n",
            "--- Ã‰poque 465/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.6209 - policy_categorical_accuracy: 0.4709 - policy_loss: 2.4614 - value_loss: 0.0983 - value_mae: 0.2523\n",
            "Epoch 1: val_loss improved from 2.50200 to 2.49451, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 2.6202 - policy_categorical_accuracy: 0.4709 - policy_loss: 2.4607 - value_loss: 0.0983 - value_mae: 0.2524 - val_loss: 2.4945 - val_policy_categorical_accuracy: 0.5008 - val_policy_loss: 2.3319 - val_value_loss: 0.0988 - val_value_mae: 0.2535 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 466/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1017 - policy_categorical_accuracy: 0.3611 - policy_loss: 2.9413 - value_loss: 0.0992 - value_mae: 0.2529\n",
            "\n",
            "--- Ã‰poque 467/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1180 - policy_categorical_accuracy: 0.3514 - policy_loss: 2.9588 - value_loss: 0.0979 - value_mae: 0.2521\n",
            "\n",
            "--- Ã‰poque 468/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1088 - policy_categorical_accuracy: 0.3649 - policy_loss: 2.9482 - value_loss: 0.0994 - value_mae: 0.2533\n",
            "\n",
            "--- Ã‰poque 469/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0720 - policy_categorical_accuracy: 0.3673 - policy_loss: 2.9123 - value_loss: 0.0984 - value_mae: 0.2532\n",
            "\n",
            "--- Ã‰poque 470/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.6239 - policy_categorical_accuracy: 0.4738 - policy_loss: 2.4651 - value_loss: 0.0977 - value_mae: 0.2506\n",
            "Epoch 1: val_loss improved from 2.49451 to 2.48666, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.6236 - policy_categorical_accuracy: 0.4738 - policy_loss: 2.4648 - value_loss: 0.0977 - value_mae: 0.2506 - val_loss: 2.4867 - val_policy_categorical_accuracy: 0.5036 - val_policy_loss: 2.3247 - val_value_loss: 0.0986 - val_value_mae: 0.2534 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 471/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1256 - policy_categorical_accuracy: 0.3559 - policy_loss: 2.9668 - value_loss: 0.0979 - value_mae: 0.2511\n",
            "\n",
            "--- Ã‰poque 472/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1056 - policy_categorical_accuracy: 0.3652 - policy_loss: 2.9446 - value_loss: 0.1001 - value_mae: 0.2557\n",
            "\n",
            "--- Ã‰poque 473/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1324 - policy_categorical_accuracy: 0.3590 - policy_loss: 2.9719 - value_loss: 0.0994 - value_mae: 0.2528\n",
            "\n",
            "--- Ã‰poque 474/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1335 - policy_categorical_accuracy: 0.3501 - policy_loss: 2.9725 - value_loss: 0.1001 - value_mae: 0.2546\n",
            "\n",
            "--- Ã‰poque 475/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.6191 - policy_categorical_accuracy: 0.4734 - policy_loss: 2.4573 - value_loss: 0.1008 - value_mae: 0.2566\n",
            "Epoch 1: val_loss did not improve from 2.48666\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.6181 - policy_categorical_accuracy: 0.4734 - policy_loss: 2.4564 - value_loss: 0.1008 - value_mae: 0.2565 - val_loss: 2.4870 - val_policy_categorical_accuracy: 0.5020 - val_policy_loss: 2.3250 - val_value_loss: 0.0989 - val_value_mae: 0.2537 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 476/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1254 - policy_categorical_accuracy: 0.3590 - policy_loss: 2.9639 - value_loss: 0.1003 - value_mae: 0.2567\n",
            "\n",
            "--- Ã‰poque 477/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0694 - policy_categorical_accuracy: 0.3630 - policy_loss: 2.9091 - value_loss: 0.0993 - value_mae: 0.2539\n",
            "\n",
            "--- Ã‰poque 478/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1147 - policy_categorical_accuracy: 0.3479 - policy_loss: 2.9561 - value_loss: 0.0978 - value_mae: 0.2525\n",
            "\n",
            "--- Ã‰poque 479/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0850 - policy_categorical_accuracy: 0.3582 - policy_loss: 2.9272 - value_loss: 0.0971 - value_mae: 0.2495\n",
            "\n",
            "--- Ã‰poque 480/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.6094 - policy_categorical_accuracy: 0.4699 - policy_loss: 2.4513 - value_loss: 0.0972 - value_mae: 0.2514\n",
            "Epoch 1: val_loss did not improve from 2.48666\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.6091 - policy_categorical_accuracy: 0.4700 - policy_loss: 2.4511 - value_loss: 0.0972 - value_mae: 0.2514 - val_loss: 2.4908 - val_policy_categorical_accuracy: 0.5024 - val_policy_loss: 2.3237 - val_value_loss: 0.1037 - val_value_mae: 0.2560 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 481/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0909 - policy_categorical_accuracy: 0.3555 - policy_loss: 2.9261 - value_loss: 0.1037 - value_mae: 0.2607\n",
            "\n",
            "--- Ã‰poque 482/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1312 - policy_categorical_accuracy: 0.3536 - policy_loss: 2.9711 - value_loss: 0.0994 - value_mae: 0.2542\n",
            "\n",
            "--- Ã‰poque 483/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0874 - policy_categorical_accuracy: 0.3595 - policy_loss: 2.9278 - value_loss: 0.0987 - value_mae: 0.2542\n",
            "\n",
            "--- Ã‰poque 484/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0982 - policy_categorical_accuracy: 0.3622 - policy_loss: 2.9400 - value_loss: 0.0972 - value_mae: 0.2502\n",
            "\n",
            "--- Ã‰poque 485/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.5879 - policy_categorical_accuracy: 0.4800 - policy_loss: 2.4281 - value_loss: 0.0990 - value_mae: 0.2537\n",
            "Epoch 1: val_loss improved from 2.48666 to 2.47290, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 2.5878 - policy_categorical_accuracy: 0.4800 - policy_loss: 2.4281 - value_loss: 0.0990 - value_mae: 0.2537 - val_loss: 2.4729 - val_policy_categorical_accuracy: 0.5041 - val_policy_loss: 2.3109 - val_value_loss: 0.0986 - val_value_mae: 0.2532 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 486/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1478 - policy_categorical_accuracy: 0.3524 - policy_loss: 2.9869 - value_loss: 0.0999 - value_mae: 0.2550\n",
            "\n",
            "--- Ã‰poque 487/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0993 - policy_categorical_accuracy: 0.3592 - policy_loss: 2.9376 - value_loss: 0.1010 - value_mae: 0.2551\n",
            "\n",
            "--- Ã‰poque 488/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0764 - policy_categorical_accuracy: 0.3753 - policy_loss: 2.9154 - value_loss: 0.1004 - value_mae: 0.2555\n",
            "\n",
            "--- Ã‰poque 489/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0992 - policy_categorical_accuracy: 0.3646 - policy_loss: 2.9362 - value_loss: 0.1023 - value_mae: 0.2599\n",
            "\n",
            "--- Ã‰poque 490/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.5752 - policy_categorical_accuracy: 0.4755 - policy_loss: 2.4172 - value_loss: 0.0972 - value_mae: 0.2505\n",
            "Epoch 1: val_loss did not improve from 2.47290\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.5754 - policy_categorical_accuracy: 0.4755 - policy_loss: 2.4173 - value_loss: 0.0973 - value_mae: 0.2507 - val_loss: 2.4771 - val_policy_categorical_accuracy: 0.5068 - val_policy_loss: 2.3144 - val_value_loss: 0.1000 - val_value_mae: 0.2539 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 491/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0948 - policy_categorical_accuracy: 0.3652 - policy_loss: 2.9342 - value_loss: 0.0998 - value_mae: 0.2550\n",
            "\n",
            "--- Ã‰poque 492/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1104 - policy_categorical_accuracy: 0.3565 - policy_loss: 2.9499 - value_loss: 0.0997 - value_mae: 0.2553\n",
            "\n",
            "--- Ã‰poque 493/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1049 - policy_categorical_accuracy: 0.3671 - policy_loss: 2.9443 - value_loss: 0.0998 - value_mae: 0.2534\n",
            "\n",
            "--- Ã‰poque 494/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0889 - policy_categorical_accuracy: 0.3636 - policy_loss: 2.9293 - value_loss: 0.0989 - value_mae: 0.2533\n",
            "\n",
            "--- Ã‰poque 495/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.5743 - policy_categorical_accuracy: 0.4811 - policy_loss: 2.4144 - value_loss: 0.0993 - value_mae: 0.2552\n",
            "Epoch 1: val_loss improved from 2.47290 to 2.46698, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.5744 - policy_categorical_accuracy: 0.4809 - policy_loss: 2.4145 - value_loss: 0.0993 - value_mae: 0.2552 - val_loss: 2.4670 - val_policy_categorical_accuracy: 0.5056 - val_policy_loss: 2.3057 - val_value_loss: 0.0986 - val_value_mae: 0.2539 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 496/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1322 - policy_categorical_accuracy: 0.3556 - policy_loss: 2.9712 - value_loss: 0.1002 - value_mae: 0.2543\n",
            "\n",
            "--- Ã‰poque 497/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1052 - policy_categorical_accuracy: 0.3611 - policy_loss: 2.9476 - value_loss: 0.0969 - value_mae: 0.2490\n",
            "\n",
            "--- Ã‰poque 498/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0776 - policy_categorical_accuracy: 0.3632 - policy_loss: 2.9152 - value_loss: 0.1017 - value_mae: 0.2567\n",
            "\n",
            "--- Ã‰poque 499/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1175 - policy_categorical_accuracy: 0.3598 - policy_loss: 2.9580 - value_loss: 0.0989 - value_mae: 0.2535\n",
            "\n",
            "--- Ã‰poque 500/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.5696 - policy_categorical_accuracy: 0.4848 - policy_loss: 2.4104 - value_loss: 0.0986 - value_mae: 0.2531\n",
            "Epoch 1: val_loss improved from 2.46698 to 2.45365, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.5696 - policy_categorical_accuracy: 0.4847 - policy_loss: 2.4105 - value_loss: 0.0986 - value_mae: 0.2531 - val_loss: 2.4536 - val_policy_categorical_accuracy: 0.5124 - val_policy_loss: 2.2927 - val_value_loss: 0.0981 - val_value_mae: 0.2531 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 501/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1048 - policy_categorical_accuracy: 0.3581 - policy_loss: 2.9464 - value_loss: 0.0976 - value_mae: 0.2510\n",
            "\n",
            "--- Ã‰poque 502/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0681 - policy_categorical_accuracy: 0.3603 - policy_loss: 2.9093 - value_loss: 0.0983 - value_mae: 0.2525\n",
            "\n",
            "--- Ã‰poque 503/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0781 - policy_categorical_accuracy: 0.3591 - policy_loss: 2.9205 - value_loss: 0.0972 - value_mae: 0.2494\n",
            "\n",
            "--- Ã‰poque 504/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0396 - policy_categorical_accuracy: 0.3685 - policy_loss: 2.8791 - value_loss: 0.1001 - value_mae: 0.2559\n",
            "\n",
            "--- Ã‰poque 505/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.5873 - policy_categorical_accuracy: 0.4730 - policy_loss: 2.4247 - value_loss: 0.1021 - value_mae: 0.2587\n",
            "Epoch 1: val_loss did not improve from 2.45365\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.5870 - policy_categorical_accuracy: 0.4731 - policy_loss: 2.4243 - value_loss: 0.1020 - value_mae: 0.2587 - val_loss: 2.4660 - val_policy_categorical_accuracy: 0.5056 - val_policy_loss: 2.3054 - val_value_loss: 0.0982 - val_value_mae: 0.2538 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 506/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1270 - policy_categorical_accuracy: 0.3522 - policy_loss: 2.9675 - value_loss: 0.0991 - value_mae: 0.2529\n",
            "\n",
            "--- Ã‰poque 507/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1051 - policy_categorical_accuracy: 0.3571 - policy_loss: 2.9458 - value_loss: 0.0988 - value_mae: 0.2533\n",
            "\n",
            "--- Ã‰poque 508/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1316 - policy_categorical_accuracy: 0.3571 - policy_loss: 2.9711 - value_loss: 0.1001 - value_mae: 0.2547\n",
            "\n",
            "--- Ã‰poque 509/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1433 - policy_categorical_accuracy: 0.3572 - policy_loss: 2.9801 - value_loss: 0.1026 - value_mae: 0.2598\n",
            "\n",
            "--- Ã‰poque 510/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5760 - policy_categorical_accuracy: 0.4736 - policy_loss: 2.4184 - value_loss: 0.0973 - value_mae: 0.2513\n",
            "Epoch 1: val_loss improved from 2.45365 to 2.44216, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.5755 - policy_categorical_accuracy: 0.4740 - policy_loss: 2.4179 - value_loss: 0.0974 - value_mae: 0.2514 - val_loss: 2.4422 - val_policy_categorical_accuracy: 0.5164 - val_policy_loss: 2.2812 - val_value_loss: 0.0982 - val_value_mae: 0.2533 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 511/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.1276 - policy_categorical_accuracy: 0.3564 - policy_loss: 2.9663 - value_loss: 0.1008 - value_mae: 0.2569\n",
            "\n",
            "--- Ã‰poque 512/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0686 - policy_categorical_accuracy: 0.3576 - policy_loss: 2.9098 - value_loss: 0.0985 - value_mae: 0.2534\n",
            "\n",
            "--- Ã‰poque 513/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0643 - policy_categorical_accuracy: 0.3658 - policy_loss: 2.9046 - value_loss: 0.0992 - value_mae: 0.2532\n",
            "\n",
            "--- Ã‰poque 514/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0877 - policy_categorical_accuracy: 0.3602 - policy_loss: 2.9273 - value_loss: 0.1001 - value_mae: 0.2552\n",
            "\n",
            "--- Ã‰poque 515/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5584 - policy_categorical_accuracy: 0.4892 - policy_loss: 2.3996 - value_loss: 0.0984 - value_mae: 0.2539\n",
            "Epoch 1: val_loss improved from 2.44216 to 2.43524, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.5581 - policy_categorical_accuracy: 0.4891 - policy_loss: 2.3993 - value_loss: 0.0985 - value_mae: 0.2539 - val_loss: 2.4352 - val_policy_categorical_accuracy: 0.5221 - val_policy_loss: 2.2742 - val_value_loss: 0.0987 - val_value_mae: 0.2524 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 516/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1344 - policy_categorical_accuracy: 0.3510 - policy_loss: 2.9768 - value_loss: 0.0974 - value_mae: 0.2517\n",
            "\n",
            "--- Ã‰poque 517/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0848 - policy_categorical_accuracy: 0.3686 - policy_loss: 2.9251 - value_loss: 0.0999 - value_mae: 0.2556\n",
            "\n",
            "--- Ã‰poque 518/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1357 - policy_categorical_accuracy: 0.3529 - policy_loss: 2.9776 - value_loss: 0.0978 - value_mae: 0.2516\n",
            "\n",
            "--- Ã‰poque 519/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0756 - policy_categorical_accuracy: 0.3573 - policy_loss: 2.9139 - value_loss: 0.1014 - value_mae: 0.2557\n",
            "\n",
            "--- Ã‰poque 520/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.5831 - policy_categorical_accuracy: 0.4828 - policy_loss: 2.4228 - value_loss: 0.1001 - value_mae: 0.2558\n",
            "Epoch 1: val_loss improved from 2.43524 to 2.43407, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.5823 - policy_categorical_accuracy: 0.4830 - policy_loss: 2.4220 - value_loss: 0.1001 - value_mae: 0.2558 - val_loss: 2.4341 - val_policy_categorical_accuracy: 0.5138 - val_policy_loss: 2.2739 - val_value_loss: 0.0977 - val_value_mae: 0.2524 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 521/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1179 - policy_categorical_accuracy: 0.3632 - policy_loss: 2.9574 - value_loss: 0.1001 - value_mae: 0.2558\n",
            "\n",
            "--- Ã‰poque 522/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1280 - policy_categorical_accuracy: 0.3502 - policy_loss: 2.9669 - value_loss: 0.1009 - value_mae: 0.2572\n",
            "\n",
            "--- Ã‰poque 523/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0625 - policy_categorical_accuracy: 0.3699 - policy_loss: 2.9045 - value_loss: 0.0978 - value_mae: 0.2511\n",
            "\n",
            "--- Ã‰poque 524/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0721 - policy_categorical_accuracy: 0.3612 - policy_loss: 2.9114 - value_loss: 0.1004 - value_mae: 0.2553\n",
            "\n",
            "--- Ã‰poque 525/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5514 - policy_categorical_accuracy: 0.4840 - policy_loss: 2.3925 - value_loss: 0.0987 - value_mae: 0.2535\n",
            "Epoch 1: val_loss improved from 2.43407 to 2.42672, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.5512 - policy_categorical_accuracy: 0.4841 - policy_loss: 2.3923 - value_loss: 0.0987 - value_mae: 0.2535 - val_loss: 2.4267 - val_policy_categorical_accuracy: 0.5191 - val_policy_loss: 2.2668 - val_value_loss: 0.0978 - val_value_mae: 0.2522 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 526/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0791 - policy_categorical_accuracy: 0.3601 - policy_loss: 2.9183 - value_loss: 0.1005 - value_mae: 0.2557\n",
            "\n",
            "--- Ã‰poque 527/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0863 - policy_categorical_accuracy: 0.3617 - policy_loss: 2.9254 - value_loss: 0.1009 - value_mae: 0.2556\n",
            "\n",
            "--- Ã‰poque 528/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0607 - policy_categorical_accuracy: 0.3599 - policy_loss: 2.9014 - value_loss: 0.0994 - value_mae: 0.2551\n",
            "\n",
            "--- Ã‰poque 529/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0713 - policy_categorical_accuracy: 0.3687 - policy_loss: 2.9129 - value_loss: 0.0982 - value_mae: 0.2517\n",
            "\n",
            "--- Ã‰poque 530/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5535 - policy_categorical_accuracy: 0.4832 - policy_loss: 2.3946 - value_loss: 0.0988 - value_mae: 0.2538\n",
            "Epoch 1: val_loss did not improve from 2.42672\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.5530 - policy_categorical_accuracy: 0.4833 - policy_loss: 2.3939 - value_loss: 0.0988 - value_mae: 0.2538 - val_loss: 2.4333 - val_policy_categorical_accuracy: 0.5179 - val_policy_loss: 2.2723 - val_value_loss: 0.0984 - val_value_mae: 0.2525 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 531/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0978 - policy_categorical_accuracy: 0.3579 - policy_loss: 2.9397 - value_loss: 0.0980 - value_mae: 0.2530\n",
            "\n",
            "--- Ã‰poque 532/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0697 - policy_categorical_accuracy: 0.3705 - policy_loss: 2.9111 - value_loss: 0.0983 - value_mae: 0.2507\n",
            "\n",
            "--- Ã‰poque 533/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0795 - policy_categorical_accuracy: 0.3606 - policy_loss: 2.9169 - value_loss: 0.1024 - value_mae: 0.2560\n",
            "\n",
            "--- Ã‰poque 534/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1074 - policy_categorical_accuracy: 0.3510 - policy_loss: 2.9494 - value_loss: 0.0981 - value_mae: 0.2517\n",
            "\n",
            "--- Ã‰poque 535/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5541 - policy_categorical_accuracy: 0.4829 - policy_loss: 2.3964 - value_loss: 0.0977 - value_mae: 0.2517\n",
            "Epoch 1: val_loss improved from 2.42672 to 2.41362, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.5534 - policy_categorical_accuracy: 0.4830 - policy_loss: 2.3956 - value_loss: 0.0977 - value_mae: 0.2518 - val_loss: 2.4136 - val_policy_categorical_accuracy: 0.5236 - val_policy_loss: 2.2537 - val_value_loss: 0.0978 - val_value_mae: 0.2523 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 536/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1060 - policy_categorical_accuracy: 0.3561 - policy_loss: 2.9482 - value_loss: 0.0978 - value_mae: 0.2524\n",
            "\n",
            "--- Ã‰poque 537/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1092 - policy_categorical_accuracy: 0.3558 - policy_loss: 2.9459 - value_loss: 0.1033 - value_mae: 0.2580\n",
            "\n",
            "--- Ã‰poque 538/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0964 - policy_categorical_accuracy: 0.3519 - policy_loss: 2.9360 - value_loss: 0.1002 - value_mae: 0.2549\n",
            "\n",
            "--- Ã‰poque 539/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1243 - policy_categorical_accuracy: 0.3591 - policy_loss: 2.9658 - value_loss: 0.0984 - value_mae: 0.2510\n",
            "\n",
            "--- Ã‰poque 540/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5456 - policy_categorical_accuracy: 0.4850 - policy_loss: 2.3862 - value_loss: 0.0994 - value_mae: 0.2544\n",
            "Epoch 1: val_loss did not improve from 2.41362\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.5451 - policy_categorical_accuracy: 0.4850 - policy_loss: 2.3858 - value_loss: 0.0994 - value_mae: 0.2543 - val_loss: 2.4295 - val_policy_categorical_accuracy: 0.5192 - val_policy_loss: 2.2676 - val_value_loss: 0.0992 - val_value_mae: 0.2526 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 541/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0817 - policy_categorical_accuracy: 0.3659 - policy_loss: 2.9225 - value_loss: 0.0991 - value_mae: 0.2527\n",
            "\n",
            "--- Ã‰poque 542/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0971 - policy_categorical_accuracy: 0.3537 - policy_loss: 2.9391 - value_loss: 0.0980 - value_mae: 0.2517\n",
            "\n",
            "--- Ã‰poque 543/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0391 - policy_categorical_accuracy: 0.3668 - policy_loss: 2.8783 - value_loss: 0.1009 - value_mae: 0.2564\n",
            "\n",
            "--- Ã‰poque 544/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0661 - policy_categorical_accuracy: 0.3602 - policy_loss: 2.9046 - value_loss: 0.1015 - value_mae: 0.2560\n",
            "\n",
            "--- Ã‰poque 545/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5677 - policy_categorical_accuracy: 0.4768 - policy_loss: 2.4106 - value_loss: 0.0973 - value_mae: 0.2512\n",
            "Epoch 1: val_loss did not improve from 2.41362\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 2.5663 - policy_categorical_accuracy: 0.4773 - policy_loss: 2.4093 - value_loss: 0.0973 - value_mae: 0.2512 - val_loss: 2.4144 - val_policy_categorical_accuracy: 0.5198 - val_policy_loss: 2.2535 - val_value_loss: 0.0985 - val_value_mae: 0.2534 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 546/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0688 - policy_categorical_accuracy: 0.3635 - policy_loss: 2.9090 - value_loss: 0.0997 - value_mae: 0.2543\n",
            "\n",
            "--- Ã‰poque 547/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0880 - policy_categorical_accuracy: 0.3576 - policy_loss: 2.9264 - value_loss: 0.1018 - value_mae: 0.2574\n",
            "\n",
            "--- Ã‰poque 548/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1011 - policy_categorical_accuracy: 0.3572 - policy_loss: 2.9453 - value_loss: 0.0962 - value_mae: 0.2492\n",
            "\n",
            "--- Ã‰poque 549/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1230 - policy_categorical_accuracy: 0.3652 - policy_loss: 2.9653 - value_loss: 0.0979 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 550/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.5422 - policy_categorical_accuracy: 0.4869 - policy_loss: 2.3823 - value_loss: 0.1001 - value_mae: 0.2559\n",
            "Epoch 1: val_loss did not improve from 2.41362\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.5416 - policy_categorical_accuracy: 0.4870 - policy_loss: 2.3818 - value_loss: 0.1000 - value_mae: 0.2558 - val_loss: 2.4251 - val_policy_categorical_accuracy: 0.5238 - val_policy_loss: 2.2644 - val_value_loss: 0.0987 - val_value_mae: 0.2544 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 551/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1210 - policy_categorical_accuracy: 0.3553 - policy_loss: 2.9670 - value_loss: 0.0942 - value_mae: 0.2454\n",
            "\n",
            "--- Ã‰poque 552/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0878 - policy_categorical_accuracy: 0.3587 - policy_loss: 2.9253 - value_loss: 0.1027 - value_mae: 0.2571\n",
            "\n",
            "--- Ã‰poque 553/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0838 - policy_categorical_accuracy: 0.3558 - policy_loss: 2.9253 - value_loss: 0.0988 - value_mae: 0.2531\n",
            "\n",
            "--- Ã‰poque 554/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0901 - policy_categorical_accuracy: 0.3591 - policy_loss: 2.9316 - value_loss: 0.0989 - value_mae: 0.2524\n",
            "\n",
            "--- Ã‰poque 555/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5191 - policy_categorical_accuracy: 0.4906 - policy_loss: 2.3597 - value_loss: 0.0997 - value_mae: 0.2542\n",
            "Epoch 1: val_loss improved from 2.41362 to 2.39807, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.5190 - policy_categorical_accuracy: 0.4907 - policy_loss: 2.3596 - value_loss: 0.0996 - value_mae: 0.2541 - val_loss: 2.3981 - val_policy_categorical_accuracy: 0.5287 - val_policy_loss: 2.2383 - val_value_loss: 0.0979 - val_value_mae: 0.2526 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 556/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1327 - policy_categorical_accuracy: 0.3520 - policy_loss: 2.9761 - value_loss: 0.0970 - value_mae: 0.2498\n",
            "\n",
            "--- Ã‰poque 557/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0867 - policy_categorical_accuracy: 0.3545 - policy_loss: 2.9247 - value_loss: 0.1023 - value_mae: 0.2572\n",
            "\n",
            "--- Ã‰poque 558/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0825 - policy_categorical_accuracy: 0.3574 - policy_loss: 2.9226 - value_loss: 0.1002 - value_mae: 0.2545\n",
            "\n",
            "--- Ã‰poque 559/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0441 - policy_categorical_accuracy: 0.3681 - policy_loss: 2.8831 - value_loss: 0.1012 - value_mae: 0.2560\n",
            "\n",
            "--- Ã‰poque 560/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5339 - policy_categorical_accuracy: 0.4875 - policy_loss: 2.3747 - value_loss: 0.0995 - value_mae: 0.2543\n",
            "Epoch 1: val_loss did not improve from 2.39807\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.5332 - policy_categorical_accuracy: 0.4877 - policy_loss: 2.3742 - value_loss: 0.0995 - value_mae: 0.2542 - val_loss: 2.4111 - val_policy_categorical_accuracy: 0.5262 - val_policy_loss: 2.2522 - val_value_loss: 0.0978 - val_value_mae: 0.2519 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 561/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1061 - policy_categorical_accuracy: 0.3567 - policy_loss: 2.9497 - value_loss: 0.0966 - value_mae: 0.2495\n",
            "\n",
            "--- Ã‰poque 562/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0965 - policy_categorical_accuracy: 0.3558 - policy_loss: 2.9385 - value_loss: 0.0984 - value_mae: 0.2527\n",
            "\n",
            "--- Ã‰poque 563/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0499 - policy_categorical_accuracy: 0.3651 - policy_loss: 2.8904 - value_loss: 0.0997 - value_mae: 0.2536\n",
            "\n",
            "--- Ã‰poque 564/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0810 - policy_categorical_accuracy: 0.3505 - policy_loss: 2.9217 - value_loss: 0.0997 - value_mae: 0.2534\n",
            "\n",
            "--- Ã‰poque 565/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5132 - policy_categorical_accuracy: 0.4947 - policy_loss: 2.3567 - value_loss: 0.0970 - value_mae: 0.2507\n",
            "Epoch 1: val_loss did not improve from 2.39807\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.5130 - policy_categorical_accuracy: 0.4947 - policy_loss: 2.3568 - value_loss: 0.0970 - value_mae: 0.2508 - val_loss: 2.4161 - val_policy_categorical_accuracy: 0.5220 - val_policy_loss: 2.2567 - val_value_loss: 0.0974 - val_value_mae: 0.2520 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 566/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1030 - policy_categorical_accuracy: 0.3519 - policy_loss: 2.9452 - value_loss: 0.0981 - value_mae: 0.2527\n",
            "\n",
            "--- Ã‰poque 567/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0744 - policy_categorical_accuracy: 0.3641 - policy_loss: 2.9154 - value_loss: 0.0994 - value_mae: 0.2543\n",
            "\n",
            "--- Ã‰poque 568/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0929 - policy_categorical_accuracy: 0.3642 - policy_loss: 2.9323 - value_loss: 0.1012 - value_mae: 0.2544\n",
            "\n",
            "--- Ã‰poque 569/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0723 - policy_categorical_accuracy: 0.3562 - policy_loss: 2.9147 - value_loss: 0.0981 - value_mae: 0.2525\n",
            "\n",
            "--- Ã‰poque 570/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5536 - policy_categorical_accuracy: 0.4825 - policy_loss: 2.3966 - value_loss: 0.0975 - value_mae: 0.2523\n",
            "Epoch 1: val_loss improved from 2.39807 to 2.38728, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.5519 - policy_categorical_accuracy: 0.4830 - policy_loss: 2.3947 - value_loss: 0.0975 - value_mae: 0.2523 - val_loss: 2.3873 - val_policy_categorical_accuracy: 0.5316 - val_policy_loss: 2.2281 - val_value_loss: 0.0978 - val_value_mae: 0.2511 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 571/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1024 - policy_categorical_accuracy: 0.3562 - policy_loss: 2.9411 - value_loss: 0.1018 - value_mae: 0.2574\n",
            "\n",
            "--- Ã‰poque 572/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0571 - policy_categorical_accuracy: 0.3678 - policy_loss: 2.8977 - value_loss: 0.0999 - value_mae: 0.2550\n",
            "\n",
            "--- Ã‰poque 573/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0949 - policy_categorical_accuracy: 0.3549 - policy_loss: 2.9381 - value_loss: 0.0974 - value_mae: 0.2519\n",
            "\n",
            "--- Ã‰poque 574/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0840 - policy_categorical_accuracy: 0.3628 - policy_loss: 2.9218 - value_loss: 0.1026 - value_mae: 0.2586\n",
            "\n",
            "--- Ã‰poque 575/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.4963 - policy_categorical_accuracy: 0.5058 - policy_loss: 2.3389 - value_loss: 0.0980 - value_mae: 0.2527\n",
            "Epoch 1: val_loss improved from 2.38728 to 2.38537, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.4964 - policy_categorical_accuracy: 0.5057 - policy_loss: 2.3391 - value_loss: 0.0980 - value_mae: 0.2527 - val_loss: 2.3854 - val_policy_categorical_accuracy: 0.5339 - val_policy_loss: 2.2252 - val_value_loss: 0.0986 - val_value_mae: 0.2535 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 576/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0726 - policy_categorical_accuracy: 0.3715 - policy_loss: 2.9131 - value_loss: 0.0999 - value_mae: 0.2550\n",
            "\n",
            "--- Ã‰poque 577/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0834 - policy_categorical_accuracy: 0.3633 - policy_loss: 2.9260 - value_loss: 0.0979 - value_mae: 0.2526\n",
            "\n",
            "--- Ã‰poque 578/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1062 - policy_categorical_accuracy: 0.3469 - policy_loss: 2.9501 - value_loss: 0.0967 - value_mae: 0.2487\n",
            "\n",
            "--- Ã‰poque 579/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0755 - policy_categorical_accuracy: 0.3646 - policy_loss: 2.9150 - value_loss: 0.1009 - value_mae: 0.2562\n",
            "\n",
            "--- Ã‰poque 580/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.5232 - policy_categorical_accuracy: 0.4882 - policy_loss: 2.3662 - value_loss: 0.0977 - value_mae: 0.2493\n",
            "Epoch 1: val_loss did not improve from 2.38537\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.5222 - policy_categorical_accuracy: 0.4885 - policy_loss: 2.3651 - value_loss: 0.0977 - value_mae: 0.2494 - val_loss: 2.3866 - val_policy_categorical_accuracy: 0.5322 - val_policy_loss: 2.2274 - val_value_loss: 0.0979 - val_value_mae: 0.2511 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 581/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1476 - policy_categorical_accuracy: 0.3416 - policy_loss: 2.9901 - value_loss: 0.0979 - value_mae: 0.2511\n",
            "\n",
            "--- Ã‰poque 582/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0593 - policy_categorical_accuracy: 0.3698 - policy_loss: 2.8996 - value_loss: 0.1004 - value_mae: 0.2550\n",
            "\n",
            "--- Ã‰poque 583/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0370 - policy_categorical_accuracy: 0.3685 - policy_loss: 2.8747 - value_loss: 0.1029 - value_mae: 0.2602\n",
            "\n",
            "--- Ã‰poque 584/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0972 - policy_categorical_accuracy: 0.3499 - policy_loss: 2.9419 - value_loss: 0.0961 - value_mae: 0.2472\n",
            "\n",
            "--- Ã‰poque 585/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5132 - policy_categorical_accuracy: 0.5017 - policy_loss: 2.3561 - value_loss: 0.0978 - value_mae: 0.2519\n",
            "Epoch 1: val_loss improved from 2.38537 to 2.37106, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.5124 - policy_categorical_accuracy: 0.5017 - policy_loss: 2.3553 - value_loss: 0.0979 - value_mae: 0.2520 - val_loss: 2.3711 - val_policy_categorical_accuracy: 0.5332 - val_policy_loss: 2.2127 - val_value_loss: 0.0973 - val_value_mae: 0.2508 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 586/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1511 - policy_categorical_accuracy: 0.3473 - policy_loss: 2.9933 - value_loss: 0.0985 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 587/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0847 - policy_categorical_accuracy: 0.3619 - policy_loss: 2.9301 - value_loss: 0.0952 - value_mae: 0.2484\n",
            "\n",
            "--- Ã‰poque 588/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0931 - policy_categorical_accuracy: 0.3537 - policy_loss: 2.9368 - value_loss: 0.0970 - value_mae: 0.2491\n",
            "\n",
            "--- Ã‰poque 589/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0818 - policy_categorical_accuracy: 0.3605 - policy_loss: 2.9248 - value_loss: 0.0978 - value_mae: 0.2504\n",
            "\n",
            "--- Ã‰poque 590/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5317 - policy_categorical_accuracy: 0.4930 - policy_loss: 2.3764 - value_loss: 0.0961 - value_mae: 0.2493\n",
            "Epoch 1: val_loss did not improve from 2.37106\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.5300 - policy_categorical_accuracy: 0.4933 - policy_loss: 2.3747 - value_loss: 0.0961 - value_mae: 0.2494 - val_loss: 2.3742 - val_policy_categorical_accuracy: 0.5353 - val_policy_loss: 2.2153 - val_value_loss: 0.0973 - val_value_mae: 0.2517 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 591/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0790 - policy_categorical_accuracy: 0.3635 - policy_loss: 2.9204 - value_loss: 0.0995 - value_mae: 0.2538\n",
            "\n",
            "--- Ã‰poque 592/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.1260 - policy_categorical_accuracy: 0.3498 - policy_loss: 2.9690 - value_loss: 0.0981 - value_mae: 0.2496\n",
            "\n",
            "--- Ã‰poque 593/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0620 - policy_categorical_accuracy: 0.3717 - policy_loss: 2.9025 - value_loss: 0.1002 - value_mae: 0.2541\n",
            "\n",
            "--- Ã‰poque 594/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0687 - policy_categorical_accuracy: 0.3626 - policy_loss: 2.9069 - value_loss: 0.1026 - value_mae: 0.2576\n",
            "\n",
            "--- Ã‰poque 595/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5160 - policy_categorical_accuracy: 0.4957 - policy_loss: 2.3589 - value_loss: 0.0980 - value_mae: 0.2529\n",
            "Epoch 1: val_loss did not improve from 2.37106\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.5148 - policy_categorical_accuracy: 0.4960 - policy_loss: 2.3577 - value_loss: 0.0980 - value_mae: 0.2529 - val_loss: 2.3739 - val_policy_categorical_accuracy: 0.5358 - val_policy_loss: 2.2160 - val_value_loss: 0.0969 - val_value_mae: 0.2508 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 596/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1026 - policy_categorical_accuracy: 0.3550 - policy_loss: 2.9471 - value_loss: 0.0965 - value_mae: 0.2487\n",
            "\n",
            "--- Ã‰poque 597/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0505 - policy_categorical_accuracy: 0.3695 - policy_loss: 2.8915 - value_loss: 0.0997 - value_mae: 0.2543\n",
            "\n",
            "--- Ã‰poque 598/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0998 - policy_categorical_accuracy: 0.3496 - policy_loss: 2.9408 - value_loss: 0.0998 - value_mae: 0.2534\n",
            "\n",
            "--- Ã‰poque 599/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0888 - policy_categorical_accuracy: 0.3608 - policy_loss: 2.9304 - value_loss: 0.0994 - value_mae: 0.2536\n",
            "\n",
            "--- Ã‰poque 600/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5043 - policy_categorical_accuracy: 0.4981 - policy_loss: 2.3475 - value_loss: 0.0978 - value_mae: 0.2535\n",
            "Epoch 1: val_loss did not improve from 2.37106\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.5034 - policy_categorical_accuracy: 0.4983 - policy_loss: 2.3466 - value_loss: 0.0977 - value_mae: 0.2534 - val_loss: 2.3737 - val_policy_categorical_accuracy: 0.5363 - val_policy_loss: 2.2153 - val_value_loss: 0.0970 - val_value_mae: 0.2510 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 601/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1226 - policy_categorical_accuracy: 0.3493 - policy_loss: 2.9647 - value_loss: 0.0988 - value_mae: 0.2515\n",
            "\n",
            "--- Ã‰poque 602/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0802 - policy_categorical_accuracy: 0.3600 - policy_loss: 2.9220 - value_loss: 0.0989 - value_mae: 0.2548\n",
            "\n",
            "--- Ã‰poque 603/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0844 - policy_categorical_accuracy: 0.3559 - policy_loss: 2.9257 - value_loss: 0.0997 - value_mae: 0.2533\n",
            "\n",
            "--- Ã‰poque 604/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0942 - policy_categorical_accuracy: 0.3550 - policy_loss: 2.9384 - value_loss: 0.0968 - value_mae: 0.2494\n",
            "\n",
            "--- Ã‰poque 605/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5230 - policy_categorical_accuracy: 0.4939 - policy_loss: 2.3691 - value_loss: 0.0948 - value_mae: 0.2479\n",
            "Epoch 1: val_loss improved from 2.37106 to 2.35747, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.5213 - policy_categorical_accuracy: 0.4942 - policy_loss: 2.3673 - value_loss: 0.0949 - value_mae: 0.2480 - val_loss: 2.3575 - val_policy_categorical_accuracy: 0.5411 - val_policy_loss: 2.1996 - val_value_loss: 0.0969 - val_value_mae: 0.2511 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 606/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1251 - policy_categorical_accuracy: 0.3455 - policy_loss: 2.9677 - value_loss: 0.0984 - value_mae: 0.2516\n",
            "\n",
            "--- Ã‰poque 607/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0897 - policy_categorical_accuracy: 0.3623 - policy_loss: 2.9323 - value_loss: 0.0985 - value_mae: 0.2537\n",
            "\n",
            "--- Ã‰poque 608/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1051 - policy_categorical_accuracy: 0.3539 - policy_loss: 2.9465 - value_loss: 0.0995 - value_mae: 0.2519\n",
            "\n",
            "--- Ã‰poque 609/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0400 - policy_categorical_accuracy: 0.3686 - policy_loss: 2.8827 - value_loss: 0.0984 - value_mae: 0.2524\n",
            "\n",
            "--- Ã‰poque 610/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5089 - policy_categorical_accuracy: 0.4950 - policy_loss: 2.3523 - value_loss: 0.0977 - value_mae: 0.2514\n",
            "Epoch 1: val_loss improved from 2.35747 to 2.34585, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.5076 - policy_categorical_accuracy: 0.4952 - policy_loss: 2.3508 - value_loss: 0.0977 - value_mae: 0.2515 - val_loss: 2.3458 - val_policy_categorical_accuracy: 0.5444 - val_policy_loss: 2.1872 - val_value_loss: 0.0965 - val_value_mae: 0.2509 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 611/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0599 - policy_categorical_accuracy: 0.3691 - policy_loss: 2.8978 - value_loss: 0.1029 - value_mae: 0.2600\n",
            "\n",
            "--- Ã‰poque 612/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0561 - policy_categorical_accuracy: 0.3533 - policy_loss: 2.9032 - value_loss: 0.0941 - value_mae: 0.2459\n",
            "\n",
            "--- Ã‰poque 613/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0920 - policy_categorical_accuracy: 0.3537 - policy_loss: 2.9365 - value_loss: 0.0968 - value_mae: 0.2495\n",
            "\n",
            "--- Ã‰poque 614/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0810 - policy_categorical_accuracy: 0.3658 - policy_loss: 2.9199 - value_loss: 0.1023 - value_mae: 0.2538\n",
            "\n",
            "--- Ã‰poque 615/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.4762 - policy_categorical_accuracy: 0.5023 - policy_loss: 2.3193 - value_loss: 0.0980 - value_mae: 0.2516\n",
            "Epoch 1: val_loss did not improve from 2.34585\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 2.4758 - policy_categorical_accuracy: 0.5024 - policy_loss: 2.3190 - value_loss: 0.0979 - value_mae: 0.2516 - val_loss: 2.3508 - val_policy_categorical_accuracy: 0.5440 - val_policy_loss: 2.1908 - val_value_loss: 0.0992 - val_value_mae: 0.2525 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 616/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0757 - policy_categorical_accuracy: 0.3627 - policy_loss: 2.9175 - value_loss: 0.0993 - value_mae: 0.2538\n",
            "\n",
            "--- Ã‰poque 617/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0633 - policy_categorical_accuracy: 0.3676 - policy_loss: 2.9060 - value_loss: 0.0984 - value_mae: 0.2518\n",
            "\n",
            "--- Ã‰poque 618/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0650 - policy_categorical_accuracy: 0.3650 - policy_loss: 2.9040 - value_loss: 0.1022 - value_mae: 0.2586\n",
            "\n",
            "--- Ã‰poque 619/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0879 - policy_categorical_accuracy: 0.3643 - policy_loss: 2.9324 - value_loss: 0.0966 - value_mae: 0.2496\n",
            "\n",
            "--- Ã‰poque 620/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5006 - policy_categorical_accuracy: 0.4984 - policy_loss: 2.3479 - value_loss: 0.0938 - value_mae: 0.2463\n",
            "Epoch 1: val_loss did not improve from 2.34585\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.4991 - policy_categorical_accuracy: 0.4988 - policy_loss: 2.3463 - value_loss: 0.0940 - value_mae: 0.2465 - val_loss: 2.3511 - val_policy_categorical_accuracy: 0.5392 - val_policy_loss: 2.1933 - val_value_loss: 0.0977 - val_value_mae: 0.2508 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 621/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1087 - policy_categorical_accuracy: 0.3574 - policy_loss: 2.9485 - value_loss: 0.1013 - value_mae: 0.2564\n",
            "\n",
            "--- Ã‰poque 622/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0822 - policy_categorical_accuracy: 0.3517 - policy_loss: 2.9245 - value_loss: 0.0989 - value_mae: 0.2531\n",
            "\n",
            "--- Ã‰poque 623/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0748 - policy_categorical_accuracy: 0.3661 - policy_loss: 2.9170 - value_loss: 0.0992 - value_mae: 0.2543\n",
            "\n",
            "--- Ã‰poque 624/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0260 - policy_categorical_accuracy: 0.3750 - policy_loss: 2.8696 - value_loss: 0.0977 - value_mae: 0.2515\n",
            "\n",
            "--- Ã‰poque 625/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4926 - policy_categorical_accuracy: 0.4996 - policy_loss: 2.3346 - value_loss: 0.0992 - value_mae: 0.2542\n",
            "Epoch 1: val_loss did not improve from 2.34585\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.4913 - policy_categorical_accuracy: 0.4998 - policy_loss: 2.3335 - value_loss: 0.0991 - value_mae: 0.2540 - val_loss: 2.3502 - val_policy_categorical_accuracy: 0.5379 - val_policy_loss: 2.1915 - val_value_loss: 0.0977 - val_value_mae: 0.2500 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 626/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.1132 - policy_categorical_accuracy: 0.3623 - policy_loss: 2.9545 - value_loss: 0.1000 - value_mae: 0.2537\n",
            "\n",
            "--- Ã‰poque 627/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0519 - policy_categorical_accuracy: 0.3648 - policy_loss: 2.8920 - value_loss: 0.1011 - value_mae: 0.2556\n",
            "\n",
            "--- Ã‰poque 628/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0618 - policy_categorical_accuracy: 0.3635 - policy_loss: 2.9026 - value_loss: 0.1005 - value_mae: 0.2542\n",
            "\n",
            "--- Ã‰poque 629/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0821 - policy_categorical_accuracy: 0.3582 - policy_loss: 2.9264 - value_loss: 0.0970 - value_mae: 0.2500\n",
            "\n",
            "--- Ã‰poque 630/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4974 - policy_categorical_accuracy: 0.4975 - policy_loss: 2.3398 - value_loss: 0.0990 - value_mae: 0.2535\n",
            "Epoch 1: val_loss improved from 2.34585 to 2.34029, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.4957 - policy_categorical_accuracy: 0.4978 - policy_loss: 2.3380 - value_loss: 0.0989 - value_mae: 0.2534 - val_loss: 2.3403 - val_policy_categorical_accuracy: 0.5412 - val_policy_loss: 2.1829 - val_value_loss: 0.0970 - val_value_mae: 0.2507 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 631/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1243 - policy_categorical_accuracy: 0.3496 - policy_loss: 2.9630 - value_loss: 0.1024 - value_mae: 0.2596\n",
            "\n",
            "--- Ã‰poque 632/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0844 - policy_categorical_accuracy: 0.3484 - policy_loss: 2.9284 - value_loss: 0.0974 - value_mae: 0.2504\n",
            "\n",
            "--- Ã‰poque 633/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0550 - policy_categorical_accuracy: 0.3637 - policy_loss: 2.8983 - value_loss: 0.0981 - value_mae: 0.2504\n",
            "\n",
            "--- Ã‰poque 634/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0448 - policy_categorical_accuracy: 0.3753 - policy_loss: 2.8876 - value_loss: 0.0985 - value_mae: 0.2521\n",
            "\n",
            "--- Ã‰poque 635/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4747 - policy_categorical_accuracy: 0.5028 - policy_loss: 2.3181 - value_loss: 0.0980 - value_mae: 0.2514\n",
            "Epoch 1: val_loss improved from 2.34029 to 2.33024, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.4738 - policy_categorical_accuracy: 0.5029 - policy_loss: 2.3171 - value_loss: 0.0979 - value_mae: 0.2514 - val_loss: 2.3302 - val_policy_categorical_accuracy: 0.5492 - val_policy_loss: 2.1715 - val_value_loss: 0.0978 - val_value_mae: 0.2510 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 636/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.0746 - policy_categorical_accuracy: 0.3674 - policy_loss: 2.9165 - value_loss: 0.0996 - value_mae: 0.2538\n",
            "\n",
            "--- Ã‰poque 637/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0913 - policy_categorical_accuracy: 0.3604 - policy_loss: 2.9331 - value_loss: 0.0995 - value_mae: 0.2540\n",
            "\n",
            "--- Ã‰poque 638/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0503 - policy_categorical_accuracy: 0.3606 - policy_loss: 2.8951 - value_loss: 0.0968 - value_mae: 0.2493\n",
            "\n",
            "--- Ã‰poque 639/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0912 - policy_categorical_accuracy: 0.3638 - policy_loss: 2.9348 - value_loss: 0.0979 - value_mae: 0.2525\n",
            "\n",
            "--- Ã‰poque 640/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4621 - policy_categorical_accuracy: 0.5059 - policy_loss: 2.3059 - value_loss: 0.0977 - value_mae: 0.2525\n",
            "Epoch 1: val_loss did not improve from 2.33024\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.4614 - policy_categorical_accuracy: 0.5060 - policy_loss: 2.3052 - value_loss: 0.0977 - value_mae: 0.2524 - val_loss: 2.3379 - val_policy_categorical_accuracy: 0.5454 - val_policy_loss: 2.1805 - val_value_loss: 0.0969 - val_value_mae: 0.2510 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 641/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0898 - policy_categorical_accuracy: 0.3517 - policy_loss: 2.9318 - value_loss: 0.0994 - value_mae: 0.2540\n",
            "\n",
            "--- Ã‰poque 642/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0942 - policy_categorical_accuracy: 0.3608 - policy_loss: 2.9375 - value_loss: 0.0982 - value_mae: 0.2511\n",
            "\n",
            "--- Ã‰poque 643/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0400 - policy_categorical_accuracy: 0.3625 - policy_loss: 2.8830 - value_loss: 0.0986 - value_mae: 0.2539\n",
            "\n",
            "--- Ã‰poque 644/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0810 - policy_categorical_accuracy: 0.3635 - policy_loss: 2.9229 - value_loss: 0.0995 - value_mae: 0.2535\n",
            "\n",
            "--- Ã‰poque 645/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4629 - policy_categorical_accuracy: 0.5042 - policy_loss: 2.3051 - value_loss: 0.0994 - value_mae: 0.2547\n",
            "Epoch 1: val_loss did not improve from 2.33024\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.4623 - policy_categorical_accuracy: 0.5044 - policy_loss: 2.3044 - value_loss: 0.0993 - value_mae: 0.2545 - val_loss: 2.3371 - val_policy_categorical_accuracy: 0.5433 - val_policy_loss: 2.1796 - val_value_loss: 0.0975 - val_value_mae: 0.2506 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 646/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0925 - policy_categorical_accuracy: 0.3592 - policy_loss: 2.9367 - value_loss: 0.0972 - value_mae: 0.2507\n",
            "\n",
            "--- Ã‰poque 647/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0302 - policy_categorical_accuracy: 0.3699 - policy_loss: 2.8732 - value_loss: 0.0985 - value_mae: 0.2515\n",
            "\n",
            "--- Ã‰poque 648/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1030 - policy_categorical_accuracy: 0.3523 - policy_loss: 2.9471 - value_loss: 0.0973 - value_mae: 0.2506\n",
            "\n",
            "--- Ã‰poque 649/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0711 - policy_categorical_accuracy: 0.3616 - policy_loss: 2.9139 - value_loss: 0.0987 - value_mae: 0.2521\n",
            "\n",
            "--- Ã‰poque 650/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.4584 - policy_categorical_accuracy: 0.5111 - policy_loss: 2.3043 - value_loss: 0.0957 - value_mae: 0.2479\n",
            "Epoch 1: val_loss improved from 2.33024 to 2.32340, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.4580 - policy_categorical_accuracy: 0.5112 - policy_loss: 2.3039 - value_loss: 0.0958 - value_mae: 0.2480 - val_loss: 2.3234 - val_policy_categorical_accuracy: 0.5513 - val_policy_loss: 2.1645 - val_value_loss: 0.0978 - val_value_mae: 0.2510 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 651/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1059 - policy_categorical_accuracy: 0.3536 - policy_loss: 2.9495 - value_loss: 0.0979 - value_mae: 0.2515\n",
            "\n",
            "--- Ã‰poque 652/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0350 - policy_categorical_accuracy: 0.3720 - policy_loss: 2.8785 - value_loss: 0.0980 - value_mae: 0.2488\n",
            "\n",
            "--- Ã‰poque 653/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0166 - policy_categorical_accuracy: 0.3690 - policy_loss: 2.8603 - value_loss: 0.0978 - value_mae: 0.2505\n",
            "\n",
            "--- Ã‰poque 654/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0911 - policy_categorical_accuracy: 0.3518 - policy_loss: 2.9357 - value_loss: 0.0970 - value_mae: 0.2498\n",
            "\n",
            "--- Ã‰poque 655/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4383 - policy_categorical_accuracy: 0.5168 - policy_loss: 2.2823 - value_loss: 0.0976 - value_mae: 0.2508\n",
            "Epoch 1: val_loss improved from 2.32340 to 2.31156, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.4381 - policy_categorical_accuracy: 0.5166 - policy_loss: 2.2821 - value_loss: 0.0976 - value_mae: 0.2508 - val_loss: 2.3116 - val_policy_categorical_accuracy: 0.5544 - val_policy_loss: 2.1517 - val_value_loss: 0.0986 - val_value_mae: 0.2511 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 656/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1167 - policy_categorical_accuracy: 0.3466 - policy_loss: 2.9600 - value_loss: 0.0983 - value_mae: 0.2525\n",
            "\n",
            "--- Ã‰poque 657/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0770 - policy_categorical_accuracy: 0.3628 - policy_loss: 2.9226 - value_loss: 0.0961 - value_mae: 0.2494\n",
            "\n",
            "--- Ã‰poque 658/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0603 - policy_categorical_accuracy: 0.3629 - policy_loss: 2.9010 - value_loss: 0.1008 - value_mae: 0.2549\n",
            "\n",
            "--- Ã‰poque 659/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0765 - policy_categorical_accuracy: 0.3594 - policy_loss: 2.9202 - value_loss: 0.0981 - value_mae: 0.2510\n",
            "\n",
            "--- Ã‰poque 660/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4747 - policy_categorical_accuracy: 0.5139 - policy_loss: 2.3203 - value_loss: 0.0961 - value_mae: 0.2490\n",
            "Epoch 1: val_loss did not improve from 2.31156\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 2.4742 - policy_categorical_accuracy: 0.5140 - policy_loss: 2.3197 - value_loss: 0.0961 - value_mae: 0.2490 - val_loss: 2.3176 - val_policy_categorical_accuracy: 0.5528 - val_policy_loss: 2.1549 - val_value_loss: 0.1017 - val_value_mae: 0.2523 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 661/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0578 - policy_categorical_accuracy: 0.3619 - policy_loss: 2.8989 - value_loss: 0.1005 - value_mae: 0.2541\n",
            "\n",
            "--- Ã‰poque 662/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0703 - policy_categorical_accuracy: 0.3641 - policy_loss: 2.9135 - value_loss: 0.0983 - value_mae: 0.2530\n",
            "\n",
            "--- Ã‰poque 663/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0762 - policy_categorical_accuracy: 0.3622 - policy_loss: 2.9179 - value_loss: 0.1001 - value_mae: 0.2549\n",
            "\n",
            "--- Ã‰poque 664/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0722 - policy_categorical_accuracy: 0.3628 - policy_loss: 2.9117 - value_loss: 0.1022 - value_mae: 0.2586\n",
            "\n",
            "--- Ã‰poque 665/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4539 - policy_categorical_accuracy: 0.5091 - policy_loss: 2.2974 - value_loss: 0.0982 - value_mae: 0.2520\n",
            "Epoch 1: val_loss improved from 2.31156 to 2.31048, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.4530 - policy_categorical_accuracy: 0.5092 - policy_loss: 2.2964 - value_loss: 0.0981 - value_mae: 0.2519 - val_loss: 2.3105 - val_policy_categorical_accuracy: 0.5506 - val_policy_loss: 2.1504 - val_value_loss: 0.0997 - val_value_mae: 0.2506 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 666/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.1187 - policy_categorical_accuracy: 0.3550 - policy_loss: 2.9619 - value_loss: 0.0986 - value_mae: 0.2517\n",
            "\n",
            "--- Ã‰poque 667/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0142 - policy_categorical_accuracy: 0.3675 - policy_loss: 2.8581 - value_loss: 0.0977 - value_mae: 0.2487\n",
            "\n",
            "--- Ã‰poque 668/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0088 - policy_categorical_accuracy: 0.3763 - policy_loss: 2.8513 - value_loss: 0.0993 - value_mae: 0.2509\n",
            "\n",
            "--- Ã‰poque 669/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0681 - policy_categorical_accuracy: 0.3577 - policy_loss: 2.9129 - value_loss: 0.0969 - value_mae: 0.2488\n",
            "\n",
            "--- Ã‰poque 670/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4722 - policy_categorical_accuracy: 0.4964 - policy_loss: 2.3175 - value_loss: 0.0965 - value_mae: 0.2489\n",
            "Epoch 1: val_loss did not improve from 2.31048\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.4703 - policy_categorical_accuracy: 0.4970 - policy_loss: 2.3155 - value_loss: 0.0965 - value_mae: 0.2490 - val_loss: 2.3223 - val_policy_categorical_accuracy: 0.5441 - val_policy_loss: 2.1645 - val_value_loss: 0.0961 - val_value_mae: 0.2503 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 671/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.1367 - policy_categorical_accuracy: 0.3604 - policy_loss: 2.9766 - value_loss: 0.1019 - value_mae: 0.2577\n",
            "\n",
            "--- Ã‰poque 672/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0769 - policy_categorical_accuracy: 0.3502 - policy_loss: 2.9198 - value_loss: 0.0988 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 673/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0497 - policy_categorical_accuracy: 0.3691 - policy_loss: 2.8961 - value_loss: 0.0955 - value_mae: 0.2485\n",
            "\n",
            "--- Ã‰poque 674/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0667 - policy_categorical_accuracy: 0.3585 - policy_loss: 2.9091 - value_loss: 0.0994 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 675/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.4276 - policy_categorical_accuracy: 0.5130 - policy_loss: 2.2722 - value_loss: 0.0974 - value_mae: 0.2510\n",
            "Epoch 1: val_loss improved from 2.31048 to 2.29802, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.4271 - policy_categorical_accuracy: 0.5132 - policy_loss: 2.2715 - value_loss: 0.0974 - value_mae: 0.2510 - val_loss: 2.2980 - val_policy_categorical_accuracy: 0.5545 - val_policy_loss: 2.1404 - val_value_loss: 0.0969 - val_value_mae: 0.2503 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 676/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0840 - policy_categorical_accuracy: 0.3559 - policy_loss: 2.9269 - value_loss: 0.0989 - value_mae: 0.2520\n",
            "\n",
            "--- Ã‰poque 677/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0894 - policy_categorical_accuracy: 0.3511 - policy_loss: 2.9340 - value_loss: 0.0977 - value_mae: 0.2511\n",
            "\n",
            "--- Ã‰poque 678/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0137 - policy_categorical_accuracy: 0.3708 - policy_loss: 2.8619 - value_loss: 0.0937 - value_mae: 0.2451\n",
            "\n",
            "--- Ã‰poque 679/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0650 - policy_categorical_accuracy: 0.3640 - policy_loss: 2.9077 - value_loss: 0.0993 - value_mae: 0.2518\n",
            "\n",
            "--- Ã‰poque 680/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4385 - policy_categorical_accuracy: 0.5118 - policy_loss: 2.2840 - value_loss: 0.0964 - value_mae: 0.2500\n",
            "Epoch 1: val_loss improved from 2.29802 to 2.28532, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.4375 - policy_categorical_accuracy: 0.5121 - policy_loss: 2.2828 - value_loss: 0.0964 - value_mae: 0.2500 - val_loss: 2.2853 - val_policy_categorical_accuracy: 0.5518 - val_policy_loss: 2.1286 - val_value_loss: 0.0967 - val_value_mae: 0.2495 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 681/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0373 - policy_categorical_accuracy: 0.3671 - policy_loss: 2.8784 - value_loss: 0.1007 - value_mae: 0.2546\n",
            "\n",
            "--- Ã‰poque 682/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0497 - policy_categorical_accuracy: 0.3585 - policy_loss: 2.8945 - value_loss: 0.0971 - value_mae: 0.2495\n",
            "\n",
            "--- Ã‰poque 683/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0679 - policy_categorical_accuracy: 0.3599 - policy_loss: 2.9148 - value_loss: 0.0951 - value_mae: 0.2463\n",
            "\n",
            "--- Ã‰poque 684/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0427 - policy_categorical_accuracy: 0.3660 - policy_loss: 2.8862 - value_loss: 0.0985 - value_mae: 0.2506\n",
            "\n",
            "--- Ã‰poque 685/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4400 - policy_categorical_accuracy: 0.5099 - policy_loss: 2.2867 - value_loss: 0.0953 - value_mae: 0.2498\n",
            "Epoch 1: val_loss did not improve from 2.28532\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.4388 - policy_categorical_accuracy: 0.5102 - policy_loss: 2.2855 - value_loss: 0.0954 - value_mae: 0.2499 - val_loss: 2.2866 - val_policy_categorical_accuracy: 0.5554 - val_policy_loss: 2.1299 - val_value_loss: 0.0964 - val_value_mae: 0.2499 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 686/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0828 - policy_categorical_accuracy: 0.3593 - policy_loss: 2.9292 - value_loss: 0.0954 - value_mae: 0.2483\n",
            "\n",
            "--- Ã‰poque 687/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0693 - policy_categorical_accuracy: 0.3581 - policy_loss: 2.9127 - value_loss: 0.0987 - value_mae: 0.2521\n",
            "\n",
            "--- Ã‰poque 688/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0968 - policy_categorical_accuracy: 0.3622 - policy_loss: 2.9416 - value_loss: 0.0971 - value_mae: 0.2495\n",
            "\n",
            "--- Ã‰poque 689/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0277 - policy_categorical_accuracy: 0.3714 - policy_loss: 2.8725 - value_loss: 0.0971 - value_mae: 0.2509\n",
            "\n",
            "--- Ã‰poque 690/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4277 - policy_categorical_accuracy: 0.5080 - policy_loss: 2.2757 - value_loss: 0.0941 - value_mae: 0.2463\n",
            "Epoch 1: val_loss improved from 2.28532 to 2.28476, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.4268 - policy_categorical_accuracy: 0.5083 - policy_loss: 2.2745 - value_loss: 0.0941 - value_mae: 0.2464 - val_loss: 2.2848 - val_policy_categorical_accuracy: 0.5573 - val_policy_loss: 2.1278 - val_value_loss: 0.0965 - val_value_mae: 0.2493 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 691/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0383 - policy_categorical_accuracy: 0.3664 - policy_loss: 2.8814 - value_loss: 0.0987 - value_mae: 0.2530\n",
            "\n",
            "--- Ã‰poque 692/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0569 - policy_categorical_accuracy: 0.3677 - policy_loss: 2.8990 - value_loss: 0.1002 - value_mae: 0.2550\n",
            "\n",
            "--- Ã‰poque 693/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0601 - policy_categorical_accuracy: 0.3621 - policy_loss: 2.9015 - value_loss: 0.1006 - value_mae: 0.2550\n",
            "\n",
            "--- Ã‰poque 694/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0594 - policy_categorical_accuracy: 0.3715 - policy_loss: 2.9024 - value_loss: 0.0990 - value_mae: 0.2528\n",
            "\n",
            "--- Ã‰poque 695/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4459 - policy_categorical_accuracy: 0.5190 - policy_loss: 2.2902 - value_loss: 0.0979 - value_mae: 0.2527\n",
            "Epoch 1: val_loss did not improve from 2.28476\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.4442 - policy_categorical_accuracy: 0.5190 - policy_loss: 2.2884 - value_loss: 0.0978 - value_mae: 0.2526 - val_loss: 2.2857 - val_policy_categorical_accuracy: 0.5561 - val_policy_loss: 2.1297 - val_value_loss: 0.0961 - val_value_mae: 0.2494 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 696/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0872 - policy_categorical_accuracy: 0.3597 - policy_loss: 2.9330 - value_loss: 0.0963 - value_mae: 0.2486\n",
            "\n",
            "--- Ã‰poque 697/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0766 - policy_categorical_accuracy: 0.3664 - policy_loss: 2.9209 - value_loss: 0.0977 - value_mae: 0.2507\n",
            "\n",
            "--- Ã‰poque 698/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0335 - policy_categorical_accuracy: 0.3690 - policy_loss: 2.8807 - value_loss: 0.0950 - value_mae: 0.2468\n",
            "\n",
            "--- Ã‰poque 699/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0562 - policy_categorical_accuracy: 0.3606 - policy_loss: 2.8981 - value_loss: 0.1002 - value_mae: 0.2537\n",
            "\n",
            "--- Ã‰poque 700/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4311 - policy_categorical_accuracy: 0.5084 - policy_loss: 2.2767 - value_loss: 0.0965 - value_mae: 0.2498\n",
            "Epoch 1: val_loss improved from 2.28476 to 2.28436, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.4300 - policy_categorical_accuracy: 0.5088 - policy_loss: 2.2757 - value_loss: 0.0965 - value_mae: 0.2498 - val_loss: 2.2844 - val_policy_categorical_accuracy: 0.5560 - val_policy_loss: 2.1277 - val_value_loss: 0.0964 - val_value_mae: 0.2501 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 701/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1104 - policy_categorical_accuracy: 0.3637 - policy_loss: 2.9562 - value_loss: 0.0963 - value_mae: 0.2492\n",
            "\n",
            "--- Ã‰poque 702/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0441 - policy_categorical_accuracy: 0.3696 - policy_loss: 2.8885 - value_loss: 0.0978 - value_mae: 0.2500\n",
            "\n",
            "--- Ã‰poque 703/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0263 - policy_categorical_accuracy: 0.3717 - policy_loss: 2.8710 - value_loss: 0.0971 - value_mae: 0.2495\n",
            "\n",
            "--- Ã‰poque 704/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0299 - policy_categorical_accuracy: 0.3702 - policy_loss: 2.8726 - value_loss: 0.0995 - value_mae: 0.2535\n",
            "\n",
            "--- Ã‰poque 705/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4371 - policy_categorical_accuracy: 0.5151 - policy_loss: 2.2817 - value_loss: 0.0976 - value_mae: 0.2522\n",
            "Epoch 1: val_loss improved from 2.28436 to 2.27454, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.4356 - policy_categorical_accuracy: 0.5155 - policy_loss: 2.2801 - value_loss: 0.0976 - value_mae: 0.2521 - val_loss: 2.2745 - val_policy_categorical_accuracy: 0.5584 - val_policy_loss: 2.1178 - val_value_loss: 0.0969 - val_value_mae: 0.2502 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 706/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0222 - policy_categorical_accuracy: 0.3703 - policy_loss: 2.8650 - value_loss: 0.0995 - value_mae: 0.2513\n",
            "\n",
            "--- Ã‰poque 707/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0721 - policy_categorical_accuracy: 0.3663 - policy_loss: 2.9175 - value_loss: 0.0969 - value_mae: 0.2493\n",
            "\n",
            "--- Ã‰poque 708/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0373 - policy_categorical_accuracy: 0.3756 - policy_loss: 2.8829 - value_loss: 0.0966 - value_mae: 0.2497\n",
            "\n",
            "--- Ã‰poque 709/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0313 - policy_categorical_accuracy: 0.3711 - policy_loss: 2.8738 - value_loss: 0.0998 - value_mae: 0.2537\n",
            "\n",
            "--- Ã‰poque 710/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4115 - policy_categorical_accuracy: 0.5277 - policy_loss: 2.2585 - value_loss: 0.0953 - value_mae: 0.2470\n",
            "Epoch 1: val_loss improved from 2.27454 to 2.25714, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.4106 - policy_categorical_accuracy: 0.5277 - policy_loss: 2.2576 - value_loss: 0.0954 - value_mae: 0.2471 - val_loss: 2.2571 - val_policy_categorical_accuracy: 0.5645 - val_policy_loss: 2.1014 - val_value_loss: 0.0957 - val_value_mae: 0.2487 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 711/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0713 - policy_categorical_accuracy: 0.3620 - policy_loss: 2.9150 - value_loss: 0.0987 - value_mae: 0.2516\n",
            "\n",
            "--- Ã‰poque 712/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0309 - policy_categorical_accuracy: 0.3719 - policy_loss: 2.8759 - value_loss: 0.0972 - value_mae: 0.2499\n",
            "\n",
            "--- Ã‰poque 713/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1145 - policy_categorical_accuracy: 0.3514 - policy_loss: 2.9558 - value_loss: 0.1013 - value_mae: 0.2562\n",
            "\n",
            "--- Ã‰poque 714/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0399 - policy_categorical_accuracy: 0.3590 - policy_loss: 2.8859 - value_loss: 0.0962 - value_mae: 0.2481\n",
            "\n",
            "--- Ã‰poque 715/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.4103 - policy_categorical_accuracy: 0.5258 - policy_loss: 2.2550 - value_loss: 0.0977 - value_mae: 0.2521\n",
            "Epoch 1: val_loss did not improve from 2.25714\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 2.4096 - policy_categorical_accuracy: 0.5256 - policy_loss: 2.2545 - value_loss: 0.0977 - value_mae: 0.2520 - val_loss: 2.2727 - val_policy_categorical_accuracy: 0.5620 - val_policy_loss: 2.1169 - val_value_loss: 0.0961 - val_value_mae: 0.2496 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 716/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1306 - policy_categorical_accuracy: 0.3488 - policy_loss: 2.9739 - value_loss: 0.0991 - value_mae: 0.2519\n",
            "\n",
            "--- Ã‰poque 717/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0447 - policy_categorical_accuracy: 0.3646 - policy_loss: 2.8897 - value_loss: 0.0973 - value_mae: 0.2499\n",
            "\n",
            "--- Ã‰poque 718/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0261 - policy_categorical_accuracy: 0.3655 - policy_loss: 2.8694 - value_loss: 0.0992 - value_mae: 0.2512\n",
            "\n",
            "--- Ã‰poque 719/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0917 - policy_categorical_accuracy: 0.3575 - policy_loss: 2.9366 - value_loss: 0.0974 - value_mae: 0.2494\n",
            "\n",
            "--- Ã‰poque 720/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4248 - policy_categorical_accuracy: 0.5202 - policy_loss: 2.2718 - value_loss: 0.0953 - value_mae: 0.2473\n",
            "Epoch 1: val_loss improved from 2.25714 to 2.25626, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.4234 - policy_categorical_accuracy: 0.5204 - policy_loss: 2.2703 - value_loss: 0.0954 - value_mae: 0.2473 - val_loss: 2.2563 - val_policy_categorical_accuracy: 0.5632 - val_policy_loss: 2.0998 - val_value_loss: 0.0970 - val_value_mae: 0.2491 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 721/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0522 - policy_categorical_accuracy: 0.3742 - policy_loss: 2.8967 - value_loss: 0.0979 - value_mae: 0.2528\n",
            "\n",
            "--- Ã‰poque 722/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0074 - policy_categorical_accuracy: 0.3773 - policy_loss: 2.8519 - value_loss: 0.0978 - value_mae: 0.2508\n",
            "\n",
            "--- Ã‰poque 723/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0336 - policy_categorical_accuracy: 0.3671 - policy_loss: 2.8780 - value_loss: 0.0981 - value_mae: 0.2507\n",
            "\n",
            "--- Ã‰poque 724/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0728 - policy_categorical_accuracy: 0.3601 - policy_loss: 2.9187 - value_loss: 0.0966 - value_mae: 0.2498\n",
            "\n",
            "--- Ã‰poque 725/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.4251 - policy_categorical_accuracy: 0.5147 - policy_loss: 2.2732 - value_loss: 0.0944 - value_mae: 0.2464\n",
            "Epoch 1: val_loss improved from 2.25626 to 2.25548, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.4246 - policy_categorical_accuracy: 0.5148 - policy_loss: 2.2727 - value_loss: 0.0944 - value_mae: 0.2464 - val_loss: 2.2555 - val_policy_categorical_accuracy: 0.5671 - val_policy_loss: 2.1002 - val_value_loss: 0.0961 - val_value_mae: 0.2488 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 726/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1151 - policy_categorical_accuracy: 0.3566 - policy_loss: 2.9590 - value_loss: 0.0987 - value_mae: 0.2527\n",
            "\n",
            "--- Ã‰poque 727/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0395 - policy_categorical_accuracy: 0.3622 - policy_loss: 2.8824 - value_loss: 0.0994 - value_mae: 0.2522\n",
            "\n",
            "--- Ã‰poque 728/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0258 - policy_categorical_accuracy: 0.3740 - policy_loss: 2.8717 - value_loss: 0.0966 - value_mae: 0.2489\n",
            "\n",
            "--- Ã‰poque 729/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0538 - policy_categorical_accuracy: 0.3589 - policy_loss: 2.9003 - value_loss: 0.0960 - value_mae: 0.2487\n",
            "\n",
            "--- Ã‰poque 730/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.3945 - policy_categorical_accuracy: 0.5268 - policy_loss: 2.2409 - value_loss: 0.0961 - value_mae: 0.2494\n",
            "Epoch 1: val_loss did not improve from 2.25548\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.3938 - policy_categorical_accuracy: 0.5267 - policy_loss: 2.2402 - value_loss: 0.0961 - value_mae: 0.2493 - val_loss: 2.2630 - val_policy_categorical_accuracy: 0.5641 - val_policy_loss: 2.1076 - val_value_loss: 0.0956 - val_value_mae: 0.2488 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 731/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0682 - policy_categorical_accuracy: 0.3657 - policy_loss: 2.9155 - value_loss: 0.0953 - value_mae: 0.2456\n",
            "\n",
            "--- Ã‰poque 732/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0528 - policy_categorical_accuracy: 0.3677 - policy_loss: 2.8964 - value_loss: 0.0988 - value_mae: 0.2512\n",
            "\n",
            "--- Ã‰poque 733/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0347 - policy_categorical_accuracy: 0.3555 - policy_loss: 2.8802 - value_loss: 0.0971 - value_mae: 0.2494\n",
            "\n",
            "--- Ã‰poque 734/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0531 - policy_categorical_accuracy: 0.3655 - policy_loss: 2.8962 - value_loss: 0.0994 - value_mae: 0.2521\n",
            "\n",
            "--- Ã‰poque 735/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3795 - policy_categorical_accuracy: 0.5227 - policy_loss: 2.2263 - value_loss: 0.0958 - value_mae: 0.2492\n",
            "Epoch 1: val_loss improved from 2.25548 to 2.24571, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 2.3793 - policy_categorical_accuracy: 0.5228 - policy_loss: 2.2260 - value_loss: 0.0958 - value_mae: 0.2492 - val_loss: 2.2457 - val_policy_categorical_accuracy: 0.5667 - val_policy_loss: 2.0898 - val_value_loss: 0.0964 - val_value_mae: 0.2489 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 736/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0735 - policy_categorical_accuracy: 0.3634 - policy_loss: 2.9193 - value_loss: 0.0968 - value_mae: 0.2492\n",
            "\n",
            "--- Ã‰poque 737/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0375 - policy_categorical_accuracy: 0.3708 - policy_loss: 2.8809 - value_loss: 0.0990 - value_mae: 0.2531\n",
            "\n",
            "--- Ã‰poque 738/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0079 - policy_categorical_accuracy: 0.3796 - policy_loss: 2.8511 - value_loss: 0.0994 - value_mae: 0.2531\n",
            "\n",
            "--- Ã‰poque 739/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0426 - policy_categorical_accuracy: 0.3686 - policy_loss: 2.8867 - value_loss: 0.0984 - value_mae: 0.2521\n",
            "\n",
            "--- Ã‰poque 740/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.4048 - policy_categorical_accuracy: 0.5244 - policy_loss: 2.2500 - value_loss: 0.0975 - value_mae: 0.2512\n",
            "Epoch 1: val_loss did not improve from 2.24571\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.4036 - policy_categorical_accuracy: 0.5245 - policy_loss: 2.2488 - value_loss: 0.0974 - value_mae: 0.2512 - val_loss: 2.2494 - val_policy_categorical_accuracy: 0.5672 - val_policy_loss: 2.0928 - val_value_loss: 0.0962 - val_value_mae: 0.2475 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 741/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0630 - policy_categorical_accuracy: 0.3636 - policy_loss: 2.9063 - value_loss: 0.0994 - value_mae: 0.2516\n",
            "\n",
            "--- Ã‰poque 742/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0157 - policy_categorical_accuracy: 0.3664 - policy_loss: 2.8617 - value_loss: 0.0966 - value_mae: 0.2490\n",
            "\n",
            "--- Ã‰poque 743/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0639 - policy_categorical_accuracy: 0.3639 - policy_loss: 2.9093 - value_loss: 0.0974 - value_mae: 0.2496\n",
            "\n",
            "--- Ã‰poque 744/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0105 - policy_categorical_accuracy: 0.3655 - policy_loss: 2.8560 - value_loss: 0.0972 - value_mae: 0.2485\n",
            "\n",
            "--- Ã‰poque 745/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4083 - policy_categorical_accuracy: 0.5182 - policy_loss: 2.2549 - value_loss: 0.0961 - value_mae: 0.2486\n",
            "Epoch 1: val_loss did not improve from 2.24571\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.4069 - policy_categorical_accuracy: 0.5185 - policy_loss: 2.2534 - value_loss: 0.0961 - value_mae: 0.2486 - val_loss: 2.2479 - val_policy_categorical_accuracy: 0.5690 - val_policy_loss: 2.0918 - val_value_loss: 0.0959 - val_value_mae: 0.2495 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 746/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0753 - policy_categorical_accuracy: 0.3649 - policy_loss: 2.9219 - value_loss: 0.0962 - value_mae: 0.2484\n",
            "\n",
            "--- Ã‰poque 747/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0584 - policy_categorical_accuracy: 0.3642 - policy_loss: 2.9019 - value_loss: 0.0993 - value_mae: 0.2530\n",
            "\n",
            "--- Ã‰poque 748/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 3.0755 - policy_categorical_accuracy: 0.3593 - policy_loss: 2.9209 - value_loss: 0.0974 - value_mae: 0.2497\n",
            "\n",
            "--- Ã‰poque 749/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0661 - policy_categorical_accuracy: 0.3562 - policy_loss: 2.9107 - value_loss: 0.0980 - value_mae: 0.2503\n",
            "\n",
            "--- Ã‰poque 750/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3641 - policy_categorical_accuracy: 0.5300 - policy_loss: 2.2125 - value_loss: 0.0943 - value_mae: 0.2463\n",
            "Epoch 1: val_loss improved from 2.24571 to 2.24023, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.3641 - policy_categorical_accuracy: 0.5300 - policy_loss: 2.2126 - value_loss: 0.0944 - value_mae: 0.2464 - val_loss: 2.2402 - val_policy_categorical_accuracy: 0.5718 - val_policy_loss: 2.0852 - val_value_loss: 0.0956 - val_value_mae: 0.2479 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 751/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0921 - policy_categorical_accuracy: 0.3583 - policy_loss: 2.9340 - value_loss: 0.1004 - value_mae: 0.2522\n",
            "\n",
            "--- Ã‰poque 752/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0495 - policy_categorical_accuracy: 0.3608 - policy_loss: 2.8960 - value_loss: 0.0962 - value_mae: 0.2473\n",
            "\n",
            "--- Ã‰poque 753/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 3.0390 - policy_categorical_accuracy: 0.3662 - policy_loss: 2.8843 - value_loss: 0.0976 - value_mae: 0.2494\n",
            "\n",
            "--- Ã‰poque 754/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0336 - policy_categorical_accuracy: 0.3708 - policy_loss: 2.8730 - value_loss: 0.1033 - value_mae: 0.2584\n",
            "\n",
            "--- Ã‰poque 755/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4102 - policy_categorical_accuracy: 0.5171 - policy_loss: 2.2564 - value_loss: 0.0965 - value_mae: 0.2498\n",
            "Epoch 1: val_loss improved from 2.24023 to 2.22588, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.4085 - policy_categorical_accuracy: 0.5175 - policy_loss: 2.2548 - value_loss: 0.0965 - value_mae: 0.2498 - val_loss: 2.2259 - val_policy_categorical_accuracy: 0.5711 - val_policy_loss: 2.0710 - val_value_loss: 0.0954 - val_value_mae: 0.2473 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 756/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0464 - policy_categorical_accuracy: 0.3668 - policy_loss: 2.8943 - value_loss: 0.0948 - value_mae: 0.2461\n",
            "\n",
            "--- Ã‰poque 757/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0493 - policy_categorical_accuracy: 0.3647 - policy_loss: 2.8925 - value_loss: 0.0996 - value_mae: 0.2520\n",
            "\n",
            "--- Ã‰poque 758/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0219 - policy_categorical_accuracy: 0.3716 - policy_loss: 2.8682 - value_loss: 0.0966 - value_mae: 0.2502\n",
            "\n",
            "--- Ã‰poque 759/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0920 - policy_categorical_accuracy: 0.3585 - policy_loss: 2.9380 - value_loss: 0.0968 - value_mae: 0.2488\n",
            "\n",
            "--- Ã‰poque 760/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3942 - policy_categorical_accuracy: 0.5249 - policy_loss: 2.2387 - value_loss: 0.0983 - value_mae: 0.2526\n",
            "Epoch 1: val_loss improved from 2.22588 to 2.22365, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.3930 - policy_categorical_accuracy: 0.5251 - policy_loss: 2.2376 - value_loss: 0.0983 - value_mae: 0.2525 - val_loss: 2.2237 - val_policy_categorical_accuracy: 0.5781 - val_policy_loss: 2.0675 - val_value_loss: 0.0964 - val_value_mae: 0.2472 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 761/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0628 - policy_categorical_accuracy: 0.3544 - policy_loss: 2.9072 - value_loss: 0.0985 - value_mae: 0.2508\n",
            "\n",
            "--- Ã‰poque 762/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0162 - policy_categorical_accuracy: 0.3627 - policy_loss: 2.8609 - value_loss: 0.0980 - value_mae: 0.2509\n",
            "\n",
            "--- Ã‰poque 763/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0770 - policy_categorical_accuracy: 0.3553 - policy_loss: 2.9247 - value_loss: 0.0952 - value_mae: 0.2445\n",
            "\n",
            "--- Ã‰poque 764/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0016 - policy_categorical_accuracy: 0.3700 - policy_loss: 2.8454 - value_loss: 0.0993 - value_mae: 0.2522\n",
            "\n",
            "--- Ã‰poque 765/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3865 - policy_categorical_accuracy: 0.5246 - policy_loss: 2.2337 - value_loss: 0.0957 - value_mae: 0.2488\n",
            "Epoch 1: val_loss did not improve from 2.22365\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.3852 - policy_categorical_accuracy: 0.5249 - policy_loss: 2.2324 - value_loss: 0.0957 - value_mae: 0.2488 - val_loss: 2.2307 - val_policy_categorical_accuracy: 0.5748 - val_policy_loss: 2.0749 - val_value_loss: 0.0958 - val_value_mae: 0.2489 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 766/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0890 - policy_categorical_accuracy: 0.3637 - policy_loss: 2.9333 - value_loss: 0.0986 - value_mae: 0.2521\n",
            "\n",
            "--- Ã‰poque 767/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0308 - policy_categorical_accuracy: 0.3724 - policy_loss: 2.8737 - value_loss: 0.1001 - value_mae: 0.2544\n",
            "\n",
            "--- Ã‰poque 768/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0800 - policy_categorical_accuracy: 0.3624 - policy_loss: 2.9255 - value_loss: 0.0975 - value_mae: 0.2490\n",
            "\n",
            "--- Ã‰poque 769/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0218 - policy_categorical_accuracy: 0.3735 - policy_loss: 2.8691 - value_loss: 0.0957 - value_mae: 0.2479\n",
            "\n",
            "--- Ã‰poque 770/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.3703 - policy_categorical_accuracy: 0.5301 - policy_loss: 2.2168 - value_loss: 0.0964 - value_mae: 0.2491\n",
            "Epoch 1: val_loss did not improve from 2.22365\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.3695 - policy_categorical_accuracy: 0.5304 - policy_loss: 2.2160 - value_loss: 0.0965 - value_mae: 0.2491 - val_loss: 2.2272 - val_policy_categorical_accuracy: 0.5802 - val_policy_loss: 2.0681 - val_value_loss: 0.0983 - val_value_mae: 0.2492 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 771/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0963 - policy_categorical_accuracy: 0.3539 - policy_loss: 2.9407 - value_loss: 0.0984 - value_mae: 0.2516\n",
            "\n",
            "--- Ã‰poque 772/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0747 - policy_categorical_accuracy: 0.3593 - policy_loss: 2.9195 - value_loss: 0.0980 - value_mae: 0.2524\n",
            "\n",
            "--- Ã‰poque 773/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0311 - policy_categorical_accuracy: 0.3657 - policy_loss: 2.8752 - value_loss: 0.0989 - value_mae: 0.2508\n",
            "\n",
            "--- Ã‰poque 774/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0811 - policy_categorical_accuracy: 0.3595 - policy_loss: 2.9270 - value_loss: 0.0974 - value_mae: 0.2507\n",
            "\n",
            "--- Ã‰poque 775/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3790 - policy_categorical_accuracy: 0.5312 - policy_loss: 2.2262 - value_loss: 0.0958 - value_mae: 0.2490\n",
            "Epoch 1: val_loss improved from 2.22365 to 2.21032, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - loss: 2.3784 - policy_categorical_accuracy: 0.5313 - policy_loss: 2.2258 - value_loss: 0.0958 - value_mae: 0.2490 - val_loss: 2.2103 - val_policy_categorical_accuracy: 0.5816 - val_policy_loss: 2.0548 - val_value_loss: 0.0958 - val_value_mae: 0.2486 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 776/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0961 - policy_categorical_accuracy: 0.3604 - policy_loss: 2.9401 - value_loss: 0.0992 - value_mae: 0.2531\n",
            "\n",
            "--- Ã‰poque 777/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0386 - policy_categorical_accuracy: 0.3581 - policy_loss: 2.8827 - value_loss: 0.0987 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 778/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0850 - policy_categorical_accuracy: 0.3530 - policy_loss: 2.9312 - value_loss: 0.0969 - value_mae: 0.2497\n",
            "\n",
            "--- Ã‰poque 779/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0292 - policy_categorical_accuracy: 0.3702 - policy_loss: 2.8757 - value_loss: 0.0965 - value_mae: 0.2489\n",
            "\n",
            "--- Ã‰poque 780/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3952 - policy_categorical_accuracy: 0.5230 - policy_loss: 2.2430 - value_loss: 0.0953 - value_mae: 0.2481\n",
            "Epoch 1: val_loss did not improve from 2.21032\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 2.3939 - policy_categorical_accuracy: 0.5233 - policy_loss: 2.2416 - value_loss: 0.0954 - value_mae: 0.2482 - val_loss: 2.2320 - val_policy_categorical_accuracy: 0.5696 - val_policy_loss: 2.0738 - val_value_loss: 0.0983 - val_value_mae: 0.2495 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 781/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0848 - policy_categorical_accuracy: 0.3642 - policy_loss: 2.9316 - value_loss: 0.0962 - value_mae: 0.2496\n",
            "\n",
            "--- Ã‰poque 782/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0424 - policy_categorical_accuracy: 0.3714 - policy_loss: 2.8858 - value_loss: 0.0997 - value_mae: 0.2532\n",
            "\n",
            "--- Ã‰poque 783/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0323 - policy_categorical_accuracy: 0.3697 - policy_loss: 2.8786 - value_loss: 0.0967 - value_mae: 0.2491\n",
            "\n",
            "--- Ã‰poque 784/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0254 - policy_categorical_accuracy: 0.3725 - policy_loss: 2.8706 - value_loss: 0.0975 - value_mae: 0.2498\n",
            "\n",
            "--- Ã‰poque 785/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3842 - policy_categorical_accuracy: 0.5215 - policy_loss: 2.2315 - value_loss: 0.0958 - value_mae: 0.2490\n",
            "Epoch 1: val_loss improved from 2.21032 to 2.21002, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 2.3825 - policy_categorical_accuracy: 0.5220 - policy_loss: 2.2302 - value_loss: 0.0958 - value_mae: 0.2489 - val_loss: 2.2100 - val_policy_categorical_accuracy: 0.5777 - val_policy_loss: 2.0552 - val_value_loss: 0.0949 - val_value_mae: 0.2478 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 786/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1123 - policy_categorical_accuracy: 0.3604 - policy_loss: 2.9569 - value_loss: 0.0987 - value_mae: 0.2502\n",
            "\n",
            "--- Ã‰poque 787/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0449 - policy_categorical_accuracy: 0.3678 - policy_loss: 2.8910 - value_loss: 0.0970 - value_mae: 0.2493\n",
            "\n",
            "--- Ã‰poque 788/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0338 - policy_categorical_accuracy: 0.3658 - policy_loss: 2.8809 - value_loss: 0.0957 - value_mae: 0.2485\n",
            "\n",
            "--- Ã‰poque 789/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0061 - policy_categorical_accuracy: 0.3685 - policy_loss: 2.8537 - value_loss: 0.0956 - value_mae: 0.2477\n",
            "\n",
            "--- Ã‰poque 790/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3592 - policy_categorical_accuracy: 0.5366 - policy_loss: 2.2046 - value_loss: 0.0977 - value_mae: 0.2509\n",
            "Epoch 1: val_loss did not improve from 2.21002\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.3579 - policy_categorical_accuracy: 0.5368 - policy_loss: 2.2034 - value_loss: 0.0976 - value_mae: 0.2508 - val_loss: 2.2340 - val_policy_categorical_accuracy: 0.5674 - val_policy_loss: 2.0777 - val_value_loss: 0.0958 - val_value_mae: 0.2490 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 791/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0527 - policy_categorical_accuracy: 0.3662 - policy_loss: 2.9005 - value_loss: 0.0951 - value_mae: 0.2461\n",
            "\n",
            "--- Ã‰poque 792/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0188 - policy_categorical_accuracy: 0.3738 - policy_loss: 2.8657 - value_loss: 0.0964 - value_mae: 0.2493\n",
            "\n",
            "--- Ã‰poque 793/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0725 - policy_categorical_accuracy: 0.3532 - policy_loss: 2.9165 - value_loss: 0.0992 - value_mae: 0.2530\n",
            "\n",
            "--- Ã‰poque 794/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0591 - policy_categorical_accuracy: 0.3605 - policy_loss: 2.9035 - value_loss: 0.0988 - value_mae: 0.2518\n",
            "\n",
            "--- Ã‰poque 795/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3480 - policy_categorical_accuracy: 0.5380 - policy_loss: 2.1961 - value_loss: 0.0951 - value_mae: 0.2484\n",
            "Epoch 1: val_loss improved from 2.21002 to 2.20567, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.3471 - policy_categorical_accuracy: 0.5381 - policy_loss: 2.1954 - value_loss: 0.0951 - value_mae: 0.2484 - val_loss: 2.2057 - val_policy_categorical_accuracy: 0.5817 - val_policy_loss: 2.0477 - val_value_loss: 0.0983 - val_value_mae: 0.2489 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 796/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.1044 - policy_categorical_accuracy: 0.3518 - policy_loss: 2.9486 - value_loss: 0.0990 - value_mae: 0.2522\n",
            "\n",
            "--- Ã‰poque 797/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0313 - policy_categorical_accuracy: 0.3749 - policy_loss: 2.8789 - value_loss: 0.0957 - value_mae: 0.2477\n",
            "\n",
            "--- Ã‰poque 798/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0141 - policy_categorical_accuracy: 0.3659 - policy_loss: 2.8600 - value_loss: 0.0976 - value_mae: 0.2499\n",
            "\n",
            "--- Ã‰poque 799/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0471 - policy_categorical_accuracy: 0.3595 - policy_loss: 2.8903 - value_loss: 0.0999 - value_mae: 0.2545\n",
            "\n",
            "--- Ã‰poque 800/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3838 - policy_categorical_accuracy: 0.5277 - policy_loss: 2.2286 - value_loss: 0.0985 - value_mae: 0.2534\n",
            "Epoch 1: val_loss improved from 2.20567 to 2.19438, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.3818 - policy_categorical_accuracy: 0.5281 - policy_loss: 2.2267 - value_loss: 0.0984 - value_mae: 0.2532 - val_loss: 2.1944 - val_policy_categorical_accuracy: 0.5790 - val_policy_loss: 2.0398 - val_value_loss: 0.0945 - val_value_mae: 0.2468 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 801/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0977 - policy_categorical_accuracy: 0.3511 - policy_loss: 2.9469 - value_loss: 0.0940 - value_mae: 0.2440\n",
            "\n",
            "--- Ã‰poque 802/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0407 - policy_categorical_accuracy: 0.3652 - policy_loss: 2.8906 - value_loss: 0.0933 - value_mae: 0.2430\n",
            "\n",
            "--- Ã‰poque 803/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0377 - policy_categorical_accuracy: 0.3648 - policy_loss: 2.8829 - value_loss: 0.0980 - value_mae: 0.2501\n",
            "\n",
            "--- Ã‰poque 804/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 3.0537 - policy_categorical_accuracy: 0.3648 - policy_loss: 2.9016 - value_loss: 0.0956 - value_mae: 0.2469\n",
            "\n",
            "--- Ã‰poque 805/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3379 - policy_categorical_accuracy: 0.5356 - policy_loss: 2.1846 - value_loss: 0.0966 - value_mae: 0.2485\n",
            "Epoch 1: val_loss improved from 2.19438 to 2.19367, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.3373 - policy_categorical_accuracy: 0.5357 - policy_loss: 2.1841 - value_loss: 0.0966 - value_mae: 0.2485 - val_loss: 2.1937 - val_policy_categorical_accuracy: 0.5823 - val_policy_loss: 2.0369 - val_value_loss: 0.0972 - val_value_mae: 0.2478 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 806/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0669 - policy_categorical_accuracy: 0.3657 - policy_loss: 2.9114 - value_loss: 0.0989 - value_mae: 0.2520\n",
            "\n",
            "--- Ã‰poque 807/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0173 - policy_categorical_accuracy: 0.3713 - policy_loss: 2.8649 - value_loss: 0.0957 - value_mae: 0.2467\n",
            "\n",
            "--- Ã‰poque 808/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0570 - policy_categorical_accuracy: 0.3609 - policy_loss: 2.9034 - value_loss: 0.0970 - value_mae: 0.2490\n",
            "\n",
            "--- Ã‰poque 809/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0387 - policy_categorical_accuracy: 0.3692 - policy_loss: 2.8832 - value_loss: 0.0991 - value_mae: 0.2527\n",
            "\n",
            "--- Ã‰poque 810/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3473 - policy_categorical_accuracy: 0.5376 - policy_loss: 2.1948 - value_loss: 0.0958 - value_mae: 0.2491\n",
            "Epoch 1: val_loss did not improve from 2.19367\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.3466 - policy_categorical_accuracy: 0.5378 - policy_loss: 2.1940 - value_loss: 0.0958 - value_mae: 0.2491 - val_loss: 2.2258 - val_policy_categorical_accuracy: 0.5730 - val_policy_loss: 2.0625 - val_value_loss: 0.1037 - val_value_mae: 0.2531 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 811/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0724 - policy_categorical_accuracy: 0.3614 - policy_loss: 2.9180 - value_loss: 0.0979 - value_mae: 0.2502\n",
            "\n",
            "--- Ã‰poque 812/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0730 - policy_categorical_accuracy: 0.3639 - policy_loss: 2.9161 - value_loss: 0.1002 - value_mae: 0.2546\n",
            "\n",
            "--- Ã‰poque 813/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0228 - policy_categorical_accuracy: 0.3708 - policy_loss: 2.8673 - value_loss: 0.0991 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 814/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 3.0070 - policy_categorical_accuracy: 0.3712 - policy_loss: 2.8546 - value_loss: 0.0959 - value_mae: 0.2483\n",
            "\n",
            "--- Ã‰poque 815/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3606 - policy_categorical_accuracy: 0.5267 - policy_loss: 2.2090 - value_loss: 0.0950 - value_mae: 0.2469\n",
            "Epoch 1: val_loss improved from 2.19367 to 2.19254, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.3589 - policy_categorical_accuracy: 0.5272 - policy_loss: 2.2073 - value_loss: 0.0950 - value_mae: 0.2469 - val_loss: 2.1925 - val_policy_categorical_accuracy: 0.5795 - val_policy_loss: 2.0382 - val_value_loss: 0.0953 - val_value_mae: 0.2476 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 816/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0903 - policy_categorical_accuracy: 0.3570 - policy_loss: 2.9352 - value_loss: 0.0986 - value_mae: 0.2505\n",
            "\n",
            "--- Ã‰poque 817/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0157 - policy_categorical_accuracy: 0.3743 - policy_loss: 2.8640 - value_loss: 0.0952 - value_mae: 0.2467\n",
            "\n",
            "--- Ã‰poque 818/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0047 - policy_categorical_accuracy: 0.3687 - policy_loss: 2.8494 - value_loss: 0.0987 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 819/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0197 - policy_categorical_accuracy: 0.3681 - policy_loss: 2.8670 - value_loss: 0.0962 - value_mae: 0.2489\n",
            "\n",
            "--- Ã‰poque 820/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.3625 - policy_categorical_accuracy: 0.5290 - policy_loss: 2.2089 - value_loss: 0.0970 - value_mae: 0.2502\n",
            "Epoch 1: val_loss improved from 2.19254 to 2.18822, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.3606 - policy_categorical_accuracy: 0.5295 - policy_loss: 2.2070 - value_loss: 0.0970 - value_mae: 0.2501 - val_loss: 2.1882 - val_policy_categorical_accuracy: 0.5848 - val_policy_loss: 2.0338 - val_value_loss: 0.0946 - val_value_mae: 0.2469 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 821/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0480 - policy_categorical_accuracy: 0.3713 - policy_loss: 2.8944 - value_loss: 0.0972 - value_mae: 0.2488\n",
            "\n",
            "--- Ã‰poque 822/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0721 - policy_categorical_accuracy: 0.3619 - policy_loss: 2.9155 - value_loss: 0.1000 - value_mae: 0.2529\n",
            "\n",
            "--- Ã‰poque 823/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0074 - policy_categorical_accuracy: 0.3701 - policy_loss: 2.8547 - value_loss: 0.0962 - value_mae: 0.2478\n",
            "\n",
            "--- Ã‰poque 824/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 2.9948 - policy_categorical_accuracy: 0.3764 - policy_loss: 2.8411 - value_loss: 0.0972 - value_mae: 0.2491\n",
            "\n",
            "--- Ã‰poque 825/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.3330 - policy_categorical_accuracy: 0.5431 - policy_loss: 2.1796 - value_loss: 0.0969 - value_mae: 0.2500\n",
            "Epoch 1: val_loss improved from 2.18822 to 2.18021, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.3321 - policy_categorical_accuracy: 0.5431 - policy_loss: 2.1787 - value_loss: 0.0968 - value_mae: 0.2499 - val_loss: 2.1802 - val_policy_categorical_accuracy: 0.5876 - val_policy_loss: 2.0261 - val_value_loss: 0.0952 - val_value_mae: 0.2466 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 826/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0283 - policy_categorical_accuracy: 0.3744 - policy_loss: 2.8734 - value_loss: 0.0984 - value_mae: 0.2491\n",
            "\n",
            "--- Ã‰poque 827/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0123 - policy_categorical_accuracy: 0.3697 - policy_loss: 2.8551 - value_loss: 0.1004 - value_mae: 0.2542\n",
            "\n",
            "--- Ã‰poque 828/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0449 - policy_categorical_accuracy: 0.3633 - policy_loss: 2.8902 - value_loss: 0.0982 - value_mae: 0.2515\n",
            "\n",
            "--- Ã‰poque 829/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0366 - policy_categorical_accuracy: 0.3640 - policy_loss: 2.8820 - value_loss: 0.0982 - value_mae: 0.2505\n",
            "\n",
            "--- Ã‰poque 830/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3430 - policy_categorical_accuracy: 0.5347 - policy_loss: 2.1922 - value_loss: 0.0943 - value_mae: 0.2474\n",
            "Epoch 1: val_loss did not improve from 2.18021\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.3416 - policy_categorical_accuracy: 0.5351 - policy_loss: 2.1909 - value_loss: 0.0944 - value_mae: 0.2474 - val_loss: 2.1905 - val_policy_categorical_accuracy: 0.5822 - val_policy_loss: 2.0369 - val_value_loss: 0.0944 - val_value_mae: 0.2472 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 831/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0464 - policy_categorical_accuracy: 0.3636 - policy_loss: 2.8924 - value_loss: 0.0976 - value_mae: 0.2501\n",
            "\n",
            "--- Ã‰poque 832/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0829 - policy_categorical_accuracy: 0.3581 - policy_loss: 2.9296 - value_loss: 0.0969 - value_mae: 0.2501\n",
            "\n",
            "--- Ã‰poque 833/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0015 - policy_categorical_accuracy: 0.3752 - policy_loss: 2.8482 - value_loss: 0.0969 - value_mae: 0.2485\n",
            "\n",
            "--- Ã‰poque 834/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0726 - policy_categorical_accuracy: 0.3660 - policy_loss: 2.9197 - value_loss: 0.0967 - value_mae: 0.2494\n",
            "\n",
            "--- Ã‰poque 835/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.3436 - policy_categorical_accuracy: 0.5344 - policy_loss: 2.1928 - value_loss: 0.0944 - value_mae: 0.2459\n",
            "Epoch 1: val_loss improved from 2.18021 to 2.17114, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.3421 - policy_categorical_accuracy: 0.5348 - policy_loss: 2.1911 - value_loss: 0.0945 - value_mae: 0.2460 - val_loss: 2.1711 - val_policy_categorical_accuracy: 0.5896 - val_policy_loss: 2.0157 - val_value_loss: 0.0964 - val_value_mae: 0.2489 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 836/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0055 - policy_categorical_accuracy: 0.3808 - policy_loss: 2.8509 - value_loss: 0.0981 - value_mae: 0.2503\n",
            "\n",
            "--- Ã‰poque 837/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0366 - policy_categorical_accuracy: 0.3668 - policy_loss: 2.8831 - value_loss: 0.0970 - value_mae: 0.2523\n",
            "\n",
            "--- Ã‰poque 838/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 2.9910 - policy_categorical_accuracy: 0.3768 - policy_loss: 2.8387 - value_loss: 0.0959 - value_mae: 0.2472\n",
            "\n",
            "--- Ã‰poque 839/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0436 - policy_categorical_accuracy: 0.3618 - policy_loss: 2.8896 - value_loss: 0.0975 - value_mae: 0.2489\n",
            "\n",
            "--- Ã‰poque 840/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3429 - policy_categorical_accuracy: 0.5359 - policy_loss: 2.1910 - value_loss: 0.0956 - value_mae: 0.2483\n",
            "Epoch 1: val_loss improved from 2.17114 to 2.16473, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.3419 - policy_categorical_accuracy: 0.5361 - policy_loss: 2.1900 - value_loss: 0.0956 - value_mae: 0.2482 - val_loss: 2.1647 - val_policy_categorical_accuracy: 0.5903 - val_policy_loss: 2.0089 - val_value_loss: 0.0969 - val_value_mae: 0.2473 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 841/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0601 - policy_categorical_accuracy: 0.3649 - policy_loss: 2.9065 - value_loss: 0.0972 - value_mae: 0.2498\n",
            "\n",
            "--- Ã‰poque 842/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0693 - policy_categorical_accuracy: 0.3586 - policy_loss: 2.9144 - value_loss: 0.0985 - value_mae: 0.2507\n",
            "\n",
            "--- Ã‰poque 843/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0412 - policy_categorical_accuracy: 0.3674 - policy_loss: 2.8905 - value_loss: 0.0946 - value_mae: 0.2449\n",
            "\n",
            "--- Ã‰poque 844/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 2.9912 - policy_categorical_accuracy: 0.3755 - policy_loss: 2.8381 - value_loss: 0.0967 - value_mae: 0.2496\n",
            "\n",
            "--- Ã‰poque 845/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3479 - policy_categorical_accuracy: 0.5302 - policy_loss: 2.1966 - value_loss: 0.0950 - value_mae: 0.2467\n",
            "Epoch 1: val_loss did not improve from 2.16473\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.3463 - policy_categorical_accuracy: 0.5306 - policy_loss: 2.1950 - value_loss: 0.0950 - value_mae: 0.2467 - val_loss: 2.1850 - val_policy_categorical_accuracy: 0.5827 - val_policy_loss: 2.0294 - val_value_loss: 0.0970 - val_value_mae: 0.2492 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 846/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0556 - policy_categorical_accuracy: 0.3592 - policy_loss: 2.9038 - value_loss: 0.0956 - value_mae: 0.2491\n",
            "\n",
            "--- Ã‰poque 847/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0251 - policy_categorical_accuracy: 0.3644 - policy_loss: 2.8729 - value_loss: 0.0960 - value_mae: 0.2472\n",
            "\n",
            "--- Ã‰poque 848/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 3.0668 - policy_categorical_accuracy: 0.3546 - policy_loss: 2.9126 - value_loss: 0.0978 - value_mae: 0.2498\n",
            "\n",
            "--- Ã‰poque 849/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 2.9984 - policy_categorical_accuracy: 0.3780 - policy_loss: 2.8461 - value_loss: 0.0962 - value_mae: 0.2496\n",
            "\n",
            "--- Ã‰poque 850/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3512 - policy_categorical_accuracy: 0.5353 - policy_loss: 2.1985 - value_loss: 0.0965 - value_mae: 0.2484\n",
            "Epoch 1: val_loss did not improve from 2.16473\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.3493 - policy_categorical_accuracy: 0.5357 - policy_loss: 2.1968 - value_loss: 0.0964 - value_mae: 0.2483 - val_loss: 2.1755 - val_policy_categorical_accuracy: 0.5902 - val_policy_loss: 2.0217 - val_value_loss: 0.0950 - val_value_mae: 0.2475 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 851/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0772 - policy_categorical_accuracy: 0.3676 - policy_loss: 2.9249 - value_loss: 0.0962 - value_mae: 0.2487\n",
            "\n",
            "--- Ã‰poque 852/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0455 - policy_categorical_accuracy: 0.3618 - policy_loss: 2.8916 - value_loss: 0.0977 - value_mae: 0.2504\n",
            "\n",
            "--- Ã‰poque 853/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0254 - policy_categorical_accuracy: 0.3714 - policy_loss: 2.8710 - value_loss: 0.0981 - value_mae: 0.2517\n",
            "\n",
            "--- Ã‰poque 854/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0233 - policy_categorical_accuracy: 0.3674 - policy_loss: 2.8710 - value_loss: 0.0961 - value_mae: 0.2477\n",
            "\n",
            "--- Ã‰poque 855/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3425 - policy_categorical_accuracy: 0.5382 - policy_loss: 2.1919 - value_loss: 0.0943 - value_mae: 0.2467\n",
            "Epoch 1: val_loss did not improve from 2.16473\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.3413 - policy_categorical_accuracy: 0.5385 - policy_loss: 2.1908 - value_loss: 0.0943 - value_mae: 0.2467 - val_loss: 2.1673 - val_policy_categorical_accuracy: 0.5908 - val_policy_loss: 2.0125 - val_value_loss: 0.0955 - val_value_mae: 0.2476 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 856/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0840 - policy_categorical_accuracy: 0.3545 - policy_loss: 2.9290 - value_loss: 0.0989 - value_mae: 0.2525\n",
            "\n",
            "--- Ã‰poque 857/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0076 - policy_categorical_accuracy: 0.3715 - policy_loss: 2.8552 - value_loss: 0.0961 - value_mae: 0.2476\n",
            "\n",
            "--- Ã‰poque 858/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0434 - policy_categorical_accuracy: 0.3609 - policy_loss: 2.8854 - value_loss: 0.1018 - value_mae: 0.2567\n",
            "\n",
            "--- Ã‰poque 859/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0318 - policy_categorical_accuracy: 0.3683 - policy_loss: 2.8777 - value_loss: 0.0978 - value_mae: 0.2521\n",
            "\n",
            "--- Ã‰poque 860/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3351 - policy_categorical_accuracy: 0.5377 - policy_loss: 2.1844 - value_loss: 0.0945 - value_mae: 0.2464\n",
            "Epoch 1: val_loss did not improve from 2.16473\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 2.3335 - policy_categorical_accuracy: 0.5379 - policy_loss: 2.1829 - value_loss: 0.0945 - value_mae: 0.2464 - val_loss: 2.1745 - val_policy_categorical_accuracy: 0.5855 - val_policy_loss: 2.0200 - val_value_loss: 0.0952 - val_value_mae: 0.2463 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 861/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0826 - policy_categorical_accuracy: 0.3568 - policy_loss: 2.9299 - value_loss: 0.0964 - value_mae: 0.2481\n",
            "\n",
            "--- Ã‰poque 862/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0357 - policy_categorical_accuracy: 0.3741 - policy_loss: 2.8792 - value_loss: 0.1003 - value_mae: 0.2536\n",
            "\n",
            "--- Ã‰poque 863/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0595 - policy_categorical_accuracy: 0.3645 - policy_loss: 2.9061 - value_loss: 0.0975 - value_mae: 0.2495\n",
            "\n",
            "--- Ã‰poque 864/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0075 - policy_categorical_accuracy: 0.3704 - policy_loss: 2.8558 - value_loss: 0.0954 - value_mae: 0.2476\n",
            "\n",
            "--- Ã‰poque 865/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3149 - policy_categorical_accuracy: 0.5471 - policy_loss: 2.1644 - value_loss: 0.0944 - value_mae: 0.2453\n",
            "Epoch 1: val_loss improved from 2.16473 to 2.16167, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.3144 - policy_categorical_accuracy: 0.5471 - policy_loss: 2.1640 - value_loss: 0.0944 - value_mae: 0.2454 - val_loss: 2.1617 - val_policy_categorical_accuracy: 0.5895 - val_policy_loss: 2.0087 - val_value_loss: 0.0945 - val_value_mae: 0.2467 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 866/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0939 - policy_categorical_accuracy: 0.3599 - policy_loss: 2.9394 - value_loss: 0.0985 - value_mae: 0.2509\n",
            "\n",
            "--- Ã‰poque 867/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0639 - policy_categorical_accuracy: 0.3712 - policy_loss: 2.9118 - value_loss: 0.0960 - value_mae: 0.2466\n",
            "\n",
            "--- Ã‰poque 868/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0331 - policy_categorical_accuracy: 0.3672 - policy_loss: 2.8812 - value_loss: 0.0958 - value_mae: 0.2478\n",
            "\n",
            "--- Ã‰poque 869/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 2.9940 - policy_categorical_accuracy: 0.3798 - policy_loss: 2.8413 - value_loss: 0.0966 - value_mae: 0.2489\n",
            "\n",
            "--- Ã‰poque 870/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.3360 - policy_categorical_accuracy: 0.5379 - policy_loss: 2.1859 - value_loss: 0.0940 - value_mae: 0.2459\n",
            "Epoch 1: val_loss did not improve from 2.16167\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.3348 - policy_categorical_accuracy: 0.5382 - policy_loss: 2.1846 - value_loss: 0.0941 - value_mae: 0.2459 - val_loss: 2.1731 - val_policy_categorical_accuracy: 0.5868 - val_policy_loss: 2.0190 - val_value_loss: 0.0952 - val_value_mae: 0.2475 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 871/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0477 - policy_categorical_accuracy: 0.3747 - policy_loss: 2.8947 - value_loss: 0.0971 - value_mae: 0.2485\n",
            "\n",
            "--- Ã‰poque 872/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0269 - policy_categorical_accuracy: 0.3682 - policy_loss: 2.8738 - value_loss: 0.0971 - value_mae: 0.2486\n",
            "\n",
            "--- Ã‰poque 873/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0430 - policy_categorical_accuracy: 0.3751 - policy_loss: 2.8921 - value_loss: 0.0949 - value_mae: 0.2455\n",
            "\n",
            "--- Ã‰poque 874/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 2.9870 - policy_categorical_accuracy: 0.3756 - policy_loss: 2.8335 - value_loss: 0.0975 - value_mae: 0.2509\n",
            "\n",
            "--- Ã‰poque 875/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.3384 - policy_categorical_accuracy: 0.5425 - policy_loss: 2.1871 - value_loss: 0.0954 - value_mae: 0.2476\n",
            "Epoch 1: val_loss improved from 2.16167 to 2.15352, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 2.3366 - policy_categorical_accuracy: 0.5428 - policy_loss: 2.1851 - value_loss: 0.0954 - value_mae: 0.2476 - val_loss: 2.1535 - val_policy_categorical_accuracy: 0.5930 - val_policy_loss: 1.9990 - val_value_loss: 0.0957 - val_value_mae: 0.2469 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 876/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0317 - policy_categorical_accuracy: 0.3715 - policy_loss: 2.8809 - value_loss: 0.0947 - value_mae: 0.2461\n",
            "\n",
            "--- Ã‰poque 877/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0497 - policy_categorical_accuracy: 0.3591 - policy_loss: 2.8946 - value_loss: 0.0990 - value_mae: 0.2517\n",
            "\n",
            "--- Ã‰poque 878/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0080 - policy_categorical_accuracy: 0.3652 - policy_loss: 2.8566 - value_loss: 0.0952 - value_mae: 0.2464\n",
            "\n",
            "--- Ã‰poque 879/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0202 - policy_categorical_accuracy: 0.3680 - policy_loss: 2.8655 - value_loss: 0.0988 - value_mae: 0.2535\n",
            "\n",
            "--- Ã‰poque 880/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3116 - policy_categorical_accuracy: 0.5440 - policy_loss: 2.1590 - value_loss: 0.0966 - value_mae: 0.2486\n",
            "Epoch 1: val_loss did not improve from 2.15352\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.3108 - policy_categorical_accuracy: 0.5443 - policy_loss: 2.1581 - value_loss: 0.0966 - value_mae: 0.2486 - val_loss: 2.1664 - val_policy_categorical_accuracy: 0.5881 - val_policy_loss: 2.0135 - val_value_loss: 0.0938 - val_value_mae: 0.2462 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 881/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0271 - policy_categorical_accuracy: 0.3878 - policy_loss: 2.8732 - value_loss: 0.0980 - value_mae: 0.2515\n",
            "\n",
            "--- Ã‰poque 882/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0421 - policy_categorical_accuracy: 0.3651 - policy_loss: 2.8902 - value_loss: 0.0959 - value_mae: 0.2467\n",
            "\n",
            "--- Ã‰poque 883/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0423 - policy_categorical_accuracy: 0.3576 - policy_loss: 2.8860 - value_loss: 0.1003 - value_mae: 0.2527\n",
            "\n",
            "--- Ã‰poque 884/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0432 - policy_categorical_accuracy: 0.3628 - policy_loss: 2.8905 - value_loss: 0.0967 - value_mae: 0.2484\n",
            "\n",
            "--- Ã‰poque 885/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.3017 - policy_categorical_accuracy: 0.5498 - policy_loss: 2.1491 - value_loss: 0.0966 - value_mae: 0.2483\n",
            "Epoch 1: val_loss did not improve from 2.15352\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.3006 - policy_categorical_accuracy: 0.5499 - policy_loss: 2.1481 - value_loss: 0.0966 - value_mae: 0.2482 - val_loss: 2.1551 - val_policy_categorical_accuracy: 0.5946 - val_policy_loss: 2.0000 - val_value_loss: 0.0960 - val_value_mae: 0.2469 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 886/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0569 - policy_categorical_accuracy: 0.3609 - policy_loss: 2.9042 - value_loss: 0.0965 - value_mae: 0.2491\n",
            "\n",
            "--- Ã‰poque 887/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0634 - policy_categorical_accuracy: 0.3652 - policy_loss: 2.9119 - value_loss: 0.0956 - value_mae: 0.2477\n",
            "\n",
            "--- Ã‰poque 888/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0152 - policy_categorical_accuracy: 0.3689 - policy_loss: 2.8647 - value_loss: 0.0945 - value_mae: 0.2462\n",
            "\n",
            "--- Ã‰poque 889/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0212 - policy_categorical_accuracy: 0.3753 - policy_loss: 2.8689 - value_loss: 0.0964 - value_mae: 0.2482\n",
            "\n",
            "--- Ã‰poque 890/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.3221 - policy_categorical_accuracy: 0.5465 - policy_loss: 2.1712 - value_loss: 0.0950 - value_mae: 0.2460\n",
            "Epoch 1: val_loss improved from 2.15352 to 2.13030, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.3204 - policy_categorical_accuracy: 0.5468 - policy_loss: 2.1695 - value_loss: 0.0950 - value_mae: 0.2459 - val_loss: 2.1303 - val_policy_categorical_accuracy: 0.6009 - val_policy_loss: 1.9780 - val_value_loss: 0.0938 - val_value_mae: 0.2446 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 891/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0055 - policy_categorical_accuracy: 0.3725 - policy_loss: 2.8518 - value_loss: 0.0979 - value_mae: 0.2499\n",
            "\n",
            "--- Ã‰poque 892/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0007 - policy_categorical_accuracy: 0.3803 - policy_loss: 2.8466 - value_loss: 0.0982 - value_mae: 0.2514\n",
            "\n",
            "--- Ã‰poque 893/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0060 - policy_categorical_accuracy: 0.3705 - policy_loss: 2.8496 - value_loss: 0.1004 - value_mae: 0.2527\n",
            "\n",
            "--- Ã‰poque 894/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 2.9957 - policy_categorical_accuracy: 0.3759 - policy_loss: 2.8434 - value_loss: 0.0965 - value_mae: 0.2479\n",
            "\n",
            "--- Ã‰poque 895/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.2801 - policy_categorical_accuracy: 0.5523 - policy_loss: 2.1278 - value_loss: 0.0965 - value_mae: 0.2501\n",
            "Epoch 1: val_loss did not improve from 2.13030\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.2795 - policy_categorical_accuracy: 0.5525 - policy_loss: 2.1271 - value_loss: 0.0964 - value_mae: 0.2500 - val_loss: 2.1409 - val_policy_categorical_accuracy: 0.5973 - val_policy_loss: 1.9850 - val_value_loss: 0.0969 - val_value_mae: 0.2468 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 896/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0421 - policy_categorical_accuracy: 0.3737 - policy_loss: 2.8905 - value_loss: 0.0957 - value_mae: 0.2462\n",
            "\n",
            "--- Ã‰poque 897/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 3.0351 - policy_categorical_accuracy: 0.3634 - policy_loss: 2.8825 - value_loss: 0.0967 - value_mae: 0.2484\n",
            "\n",
            "--- Ã‰poque 898/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0042 - policy_categorical_accuracy: 0.3703 - policy_loss: 2.8528 - value_loss: 0.0958 - value_mae: 0.2478\n",
            "\n",
            "--- Ã‰poque 899/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 2.9978 - policy_categorical_accuracy: 0.3756 - policy_loss: 2.8455 - value_loss: 0.0967 - value_mae: 0.2500\n",
            "\n",
            "--- Ã‰poque 900/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3079 - policy_categorical_accuracy: 0.5485 - policy_loss: 2.1568 - value_loss: 0.0953 - value_mae: 0.2472\n",
            "Epoch 1: val_loss did not improve from 2.13030\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.3063 - policy_categorical_accuracy: 0.5488 - policy_loss: 2.1551 - value_loss: 0.0953 - value_mae: 0.2471 - val_loss: 2.1510 - val_policy_categorical_accuracy: 0.5943 - val_policy_loss: 1.9982 - val_value_loss: 0.0938 - val_value_mae: 0.2461 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 901/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0562 - policy_categorical_accuracy: 0.3681 - policy_loss: 2.9072 - value_loss: 0.0931 - value_mae: 0.2435\n",
            "\n",
            "--- Ã‰poque 902/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0450 - policy_categorical_accuracy: 0.3629 - policy_loss: 2.8923 - value_loss: 0.0968 - value_mae: 0.2486\n",
            "\n",
            "--- Ã‰poque 903/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0757 - policy_categorical_accuracy: 0.3530 - policy_loss: 2.9225 - value_loss: 0.0973 - value_mae: 0.2508\n",
            "\n",
            "--- Ã‰poque 904/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0170 - policy_categorical_accuracy: 0.3624 - policy_loss: 2.8633 - value_loss: 0.0977 - value_mae: 0.2513\n",
            "\n",
            "--- Ã‰poque 905/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2864 - policy_categorical_accuracy: 0.5531 - policy_loss: 2.1364 - value_loss: 0.0943 - value_mae: 0.2463\n",
            "Epoch 1: val_loss improved from 2.13030 to 2.12626, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.2857 - policy_categorical_accuracy: 0.5533 - policy_loss: 2.1357 - value_loss: 0.0943 - value_mae: 0.2463 - val_loss: 2.1263 - val_policy_categorical_accuracy: 0.6030 - val_policy_loss: 1.9736 - val_value_loss: 0.0939 - val_value_mae: 0.2452 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 906/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0847 - policy_categorical_accuracy: 0.3617 - policy_loss: 2.9323 - value_loss: 0.0967 - value_mae: 0.2466\n",
            "\n",
            "--- Ã‰poque 907/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0210 - policy_categorical_accuracy: 0.3785 - policy_loss: 2.8697 - value_loss: 0.0955 - value_mae: 0.2471\n",
            "\n",
            "--- Ã‰poque 908/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0126 - policy_categorical_accuracy: 0.3757 - policy_loss: 2.8604 - value_loss: 0.0965 - value_mae: 0.2486\n",
            "\n",
            "--- Ã‰poque 909/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0418 - policy_categorical_accuracy: 0.3684 - policy_loss: 2.8902 - value_loss: 0.0958 - value_mae: 0.2484\n",
            "\n",
            "--- Ã‰poque 910/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.2774 - policy_categorical_accuracy: 0.5521 - policy_loss: 2.1256 - value_loss: 0.0961 - value_mae: 0.2481\n",
            "Epoch 1: val_loss improved from 2.12626 to 2.11304, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 2.2768 - policy_categorical_accuracy: 0.5522 - policy_loss: 2.1250 - value_loss: 0.0960 - value_mae: 0.2480 - val_loss: 2.1130 - val_policy_categorical_accuracy: 0.6089 - val_policy_loss: 1.9616 - val_value_loss: 0.0933 - val_value_mae: 0.2447 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 911/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0377 - policy_categorical_accuracy: 0.3710 - policy_loss: 2.8847 - value_loss: 0.0974 - value_mae: 0.2490\n",
            "\n",
            "--- Ã‰poque 912/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0074 - policy_categorical_accuracy: 0.3688 - policy_loss: 2.8545 - value_loss: 0.0971 - value_mae: 0.2488\n",
            "\n",
            "--- Ã‰poque 913/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0175 - policy_categorical_accuracy: 0.3736 - policy_loss: 2.8640 - value_loss: 0.0979 - value_mae: 0.2516\n",
            "\n",
            "--- Ã‰poque 914/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0261 - policy_categorical_accuracy: 0.3757 - policy_loss: 2.8759 - value_loss: 0.0946 - value_mae: 0.2447\n",
            "\n",
            "--- Ã‰poque 915/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.2969 - policy_categorical_accuracy: 0.5484 - policy_loss: 2.1490 - value_loss: 0.0922 - value_mae: 0.2421\n",
            "Epoch 1: val_loss did not improve from 2.11304\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 2.2952 - policy_categorical_accuracy: 0.5487 - policy_loss: 2.1472 - value_loss: 0.0923 - value_mae: 0.2423 - val_loss: 2.1280 - val_policy_categorical_accuracy: 0.6012 - val_policy_loss: 1.9735 - val_value_loss: 0.0971 - val_value_mae: 0.2463 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 916/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0491 - policy_categorical_accuracy: 0.3723 - policy_loss: 2.8980 - value_loss: 0.0957 - value_mae: 0.2472\n",
            "\n",
            "--- Ã‰poque 917/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0472 - policy_categorical_accuracy: 0.3586 - policy_loss: 2.8959 - value_loss: 0.0957 - value_mae: 0.2451\n",
            "\n",
            "--- Ã‰poque 918/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0124 - policy_categorical_accuracy: 0.3775 - policy_loss: 2.8586 - value_loss: 0.0982 - value_mae: 0.2512\n",
            "\n",
            "--- Ã‰poque 919/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0408 - policy_categorical_accuracy: 0.3672 - policy_loss: 2.8885 - value_loss: 0.0966 - value_mae: 0.2473\n",
            "\n",
            "--- Ã‰poque 920/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.2674 - policy_categorical_accuracy: 0.5578 - policy_loss: 2.1207 - value_loss: 0.0911 - value_mae: 0.2418\n",
            "Epoch 1: val_loss did not improve from 2.11304\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.2666 - policy_categorical_accuracy: 0.5578 - policy_loss: 2.1199 - value_loss: 0.0913 - value_mae: 0.2420 - val_loss: 2.1192 - val_policy_categorical_accuracy: 0.6049 - val_policy_loss: 1.9679 - val_value_loss: 0.0938 - val_value_mae: 0.2459 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 921/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0414 - policy_categorical_accuracy: 0.3786 - policy_loss: 2.8865 - value_loss: 0.0990 - value_mae: 0.2493\n",
            "\n",
            "--- Ã‰poque 922/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 2.9999 - policy_categorical_accuracy: 0.3771 - policy_loss: 2.8480 - value_loss: 0.0964 - value_mae: 0.2489\n",
            "\n",
            "--- Ã‰poque 923/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0158 - policy_categorical_accuracy: 0.3682 - policy_loss: 2.8635 - value_loss: 0.0966 - value_mae: 0.2482\n",
            "\n",
            "--- Ã‰poque 924/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 2.9971 - policy_categorical_accuracy: 0.3717 - policy_loss: 2.8436 - value_loss: 0.0980 - value_mae: 0.2489\n",
            "\n",
            "--- Ã‰poque 925/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.2691 - policy_categorical_accuracy: 0.5578 - policy_loss: 2.1180 - value_loss: 0.0955 - value_mae: 0.2485\n",
            "Epoch 1: val_loss did not improve from 2.11304\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.2687 - policy_categorical_accuracy: 0.5578 - policy_loss: 2.1177 - value_loss: 0.0955 - value_mae: 0.2485 - val_loss: 2.1193 - val_policy_categorical_accuracy: 0.6016 - val_policy_loss: 1.9662 - val_value_loss: 0.0956 - val_value_mae: 0.2462 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 926/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0351 - policy_categorical_accuracy: 0.3827 - policy_loss: 2.8827 - value_loss: 0.0968 - value_mae: 0.2474\n",
            "\n",
            "--- Ã‰poque 927/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0167 - policy_categorical_accuracy: 0.3766 - policy_loss: 2.8648 - value_loss: 0.0963 - value_mae: 0.2472\n",
            "\n",
            "--- Ã‰poque 928/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0348 - policy_categorical_accuracy: 0.3628 - policy_loss: 2.8847 - value_loss: 0.0946 - value_mae: 0.2465\n",
            "\n",
            "--- Ã‰poque 929/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0676 - policy_categorical_accuracy: 0.3632 - policy_loss: 2.9135 - value_loss: 0.0985 - value_mae: 0.2512\n",
            "\n",
            "--- Ã‰poque 930/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.2823 - policy_categorical_accuracy: 0.5533 - policy_loss: 2.1325 - value_loss: 0.0942 - value_mae: 0.2454\n",
            "Epoch 1: val_loss did not improve from 2.11304\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.2815 - policy_categorical_accuracy: 0.5535 - policy_loss: 2.1317 - value_loss: 0.0943 - value_mae: 0.2455 - val_loss: 2.1307 - val_policy_categorical_accuracy: 0.6028 - val_policy_loss: 1.9786 - val_value_loss: 0.0939 - val_value_mae: 0.2463 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 931/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0392 - policy_categorical_accuracy: 0.3713 - policy_loss: 2.8869 - value_loss: 0.0968 - value_mae: 0.2488\n",
            "\n",
            "--- Ã‰poque 932/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0360 - policy_categorical_accuracy: 0.3687 - policy_loss: 2.8837 - value_loss: 0.0969 - value_mae: 0.2477\n",
            "\n",
            "--- Ã‰poque 933/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 2.9757 - policy_categorical_accuracy: 0.3835 - policy_loss: 2.8231 - value_loss: 0.0969 - value_mae: 0.2486\n",
            "\n",
            "--- Ã‰poque 934/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 2.9616 - policy_categorical_accuracy: 0.3797 - policy_loss: 2.8099 - value_loss: 0.0961 - value_mae: 0.2478\n",
            "\n",
            "--- Ã‰poque 935/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2878 - policy_categorical_accuracy: 0.5554 - policy_loss: 2.1393 - value_loss: 0.0930 - value_mae: 0.2438\n",
            "Epoch 1: val_loss improved from 2.11304 to 2.11049, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.2861 - policy_categorical_accuracy: 0.5556 - policy_loss: 2.1376 - value_loss: 0.0931 - value_mae: 0.2439 - val_loss: 2.1105 - val_policy_categorical_accuracy: 0.6053 - val_policy_loss: 1.9587 - val_value_loss: 0.0936 - val_value_mae: 0.2450 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 936/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.1009 - policy_categorical_accuracy: 0.3530 - policy_loss: 2.9484 - value_loss: 0.0969 - value_mae: 0.2506\n",
            "\n",
            "--- Ã‰poque 937/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0232 - policy_categorical_accuracy: 0.3651 - policy_loss: 2.8717 - value_loss: 0.0960 - value_mae: 0.2484\n",
            "\n",
            "--- Ã‰poque 938/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0139 - policy_categorical_accuracy: 0.3783 - policy_loss: 2.8614 - value_loss: 0.0971 - value_mae: 0.2499\n",
            "\n",
            "--- Ã‰poque 939/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 2.9884 - policy_categorical_accuracy: 0.3798 - policy_loss: 2.8349 - value_loss: 0.0980 - value_mae: 0.2499\n",
            "\n",
            "--- Ã‰poque 940/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.2570 - policy_categorical_accuracy: 0.5581 - policy_loss: 2.1059 - value_loss: 0.0956 - value_mae: 0.2484\n",
            "Epoch 1: val_loss did not improve from 2.11049\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.2563 - policy_categorical_accuracy: 0.5583 - policy_loss: 2.1054 - value_loss: 0.0956 - value_mae: 0.2483 - val_loss: 2.1206 - val_policy_categorical_accuracy: 0.6073 - val_policy_loss: 1.9657 - val_value_loss: 0.0971 - val_value_mae: 0.2477 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 941/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0548 - policy_categorical_accuracy: 0.3711 - policy_loss: 2.9052 - value_loss: 0.0943 - value_mae: 0.2453\n",
            "\n",
            "--- Ã‰poque 942/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0076 - policy_categorical_accuracy: 0.3692 - policy_loss: 2.8540 - value_loss: 0.0981 - value_mae: 0.2495\n",
            "\n",
            "--- Ã‰poque 943/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0167 - policy_categorical_accuracy: 0.3680 - policy_loss: 2.8631 - value_loss: 0.0982 - value_mae: 0.2507\n",
            "\n",
            "--- Ã‰poque 944/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 2.9895 - policy_categorical_accuracy: 0.3782 - policy_loss: 2.8393 - value_loss: 0.0950 - value_mae: 0.2460\n",
            "\n",
            "--- Ã‰poque 945/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2843 - policy_categorical_accuracy: 0.5554 - policy_loss: 2.1345 - value_loss: 0.0944 - value_mae: 0.2449\n",
            "Epoch 1: val_loss did not improve from 2.11049\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.2825 - policy_categorical_accuracy: 0.5558 - policy_loss: 2.1327 - value_loss: 0.0944 - value_mae: 0.2450 - val_loss: 2.1143 - val_policy_categorical_accuracy: 0.6053 - val_policy_loss: 1.9616 - val_value_loss: 0.0947 - val_value_mae: 0.2452 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 946/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0657 - policy_categorical_accuracy: 0.3714 - policy_loss: 2.9123 - value_loss: 0.0979 - value_mae: 0.2490\n",
            "\n",
            "--- Ã‰poque 947/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 2.9907 - policy_categorical_accuracy: 0.3675 - policy_loss: 2.8383 - value_loss: 0.0971 - value_mae: 0.2490\n",
            "\n",
            "--- Ã‰poque 948/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 2.9943 - policy_categorical_accuracy: 0.3688 - policy_loss: 2.8440 - value_loss: 0.0949 - value_mae: 0.2456\n",
            "\n",
            "--- Ã‰poque 949/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0299 - policy_categorical_accuracy: 0.3703 - policy_loss: 2.8752 - value_loss: 0.0994 - value_mae: 0.2538\n",
            "\n",
            "--- Ã‰poque 950/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2691 - policy_categorical_accuracy: 0.5583 - policy_loss: 2.1195 - value_loss: 0.0943 - value_mae: 0.2468\n",
            "Epoch 1: val_loss improved from 2.11049 to 2.10265, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.2678 - policy_categorical_accuracy: 0.5586 - policy_loss: 2.1181 - value_loss: 0.0943 - value_mae: 0.2468 - val_loss: 2.1026 - val_policy_categorical_accuracy: 0.6085 - val_policy_loss: 1.9514 - val_value_loss: 0.0934 - val_value_mae: 0.2444 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 951/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0637 - policy_categorical_accuracy: 0.3586 - policy_loss: 2.9106 - value_loss: 0.0978 - value_mae: 0.2504\n",
            "\n",
            "--- Ã‰poque 952/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0627 - policy_categorical_accuracy: 0.3553 - policy_loss: 2.9096 - value_loss: 0.0980 - value_mae: 0.2513\n",
            "\n",
            "--- Ã‰poque 953/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0255 - policy_categorical_accuracy: 0.3548 - policy_loss: 2.8766 - value_loss: 0.0936 - value_mae: 0.2448\n",
            "\n",
            "--- Ã‰poque 954/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0240 - policy_categorical_accuracy: 0.3593 - policy_loss: 2.8730 - value_loss: 0.0957 - value_mae: 0.2468\n",
            "\n",
            "--- Ã‰poque 955/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.2479 - policy_categorical_accuracy: 0.5605 - policy_loss: 2.0976 - value_loss: 0.0950 - value_mae: 0.2470\n",
            "Epoch 1: val_loss improved from 2.10265 to 2.09539, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 2.2472 - policy_categorical_accuracy: 0.5606 - policy_loss: 2.0970 - value_loss: 0.0950 - value_mae: 0.2470 - val_loss: 2.0954 - val_policy_categorical_accuracy: 0.6102 - val_policy_loss: 1.9451 - val_value_loss: 0.0929 - val_value_mae: 0.2438 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 956/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0147 - policy_categorical_accuracy: 0.3762 - policy_loss: 2.8625 - value_loss: 0.0969 - value_mae: 0.2485\n",
            "\n",
            "--- Ã‰poque 957/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 2.9917 - policy_categorical_accuracy: 0.3746 - policy_loss: 2.8417 - value_loss: 0.0946 - value_mae: 0.2444\n",
            "\n",
            "--- Ã‰poque 958/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0173 - policy_categorical_accuracy: 0.3730 - policy_loss: 2.8646 - value_loss: 0.0973 - value_mae: 0.2479\n",
            "\n",
            "--- Ã‰poque 959/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0414 - policy_categorical_accuracy: 0.3632 - policy_loss: 2.8857 - value_loss: 0.1002 - value_mae: 0.2511\n",
            "\n",
            "--- Ã‰poque 960/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.2599 - policy_categorical_accuracy: 0.5586 - policy_loss: 2.1100 - value_loss: 0.0946 - value_mae: 0.2467\n",
            "Epoch 1: val_loss improved from 2.09539 to 2.09127, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 2.2586 - policy_categorical_accuracy: 0.5588 - policy_loss: 2.1087 - value_loss: 0.0946 - value_mae: 0.2467 - val_loss: 2.0913 - val_policy_categorical_accuracy: 0.6140 - val_policy_loss: 1.9394 - val_value_loss: 0.0952 - val_value_mae: 0.2450 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 961/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0274 - policy_categorical_accuracy: 0.3712 - policy_loss: 2.8746 - value_loss: 0.0976 - value_mae: 0.2490\n",
            "\n",
            "--- Ã‰poque 962/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0379 - policy_categorical_accuracy: 0.3628 - policy_loss: 2.8846 - value_loss: 0.0983 - value_mae: 0.2516\n",
            "\n",
            "--- Ã‰poque 963/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 2.9925 - policy_categorical_accuracy: 0.3626 - policy_loss: 2.8417 - value_loss: 0.0956 - value_mae: 0.2470\n",
            "\n",
            "--- Ã‰poque 964/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0014 - policy_categorical_accuracy: 0.3731 - policy_loss: 2.8511 - value_loss: 0.0951 - value_mae: 0.2461\n",
            "\n",
            "--- Ã‰poque 965/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2679 - policy_categorical_accuracy: 0.5583 - policy_loss: 2.1184 - value_loss: 0.0943 - value_mae: 0.2457\n",
            "Epoch 1: val_loss did not improve from 2.09127\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.2662 - policy_categorical_accuracy: 0.5586 - policy_loss: 2.1167 - value_loss: 0.0943 - value_mae: 0.2457 - val_loss: 2.0969 - val_policy_categorical_accuracy: 0.6133 - val_policy_loss: 1.9452 - val_value_loss: 0.0949 - val_value_mae: 0.2459 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 966/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0688 - policy_categorical_accuracy: 0.3557 - policy_loss: 2.9178 - value_loss: 0.0956 - value_mae: 0.2471\n",
            "\n",
            "--- Ã‰poque 967/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 3.0371 - policy_categorical_accuracy: 0.3687 - policy_loss: 2.8851 - value_loss: 0.0966 - value_mae: 0.2466\n",
            "\n",
            "--- Ã‰poque 968/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 2.9745 - policy_categorical_accuracy: 0.3793 - policy_loss: 2.8238 - value_loss: 0.0958 - value_mae: 0.2473\n",
            "\n",
            "--- Ã‰poque 969/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0160 - policy_categorical_accuracy: 0.3636 - policy_loss: 2.8614 - value_loss: 0.0991 - value_mae: 0.2520\n",
            "\n",
            "--- Ã‰poque 970/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2397 - policy_categorical_accuracy: 0.5613 - policy_loss: 2.0924 - value_loss: 0.0921 - value_mae: 0.2423\n",
            "Epoch 1: val_loss improved from 2.09127 to 2.08703, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.2389 - policy_categorical_accuracy: 0.5616 - policy_loss: 2.0915 - value_loss: 0.0922 - value_mae: 0.2424 - val_loss: 2.0870 - val_policy_categorical_accuracy: 0.6147 - val_policy_loss: 1.9367 - val_value_loss: 0.0935 - val_value_mae: 0.2455 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 971/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0966 - policy_categorical_accuracy: 0.3603 - policy_loss: 2.9453 - value_loss: 0.0959 - value_mae: 0.2480\n",
            "\n",
            "--- Ã‰poque 972/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0427 - policy_categorical_accuracy: 0.3692 - policy_loss: 2.8905 - value_loss: 0.0969 - value_mae: 0.2480\n",
            "\n",
            "--- Ã‰poque 973/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 2.9972 - policy_categorical_accuracy: 0.3723 - policy_loss: 2.8437 - value_loss: 0.0983 - value_mae: 0.2520\n",
            "\n",
            "--- Ã‰poque 974/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0393 - policy_categorical_accuracy: 0.3640 - policy_loss: 2.8851 - value_loss: 0.0990 - value_mae: 0.2509\n",
            "\n",
            "--- Ã‰poque 975/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2771 - policy_categorical_accuracy: 0.5544 - policy_loss: 2.1275 - value_loss: 0.0944 - value_mae: 0.2472\n",
            "Epoch 1: val_loss improved from 2.08703 to 2.08582, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.2749 - policy_categorical_accuracy: 0.5548 - policy_loss: 2.1251 - value_loss: 0.0944 - value_mae: 0.2471 - val_loss: 2.0858 - val_policy_categorical_accuracy: 0.6097 - val_policy_loss: 1.9340 - val_value_loss: 0.0945 - val_value_mae: 0.2452 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 976/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0391 - policy_categorical_accuracy: 0.3772 - policy_loss: 2.8890 - value_loss: 0.0950 - value_mae: 0.2468\n",
            "\n",
            "--- Ã‰poque 977/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 3.0070 - policy_categorical_accuracy: 0.3722 - policy_loss: 2.8539 - value_loss: 0.0980 - value_mae: 0.2494\n",
            "\n",
            "--- Ã‰poque 978/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0287 - policy_categorical_accuracy: 0.3655 - policy_loss: 2.8752 - value_loss: 0.0983 - value_mae: 0.2521\n",
            "\n",
            "--- Ã‰poque 979/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 2.9776 - policy_categorical_accuracy: 0.3795 - policy_loss: 2.8245 - value_loss: 0.0978 - value_mae: 0.2501\n",
            "\n",
            "--- Ã‰poque 980/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2644 - policy_categorical_accuracy: 0.5607 - policy_loss: 2.1158 - value_loss: 0.0935 - value_mae: 0.2451\n",
            "Epoch 1: val_loss improved from 2.08582 to 2.07720, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.2628 - policy_categorical_accuracy: 0.5611 - policy_loss: 2.1142 - value_loss: 0.0935 - value_mae: 0.2451 - val_loss: 2.0772 - val_policy_categorical_accuracy: 0.6217 - val_policy_loss: 1.9265 - val_value_loss: 0.0935 - val_value_mae: 0.2471 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 981/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0248 - policy_categorical_accuracy: 0.3788 - policy_loss: 2.8743 - value_loss: 0.0953 - value_mae: 0.2469\n",
            "\n",
            "--- Ã‰poque 982/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.0309 - policy_categorical_accuracy: 0.3665 - policy_loss: 2.8816 - value_loss: 0.0941 - value_mae: 0.2436\n",
            "\n",
            "--- Ã‰poque 983/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0092 - policy_categorical_accuracy: 0.3736 - policy_loss: 2.8558 - value_loss: 0.0981 - value_mae: 0.2493\n",
            "\n",
            "--- Ã‰poque 984/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 2.9978 - policy_categorical_accuracy: 0.3654 - policy_loss: 2.8472 - value_loss: 0.0959 - value_mae: 0.2482\n",
            "\n",
            "--- Ã‰poque 985/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2507 - policy_categorical_accuracy: 0.5569 - policy_loss: 2.1014 - value_loss: 0.0943 - value_mae: 0.2461\n",
            "Epoch 1: val_loss did not improve from 2.07720\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 2.2493 - policy_categorical_accuracy: 0.5574 - policy_loss: 2.0999 - value_loss: 0.0943 - value_mae: 0.2461 - val_loss: 2.0831 - val_policy_categorical_accuracy: 0.6197 - val_policy_loss: 1.9324 - val_value_loss: 0.0935 - val_value_mae: 0.2459 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 986/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0737 - policy_categorical_accuracy: 0.3629 - policy_loss: 2.9199 - value_loss: 0.0988 - value_mae: 0.2499\n",
            "\n",
            "--- Ã‰poque 987/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0520 - policy_categorical_accuracy: 0.3572 - policy_loss: 2.9019 - value_loss: 0.0948 - value_mae: 0.2462\n",
            "\n",
            "--- Ã‰poque 988/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0122 - policy_categorical_accuracy: 0.3680 - policy_loss: 2.8607 - value_loss: 0.0965 - value_mae: 0.2480\n",
            "\n",
            "--- Ã‰poque 989/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 2.9875 - policy_categorical_accuracy: 0.3737 - policy_loss: 2.8328 - value_loss: 0.0998 - value_mae: 0.2540\n",
            "\n",
            "--- Ã‰poque 990/1000 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.2632 - policy_categorical_accuracy: 0.5562 - policy_loss: 2.1149 - value_loss: 0.0933 - value_mae: 0.2454\n",
            "Epoch 1: val_loss improved from 2.07720 to 2.07550, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 2.2620 - policy_categorical_accuracy: 0.5565 - policy_loss: 2.1137 - value_loss: 0.0933 - value_mae: 0.2454 - val_loss: 2.0755 - val_policy_categorical_accuracy: 0.6207 - val_policy_loss: 1.9209 - val_value_loss: 0.0977 - val_value_mae: 0.2471 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 991/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0256 - policy_categorical_accuracy: 0.3839 - policy_loss: 2.8750 - value_loss: 0.0954 - value_mae: 0.2468\n",
            "\n",
            "--- Ã‰poque 992/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.0265 - policy_categorical_accuracy: 0.3780 - policy_loss: 2.8739 - value_loss: 0.0978 - value_mae: 0.2500\n",
            "\n",
            "--- Ã‰poque 993/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 2.9874 - policy_categorical_accuracy: 0.3768 - policy_loss: 2.8374 - value_loss: 0.0952 - value_mae: 0.2457\n",
            "\n",
            "--- Ã‰poque 994/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 2.9880 - policy_categorical_accuracy: 0.3677 - policy_loss: 2.8369 - value_loss: 0.0962 - value_mae: 0.2456\n",
            "\n",
            "--- Ã‰poque 995/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2565 - policy_categorical_accuracy: 0.5556 - policy_loss: 2.1076 - value_loss: 0.0939 - value_mae: 0.2448\n",
            "Epoch 1: val_loss did not improve from 2.07550\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 2.2547 - policy_categorical_accuracy: 0.5560 - policy_loss: 2.1059 - value_loss: 0.0939 - value_mae: 0.2448 - val_loss: 2.0856 - val_policy_categorical_accuracy: 0.6150 - val_policy_loss: 1.9335 - val_value_loss: 0.0947 - val_value_mae: 0.2467 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "--- Ã‰poque 996/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 3.0299 - policy_categorical_accuracy: 0.3745 - policy_loss: 2.8768 - value_loss: 0.0981 - value_mae: 0.2495\n",
            "\n",
            "--- Ã‰poque 997/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.0198 - policy_categorical_accuracy: 0.3638 - policy_loss: 2.8672 - value_loss: 0.0976 - value_mae: 0.2504\n",
            "\n",
            "--- Ã‰poque 998/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 2.9903 - policy_categorical_accuracy: 0.3776 - policy_loss: 2.8381 - value_loss: 0.0972 - value_mae: 0.2504\n",
            "\n",
            "--- Ã‰poque 999/1000 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.0369 - policy_categorical_accuracy: 0.3577 - policy_loss: 2.8861 - value_loss: 0.0961 - value_mae: 0.2488\n",
            "\n",
            "--- Ã‰poque 1000/1000 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2488 - policy_categorical_accuracy: 0.5646 - policy_loss: 2.0995 - value_loss: 0.0944 - value_mae: 0.2457\n",
            "Epoch 1: val_loss improved from 2.07550 to 2.07027, saving model to output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 2.2473 - policy_categorical_accuracy: 0.5649 - policy_loss: 2.0981 - value_loss: 0.0943 - value_mae: 0.2457 - val_loss: 2.0703 - val_policy_categorical_accuracy: 0.6192 - val_policy_loss: 1.9203 - val_value_loss: 0.0931 - val_value_mae: 0.2440 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "ğŸ§¹ GC.\n",
            "\n",
            "ğŸ’¾ Sauvegardes :\n",
            " - Best: output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_best.keras\n",
            " - Final: output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001_final.keras\n",
            "âœ… EntraÃ®nement terminÃ©.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3hvbz6raPeg"
      },
      "source": [
        "# Sauvegarde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UVmBNNsraPeg",
        "outputId": "4a66267d-9772-46dc-abf6-a2f085465cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ModÃ¨les sauvegardÃ©s :\n",
            " - output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001.h5\n",
            " - output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001.keras\n",
            "ğŸ“˜ Historique sauvegardÃ© : output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001/history.json\n",
            "\n",
            "âœ… Fichiers et graphiques enregistrÃ©s dans : output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001\n",
            "ğŸ“¦ Dossier compressÃ© : output/20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aecf0e9c-8954-463b-a1cf-2745534883df\", \"20251122_AdamH_Model4B_AttentionHybrid_ep1000_bs128_lr0.0001_l20.0001.zip\", 5354938)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ TÃ©lÃ©chargement du dossier complet lancÃ© avec succÃ¨s âœ…\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# ğŸ’¾ SAUVEGARDE + ğŸ“Š VISUALISATION + ğŸ“ˆ LISSAGE + ğŸ“¦ ZIP DOWNLOAD\n",
        "# ================================================================\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# ğŸ”¹ CrÃ©ation du dossier (si manquant)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ğŸ”¹ Sauvegarde du modÃ¨le (.h5 & .keras)\n",
        "h5_path = os.path.join(output_dir, f\"{model_name}.h5\")\n",
        "keras_path = os.path.join(output_dir, f\"{model_name}.keras\")\n",
        "hist_json = os.path.join(output_dir, \"history.json\")\n",
        "\n",
        "model.save(h5_path)\n",
        "model.save(keras_path)\n",
        "print(f\"âœ… ModÃ¨les sauvegardÃ©s :\\n - {h5_path}\\n - {keras_path}\")\n",
        "\n",
        "# ğŸ”¹ Sauvegarde de lâ€™historique complet\n",
        "with open(hist_json, \"w\") as f:\n",
        "    json.dump(history_all, f)\n",
        "print(f\"ğŸ“˜ Historique sauvegardÃ© : {hist_json}\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ“Š VISUALISATION DES COURBES\n",
        "# ================================================================\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "\n",
        "def save_plot(fig, name):\n",
        "    fig.savefig(os.path.join(output_dir, name), dpi=300, bbox_inches='tight')\n",
        "\n",
        "epochs_range = range(1, len(history_all.get(\"loss\", [])) + 1)\n",
        "\n",
        "# --- 1ï¸âƒ£ Courbe de perte (Loss)\n",
        "if history_all.get(\"loss\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"loss\"], label='Training Loss', linewidth=2)\n",
        "    if history_all.get(\"val_loss\"):\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_loss\"], label='Validation Loss', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Loss\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Loss\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"loss_curve.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 2ï¸âƒ£ Policy Accuracy\n",
        "if history_all.get(\"policy_categorical_accuracy\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"policy_categorical_accuracy\"], label='Policy Accuracy', linewidth=2)\n",
        "    if history_all.get(\"val_policy_categorical_accuracy\"):\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_policy_categorical_accuracy\"], '--', label='Val Policy Acc', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Policy Accuracy\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"policy_accuracy.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 3ï¸âƒ£ Top-5 Accuracy\n",
        "if history_all.get(\"policy_top5\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"policy_top5\"], label='Top-5 Accuracy', linewidth=2)\n",
        "    if history_all.get(\"val_policy_top5\"):  # âœ… clÃ© optionnelle\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_policy_top5\"], '--', label='Val Top-5', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Top-5 Accuracy\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"top5_accuracy.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 4ï¸âƒ£ Value MAE\n",
        "if history_all.get(\"value_mae\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"value_mae\"], label='Value MAE', linewidth=2)\n",
        "    if history_all.get(\"val_value_mae\"):\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_value_mae\"], '--', label='Val Value MAE', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Value MAE\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"MAE\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"value_mae.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ“ˆ LISSAGE (Policy Accuracy)\n",
        "# ================================================================\n",
        "def moving_average(data, window=5):\n",
        "    data = np.array(data)\n",
        "    if len(data) < window:\n",
        "        return data\n",
        "    return np.convolve(data, np.ones(window)/window, mode='valid')\n",
        "\n",
        "if history_all.get(\"policy_categorical_accuracy\"):\n",
        "    smooth_acc = moving_average(history_all[\"policy_categorical_accuracy\"], 5)\n",
        "    epochs_smooth = np.arange(5, len(history_all[\"policy_categorical_accuracy\"]) + 1)\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(range(1, len(history_all[\"policy_categorical_accuracy\"]) + 1),\n",
        "            history_all[\"policy_categorical_accuracy\"], alpha=0.4, label='Brut', linewidth=1.5)\n",
        "    ax.plot(epochs_smooth, smooth_acc, color='red', linewidth=2.5,\n",
        "            label='Moyenne glissante (5)')\n",
        "    ax.set_title(f\"{model_name} - Policy Accuracy (LissÃ©e)\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.8)\n",
        "    save_plot(fig, \"policy_acc_smooth.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ§¾ EXPORT DU RÃ‰SUMÃ‰ DES MÃ‰TRIQUES\n",
        "# ================================================================\n",
        "summary_path = os.path.join(output_dir, \"metrics_summary.txt\")\n",
        "with open(summary_path, \"w\") as f:\n",
        "    f.write(f\"Model: {model_name}\\n\")\n",
        "    f.write(f\"Epochs: {len(history_all.get('loss', []))}\\n\\n\")\n",
        "    if history_all.get(\"loss\"):\n",
        "        f.write(f\"Final Training Loss: {history_all['loss'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"val_loss\"):\n",
        "        f.write(f\"Final Validation Loss: {history_all['val_loss'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"policy_categorical_accuracy\"):\n",
        "        f.write(f\"Final Policy Accuracy: {history_all['policy_categorical_accuracy'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"val_policy_categorical_accuracy\"):\n",
        "        f.write(f\"Final Val Policy Accuracy: {history_all['val_policy_categorical_accuracy'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"value_mae\"):\n",
        "        f.write(f\"Final Value MAE: {history_all['value_mae'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"val_value_mae\"):\n",
        "        f.write(f\"Final Val Value MAE: {history_all['val_value_mae'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"policy_top5\"):\n",
        "        f.write(f\"Final Policy Top-5: {history_all['policy_top5'][-1]:.4f}\\n\")\n",
        "\n",
        "print(f\"\\nâœ… Fichiers et graphiques enregistrÃ©s dans : {output_dir}\")\n",
        "\n",
        "# ================================================================\n",
        "# ğŸ“¦ ZIP + TÃ‰LÃ‰CHARGEMENT AUTOMATIQUE\n",
        "# ================================================================\n",
        "zip_path = f\"{output_dir}.zip\"\n",
        "shutil.make_archive(output_dir, 'zip', output_dir)\n",
        "print(f\"ğŸ“¦ Dossier compressÃ© : {zip_path}\")\n",
        "\n",
        "try:\n",
        "    files.download(zip_path)\n",
        "    print(f\"ğŸ“¥ TÃ©lÃ©chargement du dossier complet lancÃ© avec succÃ¨s âœ…\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ TÃ©lÃ©chargement automatique ignorÃ© ({e})\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}