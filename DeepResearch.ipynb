{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVUS8P7qaPed",
        "outputId": "33df63b4-09f9-4ff3-f784-9584283c2988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-11 08:48:42--  https://www.lamsade.dauphine.fr/~cazenave/project2026.zip\n",
            "Resolving www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)... 193.48.71.250\n",
            "Connecting to www.lamsade.dauphine.fr (www.lamsade.dauphine.fr)|193.48.71.250|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138578548 (132M) [application/zip]\n",
            "Saving to: ‚Äòproject2026.zip‚Äô\n",
            "\n",
            "project2026.zip     100%[===================>] 132.16M  22.5MB/s    in 6.8s    \n",
            "\n",
            "2025-11-11 08:48:49 (19.5 MB/s) - ‚Äòproject2026.zip‚Äô saved [138578548/138578548]\n",
            "\n",
            "Archive:  project2026.zip\n",
            "  inflating: games.data              \n",
            "  inflating: golois.cpython-312-x86_64-linux-gnu.so  \n",
            "total 665408\n",
            "-rw-r--r-- 1 root root 542497580 Oct  7  2022 games.data\n",
            "-rwxr-xr-x 1 root root    284672 Oct  1 15:09 golois.cpython-312-x86_64-linux-gnu.so\n",
            "-rw-r--r-- 1 root root 138578548 Oct  1 20:02 project2026.zip\n",
            "drwxr-xr-x 1 root root      4096 Nov  7 14:30 sample_data\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.lamsade.dauphine.fr/~cazenave/project2026.zip\n",
        "!unzip project2026.zip\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCBpX74JaPee"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fDLUTeCDaPee"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# üì¶ IMPORTS G√âN√âRAUX\n",
        "# ================================================================\n",
        "import os, gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from google.colab import files  # pour le t√©l√©chargement auto\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import golois  # Librairie C++ fournie (jeu de donn√©es Go)\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow import keras\n",
        "import gc\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "# Utilitaires internes (si tu veux factoriser ton code)\n",
        "# from utils.model_blocks import dw_conv_block, se_block, attention_residual_block\n",
        "# from utils.training_utils import moving_average, save_plots\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ‚úÖ GO-ALPHA HYBRID ~99k PARAMS ‚Äî Cosine LR ‚Äî Sym Aug ‚Äî GOLOIS\n",
        "# ‚úÖ Version enrichie avec astuces AlphaZero / KataGo / Gumbel-AlphaZero\n",
        "# ================================================================\n",
        "import os, gc, shutil, numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from datetime import datetime\n",
        "import golois\n",
        "\n",
        "# -----------------------------\n",
        "# Runtime / GPU safety (Colab)\n",
        "# -----------------------------\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        print(\"‚úÖ GPU activ√© (memory growth).\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è GPU memory growth non appliqu√©:\", e)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Aucun GPU d√©tect√© ‚Äî CPU utilis√©.\")\n",
        "\n",
        "# ================================================================\n",
        "# üîß PARAMS (affin√©s via AlphaZero/KataGo)\n",
        "# ================================================================\n",
        "trainer = \"AdamH\"\n",
        "base_title = \"ModelDeepResearch\"\n",
        "date_str = datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "planes = 31\n",
        "board  = 19\n",
        "moves  = board * board\n",
        "N      = 10000\n",
        "epochs = 200\n",
        "batch  = 128\n",
        "\n",
        "# Mod√®le l√©ger (‚âà99k params)\n",
        "filters            = 110\n",
        "se_reduction       = 10\n",
        "value_dense_units  = 64\n",
        "\n",
        "# R√©gularisation et optimisation\n",
        "l2_reg        = 1e-4\n",
        "base_lr       = 2e-4\n",
        "label_smooth  = 0.05\n",
        "clip_norm     = 1.0\n",
        "val_every     = 5\n",
        "use_symmetry_aug = True\n",
        "\n",
        "# ================================================================\n",
        "# üìÅ OUTPUT DIR\n",
        "# ================================================================\n",
        "model_name  = f\"{date_str}_{trainer}_{base_title}_ep{epochs}_bs{batch}_lr{base_lr}_l2{l2_reg}\"\n",
        "output_root = \"output\"\n",
        "output_dir  = os.path.join(output_root, model_name)\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"üßæ Mod√®le : {model_name}\")\n",
        "\n",
        "# ================================================================\n",
        "# üìä MOCK DATA BUFFERS (golois remplit en pratique)\n",
        "# ================================================================\n",
        "input_data = np.random.randint(2, size=(N, board, board, planes)).astype('float32')\n",
        "policy     = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value      = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end        = np.random.randint(2, size=(N, board, board, 2)).astype('float32')\n",
        "groups     = np.zeros((N, board, board, 1), dtype='float32')\n",
        "\n",
        "print(\"üîç Test golois.getValidation()‚Ä¶\")\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "print(\"‚úÖ golois pr√™t.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# üîÅ Data Augmentation : 8 sym√©tries (rotations/flips)\n",
        "# ================================================================\n",
        "def apply_random_symmetry(x_board, p_vec):\n",
        "    B = x_board.shape[0]\n",
        "    p_map = p_vec.reshape(B, board, board)\n",
        "    k = np.random.randint(0, 4)\n",
        "    do_flip = np.random.rand() < 0.5\n",
        "    x = np.rot90(x_board, k=k, axes=(1, 2))\n",
        "    p = np.rot90(p_map,   k=k, axes=(1, 2))\n",
        "    if do_flip:\n",
        "        x = np.flip(x, axis=2)\n",
        "        p = np.flip(p, axis=2)\n",
        "    return x, p.reshape(B, moves)\n",
        "\n",
        "def maybe_augment(x, p, z):\n",
        "    if not use_symmetry_aug:\n",
        "        return x, p, z\n",
        "    return apply_random_symmetry(x, p)\n",
        "\n",
        "# ================================================================\n",
        "# üß† MODEL ‚Äî Attention Hybrid (~99k)\n",
        "# ================================================================\n",
        "def dw_conv_block(x, filters, l2_reg, stride=1):\n",
        "    x = layers.SeparableConv2D(filters, kernel_size=3, strides=stride, padding='same', activation='relu',\n",
        "                               depthwise_regularizer=regularizers.l2(l2_reg),\n",
        "                               pointwise_regularizer=regularizers.l2(l2_reg), use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def se_block(x, reduction=10):\n",
        "    c = int(x.shape[-1])\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(max(c // reduction, 1), activation='relu')(se)\n",
        "    se = layers.Dense(c, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, c))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "def attention_residual_block(x, filters, l2_reg, reduction):\n",
        "    shortcut = x\n",
        "    x = dw_conv_block(x, filters, l2_reg)\n",
        "    x = dw_conv_block(x, filters, l2_reg)\n",
        "    x = se_block(x, reduction=reduction)\n",
        "    x = layers.Add()([shortcut, x])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "inp = keras.Input(shape=(board, board, planes), name='board')\n",
        "x = layers.Conv2D(filters, 1, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_reg), use_bias=False)(inp)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "for i in range(3):\n",
        "    x = attention_residual_block(x, filters, l2_reg, reduction=se_reduction)\n",
        "    if i % 2 == 1:\n",
        "        x = layers.Dropout(0.10)(x)\n",
        "\n",
        "# Policy head\n",
        "p = layers.Conv2D(1, 1, activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_reg), use_bias=False)(x)\n",
        "p = layers.Flatten()(p)\n",
        "policy_head = layers.Activation('softmax', name='policy')(p)\n",
        "\n",
        "# Value head\n",
        "v = layers.GlobalAveragePooling2D()(x)\n",
        "v = layers.Dense(value_dense_units, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(v)\n",
        "v = layers.Dropout(0.15)(v)\n",
        "value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=regularizers.l2(l2_reg))(v)\n",
        "\n",
        "model = keras.Model(inputs=inp, outputs=[policy_head, value_head])\n",
        "print(f\"üî¢ Total params: {model.count_params()}\")\n",
        "assert 90_000 <= model.count_params() < 110_000\n",
        "\n",
        "# ================================================================\n",
        "# ‚öôÔ∏è COMPILE + CALLBACKS ‚Äî Cosine LR + L2 + label smoothing\n",
        "# ================================================================\n",
        "steps_per_epoch = max(1, N // batch)\n",
        "decay_steps = epochs * steps_per_epoch\n",
        "lr_schedule = keras.optimizers.schedules.CosineDecay(initial_learning_rate=base_lr, decay_steps=decay_steps, alpha=0.2)\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=clip_norm)\n",
        "policy_loss = keras.losses.CategoricalCrossentropy(label_smoothing=label_smooth)\n",
        "value_loss  = keras.losses.MeanSquaredError()\n",
        "metrics_dict = {'policy': ['categorical_accuracy'], 'value': ['mae']}\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss={'policy': policy_loss, 'value': value_loss},\n",
        "              loss_weights={'policy': 1.0, 'value': 1.0},\n",
        "              metrics=metrics_dict)\n",
        "\n",
        "ckpt_path = os.path.join(output_dir, f\"{model_name}_best.keras\")\n",
        "csv_path  = os.path.join(output_dir, f\"{model_name}_training_log.csv\")\n",
        "\n",
        "common_callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(filepath=ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),\n",
        "    keras.callbacks.CSVLogger(csv_path, append=True)\n",
        "]\n",
        "\n",
        "top5_metric = keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5\")\n",
        "\n",
        "# ================================================================\n",
        "# üèãÔ∏è‚Äç‚ôÇÔ∏è TRAIN LOOP ‚Äî self-play buffer + validation p√©riodique\n",
        "# ================================================================\n",
        "for i in range(1, epochs + 1):\n",
        "    print(f\"\\n--- √âpoque {i}/{epochs} ---\")\n",
        "    golois.getBatch(input_data, policy, value, end, groups, i * N)\n",
        "    X_train, P_train = maybe_augment(input_data, policy, value)\n",
        "    Z_train = value\n",
        "\n",
        "    do_val = (i % val_every == 0) or (i == epochs)\n",
        "    validation_data, callbacks = None, []\n",
        "    if do_val:\n",
        "        golois.getValidation(input_data, policy, value, end)\n",
        "        validation_data = (input_data, [policy, value])\n",
        "        callbacks = common_callbacks\n",
        "\n",
        "    hist = model.fit(X_train, [P_train, Z_train], epochs=1, batch_size=batch, verbose=1, validation_data=validation_data, callbacks=callbacks)\n",
        "\n",
        "    preds_policy = model.predict(X_train, batch_size=batch, verbose=0)[0]\n",
        "    top5_val = float(top5_metric(P_train, preds_policy).numpy())\n",
        "    print(f\"üèÅ Epoch {i}: Top-5 acc={top5_val:.3f}, Value MAE={hist.history['value_mae'][0]:.4f}\")\n",
        "\n",
        "    if i % 5 == 0:\n",
        "        gc.collect()\n",
        "        print(\"üßπ GC.\")\n",
        "\n",
        "final_path = os.path.join(output_dir, f\"{model_name}_final.keras\")\n",
        "model.save(final_path)\n",
        "print(f\"\\nüíæ Sauvegardes :\\n - Best: {ckpt_path}\\n - Final: {final_path}\")\n",
        "print(\"‚úÖ Entra√Ænement termin√©.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# ‚úÖ CHECKLIST D‚ÄôENTRA√éNEMENT QUOTIDIEN (inspir√©e AlphaZero/KataGo)\n",
        "# ================================================================\n",
        "# 1Ô∏è‚É£ Lancer golois pour remplir le buffer self-play.\n",
        "# 2Ô∏è‚É£ V√©rifier la coh√©rence du buffer : œÄ (policy) bien normalis√©e.\n",
        "# 3Ô∏è‚É£ Lancer l'entra√Ænement pour ~200 epochs avec Cosine LR.\n",
        "# 4Ô∏è‚É£ Valider toutes les 5 epochs, early stop si plateau >6.\n",
        "# 5Ô∏è‚É£ V√©rifier policy_acc et top5 (objectif >45%).\n",
        "# 6Ô∏è‚É£ Suivre MAE value (objectif <0.15 √† convergence).\n",
        "# 7Ô∏è‚É£ Contr√¥ler les checkpoints et logs CSV.\n",
        "# 8Ô∏è‚É£ Si stagnation : diminuer LR min, augmenter dropout ou label_smooth.\n",
        "# 9Ô∏è‚É£ Nettoyer GPU (gc.collect) tous les 5 epochs.\n",
        "# üîü Archiver le meilleur mod√®le + logs pour tests Elo ult√©rieurs.\n",
        "# ================================================================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDw9kgirhHln",
        "outputId": "55dc080e-6982-46c2-fbe0-43873e2d2f65"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è GPU memory growth non appliqu√©: Physical devices cannot be modified after being initialized\n",
            "üßæ Mod√®le : 20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001\n",
            "üîç Test golois.getValidation()‚Ä¶\n",
            "‚úÖ golois pr√™t.\n",
            "\n",
            "üî¢ Total params: 99932\n",
            "\n",
            "--- √âpoque 1/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 182ms/step - loss: 6.4288 - policy_categorical_accuracy: 0.0087 - policy_loss: 6.2169 - value_loss: 0.1312 - value_mae: 0.3070\n",
            "üèÅ Epoch 1: Top-5 acc=0.089, Value MAE=0.2989\n",
            "\n",
            "--- √âpoque 2/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 5.2274 - policy_categorical_accuracy: 0.0605 - policy_loss: 5.0261 - value_loss: 0.1213 - value_mae: 0.2895\n",
            "üèÅ Epoch 2: Top-5 acc=0.068, Value MAE=0.2882\n",
            "\n",
            "--- √âpoque 3/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 4.8148 - policy_categorical_accuracy: 0.1081 - policy_loss: 4.6139 - value_loss: 0.1212 - value_mae: 0.2902\n",
            "üèÅ Epoch 3: Top-5 acc=0.061, Value MAE=0.2902\n",
            "\n",
            "--- √âpoque 4/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 4.5709 - policy_categorical_accuracy: 0.1356 - policy_loss: 4.3703 - value_loss: 0.1212 - value_mae: 0.2901\n",
            "üèÅ Epoch 4: Top-5 acc=0.072, Value MAE=0.2888\n",
            "\n",
            "--- √âpoque 5/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.7544 - policy_categorical_accuracy: 0.0024 - policy_loss: 6.5550 - value_loss: 0.1203 - value_mae: 0.2896\n",
            "Epoch 1: val_loss improved from inf to 6.05092, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - loss: 6.7422 - policy_categorical_accuracy: 0.0025 - policy_loss: 6.5427 - value_loss: 0.1203 - value_mae: 0.2895 - val_loss: 6.0509 - val_policy_categorical_accuracy: 0.0413 - val_policy_loss: 5.8520 - val_value_loss: 0.1195 - val_value_mae: 0.2897 - learning_rate: 1.9975e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 5: Top-5 acc=0.085, Value MAE=0.2887\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 6/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 5.3367 - policy_categorical_accuracy: 0.1074 - policy_loss: 5.1409 - value_loss: 0.1171 - value_mae: 0.2833\n",
            "üèÅ Epoch 6: Top-5 acc=0.120, Value MAE=0.2835\n",
            "\n",
            "--- √âpoque 7/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 4.3729 - policy_categorical_accuracy: 0.1749 - policy_loss: 4.1780 - value_loss: 0.1163 - value_mae: 0.2823\n",
            "üèÅ Epoch 7: Top-5 acc=0.159, Value MAE=0.2858\n",
            "\n",
            "--- √âpoque 8/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4.3259 - policy_categorical_accuracy: 0.1705 - policy_loss: 4.1303 - value_loss: 0.1172 - value_mae: 0.2832\n",
            "üèÅ Epoch 8: Top-5 acc=0.196, Value MAE=0.2852\n",
            "\n",
            "--- √âpoque 9/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 4.2081 - policy_categorical_accuracy: 0.1946 - policy_loss: 4.0134 - value_loss: 0.1164 - value_mae: 0.2834\n",
            "üèÅ Epoch 9: Top-5 acc=0.227, Value MAE=0.2844\n",
            "\n",
            "--- √âpoque 10/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.8248 - policy_categorical_accuracy: 0.0024 - policy_loss: 6.6285 - value_loss: 0.1183 - value_mae: 0.2868\n",
            "Epoch 1: val_loss improved from 6.05092 to 5.55362, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 6.8115 - policy_categorical_accuracy: 0.0024 - policy_loss: 6.6152 - value_loss: 0.1182 - value_mae: 0.2868 - val_loss: 5.5536 - val_policy_categorical_accuracy: 0.1207 - val_policy_loss: 5.3563 - val_value_loss: 0.1183 - val_value_mae: 0.2845 - learning_rate: 1.9899e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 10: Top-5 acc=0.206, Value MAE=0.2863\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 11/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 5.0206 - policy_categorical_accuracy: 0.1572 - policy_loss: 4.8241 - value_loss: 0.1185 - value_mae: 0.2873\n",
            "üèÅ Epoch 11: Top-5 acc=0.232, Value MAE=0.2874\n",
            "\n",
            "--- √âpoque 12/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.1282 - policy_categorical_accuracy: 0.2076 - policy_loss: 3.9324 - value_loss: 0.1183 - value_mae: 0.2857\n",
            "üèÅ Epoch 12: Top-5 acc=0.254, Value MAE=0.2858\n",
            "\n",
            "--- √âpoque 13/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 4.0226 - policy_categorical_accuracy: 0.2167 - policy_loss: 3.8298 - value_loss: 0.1155 - value_mae: 0.2818\n",
            "üèÅ Epoch 13: Top-5 acc=0.274, Value MAE=0.2827\n",
            "\n",
            "--- √âpoque 14/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.9529 - policy_categorical_accuracy: 0.2353 - policy_loss: 3.7599 - value_loss: 0.1159 - value_mae: 0.2826\n",
            "üèÅ Epoch 14: Top-5 acc=0.292, Value MAE=0.2812\n",
            "\n",
            "--- √âpoque 15/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.9143 - policy_categorical_accuracy: 0.0031 - policy_loss: 6.7205 - value_loss: 0.1167 - value_mae: 0.2845\n",
            "Epoch 1: val_loss improved from 5.55362 to 5.37530, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 6.8996 - policy_categorical_accuracy: 0.0031 - policy_loss: 6.7057 - value_loss: 0.1167 - value_mae: 0.2845 - val_loss: 5.3753 - val_policy_categorical_accuracy: 0.1472 - val_policy_loss: 5.1790 - val_value_loss: 0.1185 - val_value_mae: 0.2834 - learning_rate: 1.9773e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 15: Top-5 acc=0.274, Value MAE=0.2848\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 16/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 4.8410 - policy_categorical_accuracy: 0.1853 - policy_loss: 4.6492 - value_loss: 0.1150 - value_mae: 0.2813\n",
            "üèÅ Epoch 16: Top-5 acc=0.289, Value MAE=0.2826\n",
            "\n",
            "--- √âpoque 17/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.9254 - policy_categorical_accuracy: 0.2467 - policy_loss: 3.7355 - value_loss: 0.1133 - value_mae: 0.2783\n",
            "üèÅ Epoch 17: Top-5 acc=0.303, Value MAE=0.2814\n",
            "\n",
            "--- √âpoque 18/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.8876 - policy_categorical_accuracy: 0.2561 - policy_loss: 3.6929 - value_loss: 0.1182 - value_mae: 0.2863\n",
            "üèÅ Epoch 18: Top-5 acc=0.315, Value MAE=0.2864\n",
            "\n",
            "--- √âpoque 19/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.8372 - policy_categorical_accuracy: 0.2538 - policy_loss: 3.6471 - value_loss: 0.1134 - value_mae: 0.2785\n",
            "üèÅ Epoch 19: Top-5 acc=0.327, Value MAE=0.2795\n",
            "\n",
            "--- √âpoque 20/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.9908 - policy_categorical_accuracy: 0.0031 - policy_loss: 6.7981 - value_loss: 0.1164 - value_mae: 0.2833\n",
            "Epoch 1: val_loss improved from 5.37530 to 5.24861, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - loss: 6.9752 - policy_categorical_accuracy: 0.0031 - policy_loss: 6.7823 - value_loss: 0.1164 - value_mae: 0.2834 - val_loss: 5.2486 - val_policy_categorical_accuracy: 0.1660 - val_policy_loss: 5.0546 - val_value_loss: 0.1174 - val_value_mae: 0.2832 - learning_rate: 1.9598e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 20: Top-5 acc=0.311, Value MAE=0.2843\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 21/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4.7315 - policy_categorical_accuracy: 0.2022 - policy_loss: 4.5380 - value_loss: 0.1171 - value_mae: 0.2856\n",
            "üèÅ Epoch 21: Top-5 acc=0.322, Value MAE=0.2821\n",
            "\n",
            "--- √âpoque 22/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.8249 - policy_categorical_accuracy: 0.2575 - policy_loss: 3.6330 - value_loss: 0.1158 - value_mae: 0.2826\n",
            "üèÅ Epoch 22: Top-5 acc=0.332, Value MAE=0.2849\n",
            "\n",
            "--- √âpoque 23/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.7701 - policy_categorical_accuracy: 0.2659 - policy_loss: 3.5776 - value_loss: 0.1165 - value_mae: 0.2841\n",
            "üèÅ Epoch 23: Top-5 acc=0.342, Value MAE=0.2842\n",
            "\n",
            "--- √âpoque 24/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.7276 - policy_categorical_accuracy: 0.2726 - policy_loss: 3.5340 - value_loss: 0.1178 - value_mae: 0.2876\n",
            "üèÅ Epoch 24: Top-5 acc=0.350, Value MAE=0.2843\n",
            "\n",
            "--- √âpoque 25/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.0467 - policy_categorical_accuracy: 0.0035 - policy_loss: 6.8573 - value_loss: 0.1137 - value_mae: 0.2807\n",
            "Epoch 1: val_loss improved from 5.24861 to 5.24517, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 7.0300 - policy_categorical_accuracy: 0.0034 - policy_loss: 6.8404 - value_loss: 0.1138 - value_mae: 0.2809 - val_loss: 5.2452 - val_policy_categorical_accuracy: 0.1650 - val_policy_loss: 5.0532 - val_value_loss: 0.1187 - val_value_mae: 0.2838 - learning_rate: 1.9376e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 25: Top-5 acc=0.337, Value MAE=0.2850\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 26/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.6815 - policy_categorical_accuracy: 0.2212 - policy_loss: 4.4918 - value_loss: 0.1140 - value_mae: 0.2799\n",
            "üèÅ Epoch 26: Top-5 acc=0.345, Value MAE=0.2805\n",
            "\n",
            "--- √âpoque 27/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.7254 - policy_categorical_accuracy: 0.2729 - policy_loss: 3.5338 - value_loss: 0.1163 - value_mae: 0.2838\n",
            "üèÅ Epoch 27: Top-5 acc=0.353, Value MAE=0.2850\n",
            "\n",
            "--- √âpoque 28/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.6668 - policy_categorical_accuracy: 0.2881 - policy_loss: 3.4775 - value_loss: 0.1139 - value_mae: 0.2793\n",
            "üèÅ Epoch 28: Top-5 acc=0.361, Value MAE=0.2820\n",
            "\n",
            "--- √âpoque 29/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.6544 - policy_categorical_accuracy: 0.2817 - policy_loss: 3.4602 - value_loss: 0.1188 - value_mae: 0.2880\n",
            "üèÅ Epoch 29: Top-5 acc=0.368, Value MAE=0.2819\n",
            "\n",
            "--- √âpoque 30/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.0453 - policy_categorical_accuracy: 0.0027 - policy_loss: 6.8545 - value_loss: 0.1157 - value_mae: 0.2832\n",
            "Epoch 1: val_loss improved from 5.24517 to 5.17769, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 7.0285 - policy_categorical_accuracy: 0.0027 - policy_loss: 6.8377 - value_loss: 0.1157 - value_mae: 0.2833 - val_loss: 5.1777 - val_policy_categorical_accuracy: 0.1636 - val_policy_loss: 4.9900 - val_value_loss: 0.1159 - val_value_mae: 0.2828 - learning_rate: 1.9106e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 30: Top-5 acc=0.356, Value MAE=0.2841\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 31/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.6012 - policy_categorical_accuracy: 0.2315 - policy_loss: 4.4118 - value_loss: 0.1143 - value_mae: 0.2827\n",
            "üèÅ Epoch 31: Top-5 acc=0.363, Value MAE=0.2797\n",
            "\n",
            "--- √âpoque 32/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.6366 - policy_categorical_accuracy: 0.2834 - policy_loss: 3.4470 - value_loss: 0.1146 - value_mae: 0.2815\n",
            "üèÅ Epoch 32: Top-5 acc=0.369, Value MAE=0.2807\n",
            "\n",
            "--- √âpoque 33/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.6338 - policy_categorical_accuracy: 0.2836 - policy_loss: 3.4460 - value_loss: 0.1131 - value_mae: 0.2787\n",
            "üèÅ Epoch 33: Top-5 acc=0.375, Value MAE=0.2804\n",
            "\n",
            "--- √âpoque 34/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.6212 - policy_categorical_accuracy: 0.2873 - policy_loss: 3.4308 - value_loss: 0.1159 - value_mae: 0.2830\n",
            "üèÅ Epoch 34: Top-5 acc=0.381, Value MAE=0.2824\n",
            "\n",
            "--- √âpoque 35/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.0440 - policy_categorical_accuracy: 0.0021 - policy_loss: 6.8529 - value_loss: 0.1166 - value_mae: 0.2849\n",
            "Epoch 1: val_loss improved from 5.17769 to 5.17732, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 7.0272 - policy_categorical_accuracy: 0.0022 - policy_loss: 6.8360 - value_loss: 0.1166 - value_mae: 0.2848 - val_loss: 5.1773 - val_policy_categorical_accuracy: 0.1800 - val_policy_loss: 4.9891 - val_value_loss: 0.1162 - val_value_mae: 0.2814 - learning_rate: 1.8791e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 35: Top-5 acc=0.371, Value MAE=0.2833\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 36/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 4.5574 - policy_categorical_accuracy: 0.2313 - policy_loss: 4.3677 - value_loss: 0.1153 - value_mae: 0.2843\n",
            "üèÅ Epoch 36: Top-5 acc=0.377, Value MAE=0.2824\n",
            "\n",
            "--- √âpoque 37/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.6111 - policy_categorical_accuracy: 0.2945 - policy_loss: 3.4227 - value_loss: 0.1142 - value_mae: 0.2809\n",
            "üèÅ Epoch 37: Top-5 acc=0.382, Value MAE=0.2812\n",
            "\n",
            "--- √âpoque 38/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.5862 - policy_categorical_accuracy: 0.2910 - policy_loss: 3.3978 - value_loss: 0.1142 - value_mae: 0.2824\n",
            "üèÅ Epoch 38: Top-5 acc=0.387, Value MAE=0.2829\n",
            "\n",
            "--- √âpoque 39/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5985 - policy_categorical_accuracy: 0.2871 - policy_loss: 3.4111 - value_loss: 0.1134 - value_mae: 0.2794\n",
            "üèÅ Epoch 39: Top-5 acc=0.392, Value MAE=0.2803\n",
            "\n",
            "--- √âpoque 40/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.5211 - policy_categorical_accuracy: 0.2999 - policy_loss: 3.3340 - value_loss: 0.1132 - value_mae: 0.2806\n",
            "Epoch 1: val_loss improved from 5.17732 to 3.41604, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 3.5211 - policy_categorical_accuracy: 0.2999 - policy_loss: 3.3342 - value_loss: 0.1132 - value_mae: 0.2806 - val_loss: 3.4160 - val_policy_categorical_accuracy: 0.3209 - val_policy_loss: 3.2232 - val_value_loss: 0.1135 - val_value_mae: 0.2799 - learning_rate: 1.8434e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 40: Top-5 acc=0.397, Value MAE=0.2814\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 41/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5679 - policy_categorical_accuracy: 0.2943 - policy_loss: 3.3809 - value_loss: 0.1133 - value_mae: 0.2796\n",
            "üèÅ Epoch 41: Top-5 acc=0.402, Value MAE=0.2791\n",
            "\n",
            "--- √âpoque 42/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.5428 - policy_categorical_accuracy: 0.2983 - policy_loss: 3.3543 - value_loss: 0.1149 - value_mae: 0.2833\n",
            "üèÅ Epoch 42: Top-5 acc=0.406, Value MAE=0.2818\n",
            "\n",
            "--- √âpoque 43/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4560 - policy_categorical_accuracy: 0.3125 - policy_loss: 3.2686 - value_loss: 0.1140 - value_mae: 0.2810\n",
            "üèÅ Epoch 43: Top-5 acc=0.411, Value MAE=0.2793\n",
            "\n",
            "--- √âpoque 44/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4699 - policy_categorical_accuracy: 0.3125 - policy_loss: 3.2832 - value_loss: 0.1135 - value_mae: 0.2796\n",
            "üèÅ Epoch 44: Top-5 acc=0.416, Value MAE=0.2787\n",
            "\n",
            "--- √âpoque 45/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.1837 - policy_categorical_accuracy: 0.0015 - policy_loss: 6.9966 - value_loss: 0.1139 - value_mae: 0.2814\n",
            "Epoch 1: val_loss did not improve from 3.41604\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 7.1644 - policy_categorical_accuracy: 0.0015 - policy_loss: 6.9772 - value_loss: 0.1139 - value_mae: 0.2814 - val_loss: 5.1009 - val_policy_categorical_accuracy: 0.1873 - val_policy_loss: 4.9140 - val_value_loss: 0.1156 - val_value_mae: 0.2796 - learning_rate: 1.8036e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 45: Top-5 acc=0.407, Value MAE=0.2812\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 46/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 4.5121 - policy_categorical_accuracy: 0.2488 - policy_loss: 4.3239 - value_loss: 0.1150 - value_mae: 0.2831\n",
            "üèÅ Epoch 46: Top-5 acc=0.410, Value MAE=0.2794\n",
            "\n",
            "--- √âpoque 47/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.4910 - policy_categorical_accuracy: 0.3080 - policy_loss: 3.3047 - value_loss: 0.1134 - value_mae: 0.2804\n",
            "üèÅ Epoch 47: Top-5 acc=0.415, Value MAE=0.2805\n",
            "\n",
            "--- √âpoque 48/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4895 - policy_categorical_accuracy: 0.3048 - policy_loss: 3.3045 - value_loss: 0.1121 - value_mae: 0.2782\n",
            "üèÅ Epoch 48: Top-5 acc=0.418, Value MAE=0.2810\n",
            "\n",
            "--- √âpoque 49/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3.4402 - policy_categorical_accuracy: 0.3109 - policy_loss: 3.2532 - value_loss: 0.1140 - value_mae: 0.2826\n",
            "üèÅ Epoch 49: Top-5 acc=0.422, Value MAE=0.2803\n",
            "\n",
            "--- √âpoque 50/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.4356 - policy_categorical_accuracy: 0.3154 - policy_loss: 3.2522 - value_loss: 0.1105 - value_mae: 0.2752\n",
            "Epoch 1: val_loss improved from 3.41604 to 3.31629, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 3.4354 - policy_categorical_accuracy: 0.3154 - policy_loss: 3.2519 - value_loss: 0.1106 - value_mae: 0.2753 - val_loss: 3.3163 - val_policy_categorical_accuracy: 0.3390 - val_policy_loss: 3.1265 - val_value_loss: 0.1116 - val_value_mae: 0.2770 - learning_rate: 1.7600e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 50: Top-5 acc=0.426, Value MAE=0.2779\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 51/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.4833 - policy_categorical_accuracy: 0.3095 - policy_loss: 3.2987 - value_loss: 0.1120 - value_mae: 0.2790\n",
            "üèÅ Epoch 51: Top-5 acc=0.430, Value MAE=0.2793\n",
            "\n",
            "--- √âpoque 52/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4442 - policy_categorical_accuracy: 0.3073 - policy_loss: 3.2615 - value_loss: 0.1100 - value_mae: 0.2749\n",
            "üèÅ Epoch 52: Top-5 acc=0.433, Value MAE=0.2733\n",
            "\n",
            "--- √âpoque 53/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4684 - policy_categorical_accuracy: 0.3027 - policy_loss: 3.2863 - value_loss: 0.1094 - value_mae: 0.2738\n",
            "üèÅ Epoch 53: Top-5 acc=0.436, Value MAE=0.2753\n",
            "\n",
            "--- √âpoque 54/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4734 - policy_categorical_accuracy: 0.3015 - policy_loss: 3.2907 - value_loss: 0.1104 - value_mae: 0.2763\n",
            "üèÅ Epoch 54: Top-5 acc=0.439, Value MAE=0.2751\n",
            "\n",
            "--- √âpoque 55/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.1819 - policy_categorical_accuracy: 0.0027 - policy_loss: 6.9972 - value_loss: 0.1124 - value_mae: 0.2792\n",
            "Epoch 1: val_loss did not improve from 3.31629\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 7.1627 - policy_categorical_accuracy: 0.0027 - policy_loss: 6.9779 - value_loss: 0.1124 - value_mae: 0.2792 - val_loss: 5.1090 - val_policy_categorical_accuracy: 0.2027 - val_policy_loss: 4.9224 - val_value_loss: 0.1154 - val_value_mae: 0.2770 - learning_rate: 1.7128e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 55: Top-5 acc=0.431, Value MAE=0.2777\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 56/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 4.4724 - policy_categorical_accuracy: 0.2549 - policy_loss: 4.2871 - value_loss: 0.1128 - value_mae: 0.2807\n",
            "üèÅ Epoch 56: Top-5 acc=0.434, Value MAE=0.2781\n",
            "\n",
            "--- √âpoque 57/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4574 - policy_categorical_accuracy: 0.3109 - policy_loss: 3.2717 - value_loss: 0.1135 - value_mae: 0.2800\n",
            "üèÅ Epoch 57: Top-5 acc=0.437, Value MAE=0.2805\n",
            "\n",
            "--- √âpoque 58/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4602 - policy_categorical_accuracy: 0.3090 - policy_loss: 3.2781 - value_loss: 0.1102 - value_mae: 0.2752\n",
            "üèÅ Epoch 58: Top-5 acc=0.440, Value MAE=0.2757\n",
            "\n",
            "--- √âpoque 59/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4290 - policy_categorical_accuracy: 0.3154 - policy_loss: 3.2472 - value_loss: 0.1100 - value_mae: 0.2762\n",
            "üèÅ Epoch 59: Top-5 acc=0.443, Value MAE=0.2766\n",
            "\n",
            "--- √âpoque 60/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.1968 - policy_categorical_accuracy: 0.0032 - policy_loss: 7.0124 - value_loss: 0.1125 - value_mae: 0.2787\n",
            "Epoch 1: val_loss did not improve from 3.31629\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 7.1768 - policy_categorical_accuracy: 0.0032 - policy_loss: 6.9923 - value_loss: 0.1125 - value_mae: 0.2786 - val_loss: 5.0733 - val_policy_categorical_accuracy: 0.2037 - val_policy_loss: 4.8887 - val_value_loss: 0.1136 - val_value_mae: 0.2762 - learning_rate: 1.6624e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 60: Top-5 acc=0.436, Value MAE=0.2768\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 61/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 4.4224 - policy_categorical_accuracy: 0.2715 - policy_loss: 4.2396 - value_loss: 0.1110 - value_mae: 0.2773\n",
            "üèÅ Epoch 61: Top-5 acc=0.439, Value MAE=0.2772\n",
            "\n",
            "--- √âpoque 62/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4585 - policy_categorical_accuracy: 0.3170 - policy_loss: 3.2768 - value_loss: 0.1099 - value_mae: 0.2748\n",
            "üèÅ Epoch 62: Top-5 acc=0.441, Value MAE=0.2744\n",
            "\n",
            "--- √âpoque 63/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3898 - policy_categorical_accuracy: 0.3108 - policy_loss: 3.2109 - value_loss: 0.1071 - value_mae: 0.2703\n",
            "üèÅ Epoch 63: Top-5 acc=0.444, Value MAE=0.2716\n",
            "\n",
            "--- √âpoque 64/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4001 - policy_categorical_accuracy: 0.3203 - policy_loss: 3.2200 - value_loss: 0.1085 - value_mae: 0.2724\n",
            "üèÅ Epoch 64: Top-5 acc=0.447, Value MAE=0.2743\n",
            "\n",
            "--- √âpoque 65/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.1595 - policy_categorical_accuracy: 0.0033 - policy_loss: 6.9795 - value_loss: 0.1086 - value_mae: 0.2731\n",
            "Epoch 1: val_loss did not improve from 3.31629\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 7.1409 - policy_categorical_accuracy: 0.0033 - policy_loss: 6.9608 - value_loss: 0.1086 - value_mae: 0.2732 - val_loss: 5.1007 - val_policy_categorical_accuracy: 0.1988 - val_policy_loss: 4.9118 - val_value_loss: 0.1191 - val_value_mae: 0.2763 - learning_rate: 1.6090e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 65: Top-5 acc=0.440, Value MAE=0.2745\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 66/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.4024 - policy_categorical_accuracy: 0.2578 - policy_loss: 4.2239 - value_loss: 0.1072 - value_mae: 0.2717\n",
            "üèÅ Epoch 66: Top-5 acc=0.442, Value MAE=0.2725\n",
            "\n",
            "--- √âpoque 67/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4688 - policy_categorical_accuracy: 0.3103 - policy_loss: 3.2897 - value_loss: 0.1079 - value_mae: 0.2712\n",
            "üèÅ Epoch 67: Top-5 acc=0.445, Value MAE=0.2690\n",
            "\n",
            "--- √âpoque 68/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4233 - policy_categorical_accuracy: 0.3147 - policy_loss: 3.2436 - value_loss: 0.1087 - value_mae: 0.2734\n",
            "üèÅ Epoch 68: Top-5 acc=0.447, Value MAE=0.2730\n",
            "\n",
            "--- √âpoque 69/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4078 - policy_categorical_accuracy: 0.3153 - policy_loss: 3.2294 - value_loss: 0.1073 - value_mae: 0.2706\n",
            "üèÅ Epoch 69: Top-5 acc=0.450, Value MAE=0.2722\n",
            "\n",
            "--- √âpoque 70/200 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.1225 - policy_categorical_accuracy: 0.0022 - policy_loss: 6.9445 - value_loss: 0.1069 - value_mae: 0.2707\n",
            "Epoch 1: val_loss did not improve from 3.31629\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 7.1109 - policy_categorical_accuracy: 0.0022 - policy_loss: 6.9327 - value_loss: 0.1070 - value_mae: 0.2708 - val_loss: 5.0156 - val_policy_categorical_accuracy: 0.2016 - val_policy_loss: 4.8276 - val_value_loss: 0.1183 - val_value_mae: 0.2755 - learning_rate: 1.5531e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 70: Top-5 acc=0.443, Value MAE=0.2742\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 71/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 4.4189 - policy_categorical_accuracy: 0.2620 - policy_loss: 4.2403 - value_loss: 0.1075 - value_mae: 0.2704\n",
            "üèÅ Epoch 71: Top-5 acc=0.446, Value MAE=0.2728\n",
            "\n",
            "--- √âpoque 72/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4198 - policy_categorical_accuracy: 0.3285 - policy_loss: 3.2414 - value_loss: 0.1073 - value_mae: 0.2710\n",
            "üèÅ Epoch 72: Top-5 acc=0.448, Value MAE=0.2714\n",
            "\n",
            "--- √âpoque 73/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3832 - policy_categorical_accuracy: 0.3246 - policy_loss: 3.2081 - value_loss: 0.1042 - value_mae: 0.2655\n",
            "üèÅ Epoch 73: Top-5 acc=0.450, Value MAE=0.2693\n",
            "\n",
            "--- √âpoque 74/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4111 - policy_categorical_accuracy: 0.3133 - policy_loss: 3.2342 - value_loss: 0.1062 - value_mae: 0.2673\n",
            "üèÅ Epoch 74: Top-5 acc=0.452, Value MAE=0.2670\n",
            "\n",
            "--- √âpoque 75/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.1907 - policy_categorical_accuracy: 0.0052 - policy_loss: 7.0110 - value_loss: 0.1091 - value_mae: 0.2739\n",
            "Epoch 1: val_loss did not improve from 3.31629\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 7.1709 - policy_categorical_accuracy: 0.0051 - policy_loss: 6.9910 - value_loss: 0.1091 - value_mae: 0.2738 - val_loss: 5.0024 - val_policy_categorical_accuracy: 0.1973 - val_policy_loss: 4.8176 - val_value_loss: 0.1140 - val_value_mae: 0.2718 - learning_rate: 1.4949e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 75: Top-5 acc=0.447, Value MAE=0.2719\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 76/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.3644 - policy_categorical_accuracy: 0.2708 - policy_loss: 4.1876 - value_loss: 0.1059 - value_mae: 0.2680\n",
            "üèÅ Epoch 76: Top-5 acc=0.449, Value MAE=0.2690\n",
            "\n",
            "--- √âpoque 77/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.4575 - policy_categorical_accuracy: 0.3155 - policy_loss: 3.2781 - value_loss: 0.1088 - value_mae: 0.2732\n",
            "üèÅ Epoch 77: Top-5 acc=0.451, Value MAE=0.2715\n",
            "\n",
            "--- √âpoque 78/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3423 - policy_categorical_accuracy: 0.3276 - policy_loss: 3.1674 - value_loss: 0.1045 - value_mae: 0.2666\n",
            "üèÅ Epoch 78: Top-5 acc=0.453, Value MAE=0.2710\n",
            "\n",
            "--- √âpoque 79/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3948 - policy_categorical_accuracy: 0.3259 - policy_loss: 3.2180 - value_loss: 0.1066 - value_mae: 0.2688\n",
            "üèÅ Epoch 79: Top-5 acc=0.455, Value MAE=0.2672\n",
            "\n",
            "--- √âpoque 80/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.3368 - policy_categorical_accuracy: 0.3334 - policy_loss: 3.1592 - value_loss: 0.1073 - value_mae: 0.2710\n",
            "Epoch 1: val_loss improved from 3.31629 to 3.27288, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 3.3372 - policy_categorical_accuracy: 0.3333 - policy_loss: 3.1595 - value_loss: 0.1073 - value_mae: 0.2710 - val_loss: 3.2729 - val_policy_categorical_accuracy: 0.3434 - val_policy_loss: 3.0902 - val_value_loss: 0.1069 - val_value_mae: 0.2696 - learning_rate: 1.4349e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 80: Top-5 acc=0.457, Value MAE=0.2709\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 81/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3560 - policy_categorical_accuracy: 0.3257 - policy_loss: 3.1817 - value_loss: 0.1041 - value_mae: 0.2650\n",
            "üèÅ Epoch 81: Top-5 acc=0.459, Value MAE=0.2669\n",
            "\n",
            "--- √âpoque 82/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3825 - policy_categorical_accuracy: 0.3225 - policy_loss: 3.2073 - value_loss: 0.1052 - value_mae: 0.2667\n",
            "üèÅ Epoch 82: Top-5 acc=0.461, Value MAE=0.2675\n",
            "\n",
            "--- √âpoque 83/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.3516 - policy_categorical_accuracy: 0.3136 - policy_loss: 3.1760 - value_loss: 0.1056 - value_mae: 0.2682\n",
            "üèÅ Epoch 83: Top-5 acc=0.463, Value MAE=0.2689\n",
            "\n",
            "--- √âpoque 84/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3320 - policy_categorical_accuracy: 0.3274 - policy_loss: 3.1558 - value_loss: 0.1063 - value_mae: 0.2689\n",
            "üèÅ Epoch 84: Top-5 acc=0.465, Value MAE=0.2668\n",
            "\n",
            "--- √âpoque 85/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.2991 - policy_categorical_accuracy: 0.0028 - policy_loss: 7.1226 - value_loss: 0.1066 - value_mae: 0.2694\n",
            "Epoch 1: val_loss did not improve from 3.27288\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 7.2792 - policy_categorical_accuracy: 0.0028 - policy_loss: 7.1025 - value_loss: 0.1066 - value_mae: 0.2694 - val_loss: 4.8959 - val_policy_categorical_accuracy: 0.2133 - val_policy_loss: 4.7122 - val_value_loss: 0.1139 - val_value_mae: 0.2712 - learning_rate: 1.3734e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 85: Top-5 acc=0.459, Value MAE=0.2703\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 86/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.3251 - policy_categorical_accuracy: 0.2788 - policy_loss: 4.1474 - value_loss: 0.1078 - value_mae: 0.2706\n",
            "üèÅ Epoch 86: Top-5 acc=0.461, Value MAE=0.2694\n",
            "\n",
            "--- √âpoque 87/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3592 - policy_categorical_accuracy: 0.3244 - policy_loss: 3.1851 - value_loss: 0.1044 - value_mae: 0.2653\n",
            "üèÅ Epoch 87: Top-5 acc=0.463, Value MAE=0.2690\n",
            "\n",
            "--- √âpoque 88/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3546 - policy_categorical_accuracy: 0.3184 - policy_loss: 3.1788 - value_loss: 0.1061 - value_mae: 0.2687\n",
            "üèÅ Epoch 88: Top-5 acc=0.465, Value MAE=0.2699\n",
            "\n",
            "--- √âpoque 89/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3635 - policy_categorical_accuracy: 0.3239 - policy_loss: 3.1875 - value_loss: 0.1063 - value_mae: 0.2678\n",
            "üèÅ Epoch 89: Top-5 acc=0.466, Value MAE=0.2675\n",
            "\n",
            "--- √âpoque 90/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.2467 - policy_categorical_accuracy: 0.0036 - policy_loss: 7.0732 - value_loss: 0.1039 - value_mae: 0.2642\n",
            "Epoch 1: val_loss did not improve from 3.27288\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 7.2278 - policy_categorical_accuracy: 0.0036 - policy_loss: 7.0540 - value_loss: 0.1040 - value_mae: 0.2644 - val_loss: 4.8846 - val_policy_categorical_accuracy: 0.2068 - val_policy_loss: 4.7024 - val_value_loss: 0.1132 - val_value_mae: 0.2700 - learning_rate: 1.3108e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 90: Top-5 acc=0.461, Value MAE=0.2688\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 91/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.3132 - policy_categorical_accuracy: 0.2661 - policy_loss: 4.1381 - value_loss: 0.1057 - value_mae: 0.2668\n",
            "üèÅ Epoch 91: Top-5 acc=0.463, Value MAE=0.2686\n",
            "\n",
            "--- √âpoque 92/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.4268 - policy_categorical_accuracy: 0.3173 - policy_loss: 3.2509 - value_loss: 0.1062 - value_mae: 0.2690\n",
            "üèÅ Epoch 92: Top-5 acc=0.465, Value MAE=0.2681\n",
            "\n",
            "--- √âpoque 93/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3135 - policy_categorical_accuracy: 0.3369 - policy_loss: 3.1381 - value_loss: 0.1056 - value_mae: 0.2681\n",
            "üèÅ Epoch 93: Top-5 acc=0.466, Value MAE=0.2689\n",
            "\n",
            "--- √âpoque 94/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.3699 - policy_categorical_accuracy: 0.3164 - policy_loss: 3.1950 - value_loss: 0.1054 - value_mae: 0.2666\n",
            "üèÅ Epoch 94: Top-5 acc=0.468, Value MAE=0.2679\n",
            "\n",
            "--- √âpoque 95/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.3056 - policy_categorical_accuracy: 0.0025 - policy_loss: 7.1323 - value_loss: 0.1040 - value_mae: 0.2640\n",
            "Epoch 1: val_loss did not improve from 3.27288\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 7.2857 - policy_categorical_accuracy: 0.0025 - policy_loss: 7.1121 - value_loss: 0.1041 - value_mae: 0.2642 - val_loss: 4.8061 - val_policy_categorical_accuracy: 0.2184 - val_policy_loss: 4.6268 - val_value_loss: 0.1100 - val_value_mae: 0.2674 - learning_rate: 1.2475e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 95: Top-5 acc=0.463, Value MAE=0.2676\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 96/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.3106 - policy_categorical_accuracy: 0.2601 - policy_loss: 4.1341 - value_loss: 0.1072 - value_mae: 0.2689\n",
            "üèÅ Epoch 96: Top-5 acc=0.465, Value MAE=0.2668\n",
            "\n",
            "--- √âpoque 97/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3651 - policy_categorical_accuracy: 0.3318 - policy_loss: 3.1865 - value_loss: 0.1093 - value_mae: 0.2738\n",
            "üèÅ Epoch 97: Top-5 acc=0.466, Value MAE=0.2691\n",
            "\n",
            "--- √âpoque 98/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3752 - policy_categorical_accuracy: 0.3148 - policy_loss: 3.2008 - value_loss: 0.1054 - value_mae: 0.2686\n",
            "üèÅ Epoch 98: Top-5 acc=0.468, Value MAE=0.2687\n",
            "\n",
            "--- √âpoque 99/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3470 - policy_categorical_accuracy: 0.3206 - policy_loss: 3.1731 - value_loss: 0.1048 - value_mae: 0.2655\n",
            "üèÅ Epoch 99: Top-5 acc=0.469, Value MAE=0.2660\n",
            "\n",
            "--- √âpoque 100/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2950 - policy_categorical_accuracy: 0.3357 - policy_loss: 3.1200 - value_loss: 0.1058 - value_mae: 0.2674\n",
            "Epoch 1: val_loss improved from 3.27288 to 3.24046, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.2943 - policy_categorical_accuracy: 0.3358 - policy_loss: 3.1193 - value_loss: 0.1058 - value_mae: 0.2674 - val_loss: 3.2405 - val_policy_categorical_accuracy: 0.3456 - val_policy_loss: 3.0607 - val_value_loss: 0.1059 - val_value_mae: 0.2669 - learning_rate: 1.1839e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 100: Top-5 acc=0.471, Value MAE=0.2669\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 101/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3050 - policy_categorical_accuracy: 0.3317 - policy_loss: 3.1303 - value_loss: 0.1057 - value_mae: 0.2663\n",
            "üèÅ Epoch 101: Top-5 acc=0.473, Value MAE=0.2671\n",
            "\n",
            "--- √âpoque 102/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.3182 - policy_categorical_accuracy: 0.3224 - policy_loss: 3.1438 - value_loss: 0.1056 - value_mae: 0.2661\n",
            "üèÅ Epoch 102: Top-5 acc=0.474, Value MAE=0.2650\n",
            "\n",
            "--- √âpoque 103/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.2926 - policy_categorical_accuracy: 0.3420 - policy_loss: 3.1173 - value_loss: 0.1062 - value_mae: 0.2670\n",
            "üèÅ Epoch 103: Top-5 acc=0.476, Value MAE=0.2677\n",
            "\n",
            "--- √âpoque 104/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.2383 - policy_categorical_accuracy: 0.3431 - policy_loss: 3.0655 - value_loss: 0.1039 - value_mae: 0.2650\n",
            "üèÅ Epoch 104: Top-5 acc=0.477, Value MAE=0.2657\n",
            "\n",
            "--- √âpoque 105/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.4427 - policy_categorical_accuracy: 0.0015 - policy_loss: 7.2675 - value_loss: 0.1064 - value_mae: 0.2683\n",
            "Epoch 1: val_loss did not improve from 3.24046\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 7.4213 - policy_categorical_accuracy: 0.0015 - policy_loss: 7.2459 - value_loss: 0.1064 - value_mae: 0.2683 - val_loss: 4.7829 - val_policy_categorical_accuracy: 0.1942 - val_policy_loss: 4.6048 - val_value_loss: 0.1097 - val_value_mae: 0.2672 - learning_rate: 1.1204e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 105: Top-5 acc=0.473, Value MAE=0.2675\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 106/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4.2300 - policy_categorical_accuracy: 0.2705 - policy_loss: 4.0562 - value_loss: 0.1052 - value_mae: 0.2655\n",
            "üèÅ Epoch 106: Top-5 acc=0.474, Value MAE=0.2658\n",
            "\n",
            "--- √âpoque 107/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3974 - policy_categorical_accuracy: 0.3215 - policy_loss: 3.2204 - value_loss: 0.1084 - value_mae: 0.2706\n",
            "üèÅ Epoch 107: Top-5 acc=0.475, Value MAE=0.2696\n",
            "\n",
            "--- √âpoque 108/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2825 - policy_categorical_accuracy: 0.3368 - policy_loss: 3.1088 - value_loss: 0.1050 - value_mae: 0.2671\n",
            "üèÅ Epoch 108: Top-5 acc=0.477, Value MAE=0.2677\n",
            "\n",
            "--- √âpoque 109/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3451 - policy_categorical_accuracy: 0.3197 - policy_loss: 3.1703 - value_loss: 0.1063 - value_mae: 0.2677\n",
            "üèÅ Epoch 109: Top-5 acc=0.478, Value MAE=0.2694\n",
            "\n",
            "--- √âpoque 110/200 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.3159 - policy_categorical_accuracy: 0.0035 - policy_loss: 7.1423 - value_loss: 0.1050 - value_mae: 0.2663\n",
            "Epoch 1: val_loss did not improve from 3.24046\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 7.3034 - policy_categorical_accuracy: 0.0035 - policy_loss: 7.1296 - value_loss: 0.1050 - value_mae: 0.2663 - val_loss: 4.6743 - val_policy_categorical_accuracy: 0.1932 - val_policy_loss: 4.5004 - val_value_loss: 0.1051 - val_value_mae: 0.2662 - learning_rate: 1.0574e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 110: Top-5 acc=0.474, Value MAE=0.2666\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 111/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.2157 - policy_categorical_accuracy: 0.2740 - policy_loss: 4.0430 - value_loss: 0.1042 - value_mae: 0.2646\n",
            "üèÅ Epoch 111: Top-5 acc=0.475, Value MAE=0.2626\n",
            "\n",
            "--- √âpoque 112/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3462 - policy_categorical_accuracy: 0.3314 - policy_loss: 3.1723 - value_loss: 0.1056 - value_mae: 0.2664\n",
            "üèÅ Epoch 112: Top-5 acc=0.477, Value MAE=0.2658\n",
            "\n",
            "--- √âpoque 113/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.3110 - policy_categorical_accuracy: 0.3325 - policy_loss: 3.1394 - value_loss: 0.1032 - value_mae: 0.2639\n",
            "üèÅ Epoch 113: Top-5 acc=0.478, Value MAE=0.2650\n",
            "\n",
            "--- √âpoque 114/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3046 - policy_categorical_accuracy: 0.3330 - policy_loss: 3.1319 - value_loss: 0.1042 - value_mae: 0.2641\n",
            "üèÅ Epoch 114: Top-5 acc=0.479, Value MAE=0.2637\n",
            "\n",
            "--- √âpoque 115/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.3342 - policy_categorical_accuracy: 0.0037 - policy_loss: 7.1599 - value_loss: 0.1060 - value_mae: 0.2677\n",
            "Epoch 1: val_loss did not improve from 3.24046\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 7.3153 - policy_categorical_accuracy: 0.0037 - policy_loss: 7.1409 - value_loss: 0.1059 - value_mae: 0.2677 - val_loss: 4.6215 - val_policy_categorical_accuracy: 0.1838 - val_policy_loss: 4.4489 - val_value_loss: 0.1051 - val_value_mae: 0.2665 - learning_rate: 9.9528e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 115: Top-5 acc=0.475, Value MAE=0.2670\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 116/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.1676 - policy_categorical_accuracy: 0.2742 - policy_loss: 3.9928 - value_loss: 0.1067 - value_mae: 0.2688\n",
            "üèÅ Epoch 116: Top-5 acc=0.476, Value MAE=0.2675\n",
            "\n",
            "--- √âpoque 117/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3707 - policy_categorical_accuracy: 0.3320 - policy_loss: 3.1963 - value_loss: 0.1061 - value_mae: 0.2671\n",
            "üèÅ Epoch 117: Top-5 acc=0.478, Value MAE=0.2668\n",
            "\n",
            "--- √âpoque 118/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3210 - policy_categorical_accuracy: 0.3288 - policy_loss: 3.1482 - value_loss: 0.1044 - value_mae: 0.2645\n",
            "üèÅ Epoch 118: Top-5 acc=0.479, Value MAE=0.2638\n",
            "\n",
            "--- √âpoque 119/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.2959 - policy_categorical_accuracy: 0.3335 - policy_loss: 3.1260 - value_loss: 0.1016 - value_mae: 0.2600\n",
            "üèÅ Epoch 119: Top-5 acc=0.480, Value MAE=0.2598\n",
            "\n",
            "--- √âpoque 120/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.3492 - policy_categorical_accuracy: 0.0023 - policy_loss: 7.1777 - value_loss: 0.1034 - value_mae: 0.2633\n",
            "Epoch 1: val_loss did not improve from 3.24046\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 7.3310 - policy_categorical_accuracy: 0.0023 - policy_loss: 7.1592 - value_loss: 0.1034 - value_mae: 0.2634 - val_loss: 4.5045 - val_policy_categorical_accuracy: 0.2156 - val_policy_loss: 4.3313 - val_value_loss: 0.1056 - val_value_mae: 0.2679 - learning_rate: 9.3447e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 120: Top-5 acc=0.476, Value MAE=0.2663\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 121/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.1742 - policy_categorical_accuracy: 0.2636 - policy_loss: 4.0012 - value_loss: 0.1048 - value_mae: 0.2660\n",
            "üèÅ Epoch 121: Top-5 acc=0.477, Value MAE=0.2636\n",
            "\n",
            "--- √âpoque 122/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3738 - policy_categorical_accuracy: 0.3268 - policy_loss: 3.2019 - value_loss: 0.1041 - value_mae: 0.2639\n",
            "üèÅ Epoch 122: Top-5 acc=0.479, Value MAE=0.2634\n",
            "\n",
            "--- √âpoque 123/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3000 - policy_categorical_accuracy: 0.3366 - policy_loss: 3.1260 - value_loss: 0.1062 - value_mae: 0.2685\n",
            "üèÅ Epoch 123: Top-5 acc=0.480, Value MAE=0.2648\n",
            "\n",
            "--- √âpoque 124/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3404 - policy_categorical_accuracy: 0.3231 - policy_loss: 3.1696 - value_loss: 0.1025 - value_mae: 0.2605\n",
            "üèÅ Epoch 124: Top-5 acc=0.481, Value MAE=0.2622\n",
            "\n",
            "--- √âpoque 125/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.3932 - policy_categorical_accuracy: 0.0030 - policy_loss: 7.2215 - value_loss: 0.1037 - value_mae: 0.2640\n",
            "Epoch 1: val_loss did not improve from 3.24046\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 7.3744 - policy_categorical_accuracy: 0.0031 - policy_loss: 7.2025 - value_loss: 0.1038 - value_mae: 0.2640 - val_loss: 4.3812 - val_policy_categorical_accuracy: 0.2313 - val_policy_loss: 4.2065 - val_value_loss: 0.1072 - val_value_mae: 0.2684 - learning_rate: 8.7535e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 125: Top-5 acc=0.477, Value MAE=0.2657\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 126/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.1148 - policy_categorical_accuracy: 0.2727 - policy_loss: 3.9401 - value_loss: 0.1068 - value_mae: 0.2687\n",
            "üèÅ Epoch 126: Top-5 acc=0.478, Value MAE=0.2672\n",
            "\n",
            "--- √âpoque 127/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3487 - policy_categorical_accuracy: 0.3296 - policy_loss: 3.1747 - value_loss: 0.1061 - value_mae: 0.2661\n",
            "üèÅ Epoch 127: Top-5 acc=0.479, Value MAE=0.2630\n",
            "\n",
            "--- √âpoque 128/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3187 - policy_categorical_accuracy: 0.3340 - policy_loss: 3.1468 - value_loss: 0.1040 - value_mae: 0.2636\n",
            "üèÅ Epoch 128: Top-5 acc=0.481, Value MAE=0.2634\n",
            "\n",
            "--- √âpoque 129/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.2929 - policy_categorical_accuracy: 0.3387 - policy_loss: 3.1204 - value_loss: 0.1046 - value_mae: 0.2630\n",
            "üèÅ Epoch 129: Top-5 acc=0.482, Value MAE=0.2638\n",
            "\n",
            "--- √âpoque 130/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.4446 - policy_categorical_accuracy: 0.0032 - policy_loss: 7.2722 - value_loss: 0.1046 - value_mae: 0.2648\n",
            "Epoch 1: val_loss did not improve from 3.24046\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 7.4260 - policy_categorical_accuracy: 0.0032 - policy_loss: 7.2534 - value_loss: 0.1046 - value_mae: 0.2648 - val_loss: 4.3921 - val_policy_categorical_accuracy: 0.2593 - val_policy_loss: 4.2164 - val_value_loss: 0.1078 - val_value_mae: 0.2658 - learning_rate: 8.1827e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 130: Top-5 acc=0.478, Value MAE=0.2656\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 131/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.0138 - policy_categorical_accuracy: 0.2884 - policy_loss: 3.8410 - value_loss: 0.1050 - value_mae: 0.2672\n",
            "üèÅ Epoch 131: Top-5 acc=0.479, Value MAE=0.2667\n",
            "\n",
            "--- √âpoque 132/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.3711 - policy_categorical_accuracy: 0.3401 - policy_loss: 3.1975 - value_loss: 0.1059 - value_mae: 0.2651\n",
            "üèÅ Epoch 132: Top-5 acc=0.480, Value MAE=0.2656\n",
            "\n",
            "--- √âpoque 133/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3340 - policy_categorical_accuracy: 0.3307 - policy_loss: 3.1613 - value_loss: 0.1051 - value_mae: 0.2651\n",
            "üèÅ Epoch 133: Top-5 acc=0.482, Value MAE=0.2637\n",
            "\n",
            "--- √âpoque 134/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.3029 - policy_categorical_accuracy: 0.3341 - policy_loss: 3.1312 - value_loss: 0.1040 - value_mae: 0.2631\n",
            "üèÅ Epoch 134: Top-5 acc=0.483, Value MAE=0.2629\n",
            "\n",
            "--- √âpoque 135/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.4387 - policy_categorical_accuracy: 0.0023 - policy_loss: 7.2681 - value_loss: 0.1029 - value_mae: 0.2629\n",
            "Epoch 1: val_loss did not improve from 3.24046\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 7.4211 - policy_categorical_accuracy: 0.0023 - policy_loss: 7.2502 - value_loss: 0.1030 - value_mae: 0.2630 - val_loss: 4.3548 - val_policy_categorical_accuracy: 0.2728 - val_policy_loss: 4.1799 - val_value_loss: 0.1061 - val_value_mae: 0.2641 - learning_rate: 7.6361e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 135: Top-5 acc=0.479, Value MAE=0.2636\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 136/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.9684 - policy_categorical_accuracy: 0.3002 - policy_loss: 3.7956 - value_loss: 0.1051 - value_mae: 0.2648\n",
            "üèÅ Epoch 136: Top-5 acc=0.480, Value MAE=0.2616\n",
            "\n",
            "--- √âpoque 137/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.3374 - policy_categorical_accuracy: 0.3316 - policy_loss: 3.1673 - value_loss: 0.1022 - value_mae: 0.2596\n",
            "üèÅ Epoch 137: Top-5 acc=0.481, Value MAE=0.2603\n",
            "\n",
            "--- √âpoque 138/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3424 - policy_categorical_accuracy: 0.3267 - policy_loss: 3.1724 - value_loss: 0.1024 - value_mae: 0.2604\n",
            "üèÅ Epoch 138: Top-5 acc=0.482, Value MAE=0.2623\n",
            "\n",
            "--- √âpoque 139/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2736 - policy_categorical_accuracy: 0.3410 - policy_loss: 3.1043 - value_loss: 0.1017 - value_mae: 0.2599\n",
            "üèÅ Epoch 139: Top-5 acc=0.483, Value MAE=0.2619\n",
            "\n",
            "--- √âpoque 140/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.4080 - policy_categorical_accuracy: 0.0021 - policy_loss: 7.2362 - value_loss: 0.1043 - value_mae: 0.2636\n",
            "Epoch 1: val_loss did not improve from 3.24046\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 7.3911 - policy_categorical_accuracy: 0.0021 - policy_loss: 7.2192 - value_loss: 0.1043 - value_mae: 0.2636 - val_loss: 4.4850 - val_policy_categorical_accuracy: 0.2586 - val_policy_loss: 4.3076 - val_value_loss: 0.1084 - val_value_mae: 0.2660 - learning_rate: 7.1171e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 140: Top-5 acc=0.480, Value MAE=0.2640\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 141/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 4.0151 - policy_categorical_accuracy: 0.2925 - policy_loss: 3.8409 - value_loss: 0.1066 - value_mae: 0.2676\n",
            "üèÅ Epoch 141: Top-5 acc=0.481, Value MAE=0.2667\n",
            "\n",
            "--- √âpoque 142/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3578 - policy_categorical_accuracy: 0.3311 - policy_loss: 3.1851 - value_loss: 0.1052 - value_mae: 0.2653\n",
            "üèÅ Epoch 142: Top-5 acc=0.482, Value MAE=0.2650\n",
            "\n",
            "--- √âpoque 143/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3099 - policy_categorical_accuracy: 0.3260 - policy_loss: 3.1385 - value_loss: 0.1041 - value_mae: 0.2626\n",
            "üèÅ Epoch 143: Top-5 acc=0.483, Value MAE=0.2634\n",
            "\n",
            "--- √âpoque 144/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.2878 - policy_categorical_accuracy: 0.3330 - policy_loss: 3.1137 - value_loss: 0.1067 - value_mae: 0.2671\n",
            "üèÅ Epoch 144: Top-5 acc=0.484, Value MAE=0.2668\n",
            "\n",
            "--- √âpoque 145/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.2149 - policy_categorical_accuracy: 0.3449 - policy_loss: 3.0424 - value_loss: 0.1051 - value_mae: 0.2662\n",
            "Epoch 1: val_loss improved from 3.24046 to 3.20325, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - loss: 3.2156 - policy_categorical_accuracy: 0.3449 - policy_loss: 3.0432 - value_loss: 0.1050 - value_mae: 0.2661 - val_loss: 3.2032 - val_policy_categorical_accuracy: 0.3509 - val_policy_loss: 3.0282 - val_value_loss: 0.1033 - val_value_mae: 0.2623 - learning_rate: 6.6290e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 145: Top-5 acc=0.485, Value MAE=0.2638\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 146/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2779 - policy_categorical_accuracy: 0.3364 - policy_loss: 3.1073 - value_loss: 0.1032 - value_mae: 0.2615\n",
            "üèÅ Epoch 146: Top-5 acc=0.486, Value MAE=0.2652\n",
            "\n",
            "--- √âpoque 147/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2693 - policy_categorical_accuracy: 0.3387 - policy_loss: 3.0970 - value_loss: 0.1049 - value_mae: 0.2654\n",
            "üèÅ Epoch 147: Top-5 acc=0.487, Value MAE=0.2654\n",
            "\n",
            "--- √âpoque 148/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2300 - policy_categorical_accuracy: 0.3411 - policy_loss: 3.0593 - value_loss: 0.1034 - value_mae: 0.2621\n",
            "üèÅ Epoch 148: Top-5 acc=0.488, Value MAE=0.2615\n",
            "\n",
            "--- √âpoque 149/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2731 - policy_categorical_accuracy: 0.3338 - policy_loss: 3.1015 - value_loss: 0.1044 - value_mae: 0.2644\n",
            "üèÅ Epoch 149: Top-5 acc=0.489, Value MAE=0.2636\n",
            "\n",
            "--- √âpoque 150/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.5527 - policy_categorical_accuracy: 0.0025 - policy_loss: 7.3810 - value_loss: 0.1045 - value_mae: 0.2641\n",
            "Epoch 1: val_loss did not improve from 3.20325\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 7.5353 - policy_categorical_accuracy: 0.0025 - policy_loss: 7.3635 - value_loss: 0.1044 - value_mae: 0.2641 - val_loss: 4.3486 - val_policy_categorical_accuracy: 0.2607 - val_policy_loss: 4.1723 - val_value_loss: 0.1067 - val_value_mae: 0.2651 - learning_rate: 6.1749e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 150: Top-5 acc=0.486, Value MAE=0.2631\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 151/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.9399 - policy_categorical_accuracy: 0.2994 - policy_loss: 3.7693 - value_loss: 0.1033 - value_mae: 0.2631\n",
            "üèÅ Epoch 151: Top-5 acc=0.487, Value MAE=0.2626\n",
            "\n",
            "--- √âpoque 152/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3.3130 - policy_categorical_accuracy: 0.3383 - policy_loss: 3.1412 - value_loss: 0.1045 - value_mae: 0.2641\n",
            "üèÅ Epoch 152: Top-5 acc=0.488, Value MAE=0.2639\n",
            "\n",
            "--- √âpoque 153/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2932 - policy_categorical_accuracy: 0.3338 - policy_loss: 3.1234 - value_loss: 0.1026 - value_mae: 0.2613\n",
            "üèÅ Epoch 153: Top-5 acc=0.489, Value MAE=0.2639\n",
            "\n",
            "--- √âpoque 154/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.2758 - policy_categorical_accuracy: 0.3392 - policy_loss: 3.1042 - value_loss: 0.1043 - value_mae: 0.2635\n",
            "üèÅ Epoch 154: Top-5 acc=0.490, Value MAE=0.2624\n",
            "\n",
            "--- √âpoque 155/200 ---\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2407 - policy_categorical_accuracy: 0.3436 - policy_loss: 3.0685 - value_loss: 0.1050 - value_mae: 0.2657\n",
            "Epoch 1: val_loss improved from 3.20325 to 3.16992, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.2405 - policy_categorical_accuracy: 0.3436 - policy_loss: 3.0685 - value_loss: 0.1050 - value_mae: 0.2657 - val_loss: 3.1699 - val_policy_categorical_accuracy: 0.3572 - val_policy_loss: 2.9937 - val_value_loss: 0.1036 - val_value_mae: 0.2625 - learning_rate: 5.7576e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 155: Top-5 acc=0.491, Value MAE=0.2635\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 156/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2690 - policy_categorical_accuracy: 0.3328 - policy_loss: 3.0975 - value_loss: 0.1045 - value_mae: 0.2646\n",
            "üèÅ Epoch 156: Top-5 acc=0.491, Value MAE=0.2650\n",
            "\n",
            "--- √âpoque 157/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2428 - policy_categorical_accuracy: 0.3328 - policy_loss: 3.0746 - value_loss: 0.1010 - value_mae: 0.2581\n",
            "üèÅ Epoch 157: Top-5 acc=0.492, Value MAE=0.2607\n",
            "\n",
            "--- √âpoque 158/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2710 - policy_categorical_accuracy: 0.3369 - policy_loss: 3.0988 - value_loss: 0.1053 - value_mae: 0.2657\n",
            "üèÅ Epoch 158: Top-5 acc=0.493, Value MAE=0.2654\n",
            "\n",
            "--- √âpoque 159/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2261 - policy_categorical_accuracy: 0.3463 - policy_loss: 3.0557 - value_loss: 0.1032 - value_mae: 0.2613\n",
            "üèÅ Epoch 159: Top-5 acc=0.494, Value MAE=0.2634\n",
            "\n",
            "--- √âpoque 160/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.6393 - policy_categorical_accuracy: 0.0033 - policy_loss: 7.4666 - value_loss: 0.1057 - value_mae: 0.2669\n",
            "Epoch 1: val_loss did not improve from 3.16992\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 7.6217 - policy_categorical_accuracy: 0.0033 - policy_loss: 7.4488 - value_loss: 0.1057 - value_mae: 0.2668 - val_loss: 4.2505 - val_policy_categorical_accuracy: 0.2743 - val_policy_loss: 4.0760 - val_value_loss: 0.1052 - val_value_mae: 0.2644 - learning_rate: 5.3797e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 160: Top-5 acc=0.491, Value MAE=0.2636\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 161/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.8881 - policy_categorical_accuracy: 0.3082 - policy_loss: 3.7170 - value_loss: 0.1041 - value_mae: 0.2643\n",
            "üèÅ Epoch 161: Top-5 acc=0.492, Value MAE=0.2630\n",
            "\n",
            "--- √âpoque 162/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.3021 - policy_categorical_accuracy: 0.3446 - policy_loss: 3.1310 - value_loss: 0.1044 - value_mae: 0.2645\n",
            "üèÅ Epoch 162: Top-5 acc=0.493, Value MAE=0.2626\n",
            "\n",
            "--- √âpoque 163/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2564 - policy_categorical_accuracy: 0.3429 - policy_loss: 3.0834 - value_loss: 0.1061 - value_mae: 0.2671\n",
            "üèÅ Epoch 163: Top-5 acc=0.494, Value MAE=0.2659\n",
            "\n",
            "--- √âpoque 164/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3.2613 - policy_categorical_accuracy: 0.3324 - policy_loss: 3.0945 - value_loss: 0.0998 - value_mae: 0.2565\n",
            "üèÅ Epoch 164: Top-5 acc=0.495, Value MAE=0.2587\n",
            "\n",
            "--- √âpoque 165/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.2631 - policy_categorical_accuracy: 0.3405 - policy_loss: 3.0940 - value_loss: 0.1022 - value_mae: 0.2599\n",
            "Epoch 1: val_loss improved from 3.16992 to 3.15350, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 3.2614 - policy_categorical_accuracy: 0.3408 - policy_loss: 3.0922 - value_loss: 0.1023 - value_mae: 0.2600 - val_loss: 3.1535 - val_policy_categorical_accuracy: 0.3576 - val_policy_loss: 2.9782 - val_value_loss: 0.1032 - val_value_mae: 0.2619 - learning_rate: 5.0438e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 165: Top-5 acc=0.496, Value MAE=0.2627\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 166/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.1995 - policy_categorical_accuracy: 0.3507 - policy_loss: 3.0295 - value_loss: 0.1031 - value_mae: 0.2625\n",
            "üèÅ Epoch 166: Top-5 acc=0.496, Value MAE=0.2623\n",
            "\n",
            "--- √âpoque 167/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.2655 - policy_categorical_accuracy: 0.3437 - policy_loss: 3.0963 - value_loss: 0.1024 - value_mae: 0.2616\n",
            "üèÅ Epoch 167: Top-5 acc=0.497, Value MAE=0.2605\n",
            "\n",
            "--- √âpoque 168/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2738 - policy_categorical_accuracy: 0.3381 - policy_loss: 3.1047 - value_loss: 0.1023 - value_mae: 0.2619\n",
            "üèÅ Epoch 168: Top-5 acc=0.498, Value MAE=0.2627\n",
            "\n",
            "--- √âpoque 169/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2336 - policy_categorical_accuracy: 0.3454 - policy_loss: 3.0614 - value_loss: 0.1055 - value_mae: 0.2663\n",
            "üèÅ Epoch 169: Top-5 acc=0.499, Value MAE=0.2628\n",
            "\n",
            "--- √âpoque 170/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.6702 - policy_categorical_accuracy: 0.0022 - policy_loss: 7.5013 - value_loss: 0.1021 - value_mae: 0.2605\n",
            "Epoch 1: val_loss did not improve from 3.15350\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 7.6531 - policy_categorical_accuracy: 0.0022 - policy_loss: 7.4840 - value_loss: 0.1022 - value_mae: 0.2606 - val_loss: 4.1899 - val_policy_categorical_accuracy: 0.2814 - val_policy_loss: 4.0161 - val_value_loss: 0.1040 - val_value_mae: 0.2633 - learning_rate: 4.7518e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 170: Top-5 acc=0.496, Value MAE=0.2635\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 171/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.8017 - policy_categorical_accuracy: 0.3052 - policy_loss: 3.6319 - value_loss: 0.1029 - value_mae: 0.2629\n",
            "üèÅ Epoch 171: Top-5 acc=0.497, Value MAE=0.2617\n",
            "\n",
            "--- √âpoque 172/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2828 - policy_categorical_accuracy: 0.3469 - policy_loss: 3.1118 - value_loss: 0.1043 - value_mae: 0.2646\n",
            "üèÅ Epoch 172: Top-5 acc=0.498, Value MAE=0.2640\n",
            "\n",
            "--- √âpoque 173/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2977 - policy_categorical_accuracy: 0.3356 - policy_loss: 3.1285 - value_loss: 0.1025 - value_mae: 0.2623\n",
            "üèÅ Epoch 173: Top-5 acc=0.498, Value MAE=0.2616\n",
            "\n",
            "--- √âpoque 174/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3.2242 - policy_categorical_accuracy: 0.3491 - policy_loss: 3.0536 - value_loss: 0.1041 - value_mae: 0.2621\n",
            "üèÅ Epoch 174: Top-5 acc=0.499, Value MAE=0.2635\n",
            "\n",
            "--- √âpoque 175/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2099 - policy_categorical_accuracy: 0.3470 - policy_loss: 3.0390 - value_loss: 0.1042 - value_mae: 0.2639\n",
            "Epoch 1: val_loss improved from 3.15350 to 3.14000, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.2096 - policy_categorical_accuracy: 0.3470 - policy_loss: 3.0390 - value_loss: 0.1042 - value_mae: 0.2638 - val_loss: 3.1400 - val_policy_categorical_accuracy: 0.3628 - val_policy_loss: 2.9654 - val_value_loss: 0.1027 - val_value_mae: 0.2612 - learning_rate: 4.5057e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 175: Top-5 acc=0.500, Value MAE=0.2629\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 176/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2541 - policy_categorical_accuracy: 0.3345 - policy_loss: 3.0860 - value_loss: 0.1015 - value_mae: 0.2592\n",
            "üèÅ Epoch 176: Top-5 acc=0.501, Value MAE=0.2605\n",
            "\n",
            "--- √âpoque 177/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.2766 - policy_categorical_accuracy: 0.3355 - policy_loss: 3.1075 - value_loss: 0.1024 - value_mae: 0.2603\n",
            "üèÅ Epoch 177: Top-5 acc=0.502, Value MAE=0.2611\n",
            "\n",
            "--- √âpoque 178/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2758 - policy_categorical_accuracy: 0.3307 - policy_loss: 3.1060 - value_loss: 0.1031 - value_mae: 0.2622\n",
            "üèÅ Epoch 178: Top-5 acc=0.502, Value MAE=0.2619\n",
            "\n",
            "--- √âpoque 179/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2721 - policy_categorical_accuracy: 0.3350 - policy_loss: 3.1049 - value_loss: 0.1006 - value_mae: 0.2592\n",
            "üèÅ Epoch 179: Top-5 acc=0.503, Value MAE=0.2608\n",
            "\n",
            "--- √âpoque 180/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.1867 - policy_categorical_accuracy: 0.3485 - policy_loss: 3.0151 - value_loss: 0.1051 - value_mae: 0.2645\n",
            "Epoch 1: val_loss improved from 3.14000 to 3.11658, saving model to output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 3.1864 - policy_categorical_accuracy: 0.3486 - policy_loss: 3.0150 - value_loss: 0.1050 - value_mae: 0.2644 - val_loss: 3.1166 - val_policy_categorical_accuracy: 0.3630 - val_policy_loss: 2.9420 - val_value_loss: 0.1026 - val_value_mae: 0.2607 - learning_rate: 4.3070e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 180: Top-5 acc=0.504, Value MAE=0.2616\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 181/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 3.2192 - policy_categorical_accuracy: 0.3395 - policy_loss: 3.0497 - value_loss: 0.1030 - value_mae: 0.2613\n",
            "üèÅ Epoch 181: Top-5 acc=0.505, Value MAE=0.2611\n",
            "\n",
            "--- √âpoque 182/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2622 - policy_categorical_accuracy: 0.3319 - policy_loss: 3.0947 - value_loss: 0.1010 - value_mae: 0.2594\n",
            "üèÅ Epoch 182: Top-5 acc=0.505, Value MAE=0.2633\n",
            "\n",
            "--- √âpoque 183/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2128 - policy_categorical_accuracy: 0.3410 - policy_loss: 3.0399 - value_loss: 0.1065 - value_mae: 0.2660\n",
            "üèÅ Epoch 183: Top-5 acc=0.506, Value MAE=0.2654\n",
            "\n",
            "--- √âpoque 184/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2544 - policy_categorical_accuracy: 0.3387 - policy_loss: 3.0850 - value_loss: 0.1029 - value_mae: 0.2613\n",
            "üèÅ Epoch 184: Top-5 acc=0.507, Value MAE=0.2621\n",
            "\n",
            "--- √âpoque 185/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.7496 - policy_categorical_accuracy: 0.0038 - policy_loss: 7.5807 - value_loss: 0.1024 - value_mae: 0.2610\n",
            "Epoch 1: val_loss did not improve from 3.11658\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 7.7325 - policy_categorical_accuracy: 0.0038 - policy_loss: 7.5634 - value_loss: 0.1025 - value_mae: 0.2611 - val_loss: 4.0291 - val_policy_categorical_accuracy: 0.2973 - val_policy_loss: 3.8551 - val_value_loss: 0.1045 - val_value_mae: 0.2629 - learning_rate: 4.1569e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 185: Top-5 acc=0.504, Value MAE=0.2623\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 186/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.7311 - policy_categorical_accuracy: 0.3143 - policy_loss: 3.5616 - value_loss: 0.1030 - value_mae: 0.2600\n",
            "üèÅ Epoch 186: Top-5 acc=0.505, Value MAE=0.2604\n",
            "\n",
            "--- √âpoque 187/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 3.3380 - policy_categorical_accuracy: 0.3305 - policy_loss: 3.1664 - value_loss: 0.1050 - value_mae: 0.2657\n",
            "üèÅ Epoch 187: Top-5 acc=0.505, Value MAE=0.2631\n",
            "\n",
            "--- √âpoque 188/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2140 - policy_categorical_accuracy: 0.3571 - policy_loss: 3.0456 - value_loss: 0.1019 - value_mae: 0.2595\n",
            "üèÅ Epoch 188: Top-5 acc=0.506, Value MAE=0.2597\n",
            "\n",
            "--- √âpoque 189/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2698 - policy_categorical_accuracy: 0.3382 - policy_loss: 3.0993 - value_loss: 0.1043 - value_mae: 0.2651\n",
            "üèÅ Epoch 189: Top-5 acc=0.507, Value MAE=0.2630\n",
            "\n",
            "--- √âpoque 190/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.6040 - policy_categorical_accuracy: 0.0025 - policy_loss: 7.4361 - value_loss: 0.1016 - value_mae: 0.2588\n",
            "Epoch 1: val_loss did not improve from 3.11658\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 7.5891 - policy_categorical_accuracy: 0.0025 - policy_loss: 7.4210 - value_loss: 0.1016 - value_mae: 0.2589 - val_loss: 3.8633 - val_policy_categorical_accuracy: 0.3255 - val_policy_loss: 3.6904 - val_value_loss: 0.1033 - val_value_mae: 0.2613 - learning_rate: 4.0564e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 190: Top-5 acc=0.504, Value MAE=0.2618\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 191/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.7595 - policy_categorical_accuracy: 0.3114 - policy_loss: 3.5902 - value_loss: 0.1032 - value_mae: 0.2629\n",
            "üèÅ Epoch 191: Top-5 acc=0.505, Value MAE=0.2620\n",
            "\n",
            "--- √âpoque 192/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3.3036 - policy_categorical_accuracy: 0.3430 - policy_loss: 3.1358 - value_loss: 0.1016 - value_mae: 0.2586\n",
            "üèÅ Epoch 192: Top-5 acc=0.505, Value MAE=0.2589\n",
            "\n",
            "--- √âpoque 193/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2327 - policy_categorical_accuracy: 0.3524 - policy_loss: 3.0619 - value_loss: 0.1046 - value_mae: 0.2648\n",
            "üèÅ Epoch 193: Top-5 acc=0.506, Value MAE=0.2612\n",
            "\n",
            "--- √âpoque 194/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2867 - policy_categorical_accuracy: 0.3294 - policy_loss: 3.1181 - value_loss: 0.1023 - value_mae: 0.2612\n",
            "üèÅ Epoch 194: Top-5 acc=0.507, Value MAE=0.2600\n",
            "\n",
            "--- √âpoque 195/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.5139 - policy_categorical_accuracy: 0.0040 - policy_loss: 7.3464 - value_loss: 0.1012 - value_mae: 0.2594\n",
            "Epoch 1: val_loss did not improve from 3.11658\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 7.5001 - policy_categorical_accuracy: 0.0039 - policy_loss: 7.3324 - value_loss: 0.1012 - value_mae: 0.2595 - val_loss: 3.7790 - val_policy_categorical_accuracy: 0.3272 - val_policy_loss: 3.6059 - val_value_loss: 0.1042 - val_value_mae: 0.2620 - learning_rate: 4.0062e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 195: Top-5 acc=0.504, Value MAE=0.2619\n",
            "üßπ GC.\n",
            "\n",
            "--- √âpoque 196/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.7092 - policy_categorical_accuracy: 0.3172 - policy_loss: 3.5388 - value_loss: 0.1042 - value_mae: 0.2636\n",
            "üèÅ Epoch 196: Top-5 acc=0.505, Value MAE=0.2606\n",
            "\n",
            "--- √âpoque 197/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 3.2773 - policy_categorical_accuracy: 0.3392 - policy_loss: 3.1109 - value_loss: 0.1003 - value_mae: 0.2564\n",
            "üèÅ Epoch 197: Top-5 acc=0.506, Value MAE=0.2606\n",
            "\n",
            "--- √âpoque 198/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3.2853 - policy_categorical_accuracy: 0.3347 - policy_loss: 3.1162 - value_loss: 0.1029 - value_mae: 0.2620\n",
            "üèÅ Epoch 198: Top-5 acc=0.506, Value MAE=0.2600\n",
            "\n",
            "--- √âpoque 199/200 ---\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 3.2719 - policy_categorical_accuracy: 0.3373 - policy_loss: 3.0959 - value_loss: 0.1096 - value_mae: 0.2725\n",
            "üèÅ Epoch 199: Top-5 acc=0.507, Value MAE=0.2672\n",
            "\n",
            "--- √âpoque 200/200 ---\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.5220 - policy_categorical_accuracy: 0.0022 - policy_loss: 7.3539 - value_loss: 0.1018 - value_mae: 0.2589\n",
            "Epoch 1: val_loss did not improve from 3.11658\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 7.5079 - policy_categorical_accuracy: 0.0022 - policy_loss: 7.3397 - value_loss: 0.1019 - value_mae: 0.2591 - val_loss: 3.6763 - val_policy_categorical_accuracy: 0.3289 - val_policy_loss: 3.5019 - val_value_loss: 0.1059 - val_value_mae: 0.2659 - learning_rate: 4.0000e-05\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "üèÅ Epoch 200: Top-5 acc=0.504, Value MAE=0.2633\n",
            "üßπ GC.\n",
            "\n",
            "üíæ Sauvegardes :\n",
            " - Best: output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            " - Final: output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_final.keras\n",
            "‚úÖ Entra√Ænement termin√©.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3hvbz6raPeg"
      },
      "source": [
        "# Sauvegarde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UVmBNNsraPeg",
        "outputId": "13db1b81-73d6-4b88-e97c-aff7ff3d499b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®les sauvegard√©s :\n",
            " - output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001.h5\n",
            " - output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001.keras\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history_all' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1595169093.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# üîπ Sauvegarde de l‚Äôhistorique complet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üìò Historique sauvegard√© : {hist_json}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history_all' is not defined"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# üíæ SAUVEGARDE + üìä VISUALISATION + üìà LISSAGE + üì¶ ZIP DOWNLOAD\n",
        "# ================================================================\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# üîπ Cr√©ation du dossier (si manquant)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# üîπ Sauvegarde du mod√®le (.h5 & .keras)\n",
        "h5_path = os.path.join(output_dir, f\"{model_name}.h5\")\n",
        "keras_path = os.path.join(output_dir, f\"{model_name}.keras\")\n",
        "hist_json = os.path.join(output_dir, \"history.json\")\n",
        "\n",
        "model.save(h5_path)\n",
        "model.save(keras_path)\n",
        "print(f\"‚úÖ Mod√®les sauvegard√©s :\\n - {h5_path}\\n - {keras_path}\")\n",
        "\n",
        "# üîπ Sauvegarde de l‚Äôhistorique complet\n",
        "with open(hist_json, \"w\") as f:\n",
        "    json.dump(history_all, f)\n",
        "print(f\"üìò Historique sauvegard√© : {hist_json}\")\n",
        "\n",
        "# ================================================================\n",
        "# üìä VISUALISATION DES COURBES\n",
        "# ================================================================\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "\n",
        "def save_plot(fig, name):\n",
        "    fig.savefig(os.path.join(output_dir, name), dpi=300, bbox_inches='tight')\n",
        "\n",
        "epochs_range = range(1, len(history_all.get(\"loss\", [])) + 1)\n",
        "\n",
        "# --- 1Ô∏è‚É£ Courbe de perte (Loss)\n",
        "if history_all.get(\"loss\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"loss\"], label='Training Loss', linewidth=2)\n",
        "    if history_all.get(\"val_loss\"):\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_loss\"], label='Validation Loss', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Loss\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Loss\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"loss_curve.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 2Ô∏è‚É£ Policy Accuracy\n",
        "if history_all.get(\"policy_categorical_accuracy\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"policy_categorical_accuracy\"], label='Policy Accuracy', linewidth=2)\n",
        "    if history_all.get(\"val_policy_categorical_accuracy\"):\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_policy_categorical_accuracy\"], '--', label='Val Policy Acc', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Policy Accuracy\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"policy_accuracy.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 3Ô∏è‚É£ Top-5 Accuracy\n",
        "if history_all.get(\"policy_top5\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"policy_top5\"], label='Top-5 Accuracy', linewidth=2)\n",
        "    if history_all.get(\"val_policy_top5\"):  # ‚úÖ cl√© optionnelle\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_policy_top5\"], '--', label='Val Top-5', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Top-5 Accuracy\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"top5_accuracy.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 4Ô∏è‚É£ Value MAE\n",
        "if history_all.get(\"value_mae\"):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(epochs_range, history_all[\"value_mae\"], label='Value MAE', linewidth=2)\n",
        "    if history_all.get(\"val_value_mae\"):\n",
        "        ax.plot(history_all[\"val_epochs\"], history_all[\"val_value_mae\"], '--', label='Val Value MAE', linewidth=2)\n",
        "    ax.set_title(f\"{model_name} - Value MAE\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"MAE\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    save_plot(fig, \"value_mae.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# ================================================================\n",
        "# üìà LISSAGE (Policy Accuracy)\n",
        "# ================================================================\n",
        "def moving_average(data, window=5):\n",
        "    data = np.array(data)\n",
        "    if len(data) < window:\n",
        "        return data\n",
        "    return np.convolve(data, np.ones(window)/window, mode='valid')\n",
        "\n",
        "if history_all.get(\"policy_categorical_accuracy\"):\n",
        "    smooth_acc = moving_average(history_all[\"policy_categorical_accuracy\"], 5)\n",
        "    epochs_smooth = np.arange(5, len(history_all[\"policy_categorical_accuracy\"]) + 1)\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    ax.plot(range(1, len(history_all[\"policy_categorical_accuracy\"]) + 1),\n",
        "            history_all[\"policy_categorical_accuracy\"], alpha=0.4, label='Brut', linewidth=1.5)\n",
        "    ax.plot(epochs_smooth, smooth_acc, color='red', linewidth=2.5,\n",
        "            label='Moyenne glissante (5)')\n",
        "    ax.set_title(f\"{model_name} - Policy Accuracy (Liss√©e)\")\n",
        "    ax.set_xlabel(\"Epochs\"); ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend(); ax.grid(True, linestyle='--', alpha=0.8)\n",
        "    save_plot(fig, \"policy_acc_smooth.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "# ================================================================\n",
        "# üßæ EXPORT DU R√âSUM√â DES M√âTRIQUES\n",
        "# ================================================================\n",
        "summary_path = os.path.join(output_dir, \"metrics_summary.txt\")\n",
        "with open(summary_path, \"w\") as f:\n",
        "    f.write(f\"Model: {model_name}\\n\")\n",
        "    f.write(f\"Epochs: {len(history_all.get('loss', []))}\\n\\n\")\n",
        "    if history_all.get(\"loss\"):\n",
        "        f.write(f\"Final Training Loss: {history_all['loss'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"val_loss\"):\n",
        "        f.write(f\"Final Validation Loss: {history_all['val_loss'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"policy_categorical_accuracy\"):\n",
        "        f.write(f\"Final Policy Accuracy: {history_all['policy_categorical_accuracy'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"val_policy_categorical_accuracy\"):\n",
        "        f.write(f\"Final Val Policy Accuracy: {history_all['val_policy_categorical_accuracy'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"value_mae\"):\n",
        "        f.write(f\"Final Value MAE: {history_all['value_mae'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"val_value_mae\"):\n",
        "        f.write(f\"Final Val Value MAE: {history_all['val_value_mae'][-1]:.4f}\\n\")\n",
        "    if history_all.get(\"policy_top5\"):\n",
        "        f.write(f\"Final Policy Top-5: {history_all['policy_top5'][-1]:.4f}\\n\")\n",
        "\n",
        "print(f\"\\n‚úÖ Fichiers et graphiques enregistr√©s dans : {output_dir}\")\n",
        "\n",
        "# ================================================================\n",
        "# üì¶ ZIP + T√âL√âCHARGEMENT AUTOMATIQUE\n",
        "# ================================================================\n",
        "zip_path = f\"{output_dir}.zip\"\n",
        "shutil.make_archive(output_dir, 'zip', output_dir)\n",
        "print(f\"üì¶ Dossier compress√© : {zip_path}\")\n",
        "\n",
        "try:\n",
        "    files.download(zip_path)\n",
        "    print(f\"üì• T√©l√©chargement du dossier complet lanc√© avec succ√®s ‚úÖ\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è T√©l√©chargement automatique ignor√© ({e})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparaison"
      ],
      "metadata": {
        "id": "KLnyoF9_T-Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import golois\n",
        "\n",
        "# Charger ton mod√®le best\n",
        "best_model_path = \"20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\"\n",
        "model = keras.models.load_model(best_model_path)\n",
        "print(f\"‚úÖ Mod√®le charg√© : {best_model_path}\")\n",
        "\n",
        "# --- Pr√©parer des donn√©es de test / validation\n",
        "# (ou bien tu utilises le buffer d√©j√† charg√© dans ton notebook)\n",
        "N = 10000\n",
        "planes, moves = 31, 361\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value  = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end    = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "\n",
        "# Optionnel : test avec golois\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "\n",
        "# --- √âvaluer\n",
        "results = model.evaluate(input_data, [policy, value], batch_size=128, verbose=1)\n",
        "\n",
        "# Afficher les m√©triques\n",
        "print(\"\\nüìä R√©sultats du mod√®le best:\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name:35s}: {val:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2OLUhGFGjO-",
        "outputId": "5ffad20b-ca23-4dd8-92a8-5092c64eb630"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 90 variables whereas the saved optimizer has 94 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© : 20251110_AdamH_GoSepResNet_100k_ep60_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - loss: 3.5581 - policy_categorical_accuracy: 0.3527 - policy_loss: 3.3754 - value_loss: 0.1088 - value_mae: 0.2730\n",
            "\n",
            "üìä R√©sultats du mod√®le best:\n",
            "loss                               : 3.587417\n",
            "compile_metrics                    : 3.398542\n",
            "policy_loss                        : 0.109071\n",
            "value_loss                         : 0.343200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XGoQq4U2HR-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import golois\n",
        "\n",
        "# Charger ton mod√®le best\n",
        "best_model_path = \"20251110_AdamH_Model4B_AttentionHybrid_v5_ep200_bs128_lr0.0001_best.keras\"\n",
        "model = keras.models.load_model(best_model_path)\n",
        "print(f\"‚úÖ Mod√®le charg√© : {best_model_path}\")\n",
        "\n",
        "# --- Pr√©parer des donn√©es de test / validation\n",
        "# (ou bien tu utilises le buffer d√©j√† charg√© dans ton notebook)\n",
        "N = 10000\n",
        "planes, moves = 31, 361\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value  = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end    = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "\n",
        "# Optionnel : test avec golois\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "\n",
        "# --- √âvaluer\n",
        "results = model.evaluate(input_data, [policy, value], batch_size=128, verbose=1)\n",
        "\n",
        "# Afficher les m√©triques\n",
        "print(\"\\nüìä R√©sultats du mod√®le best:\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name:35s}: {val:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN9OymtgHWoN",
        "outputId": "0414a617-18a1-466c-d937-6141bac9a8fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© : 20251110_AdamH_Model4B_AttentionHybrid_v5_ep200_bs128_lr0.0001_best.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - loss: 3.1833 - policy_categorical_accuracy: 0.4087 - policy_loss: 3.0183 - value_loss: 0.1011 - value_mae: 0.2586\n",
            "\n",
            "üìä R√©sultats du mod√®le best:\n",
            "loss                               : 3.212022\n",
            "compile_metrics                    : 3.042224\n",
            "policy_loss                        : 0.100921\n",
            "value_loss                         : 0.404900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FDVQQ67nHvVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import golois\n",
        "\n",
        "# Charger ton mod√®le best\n",
        "best_model_path = \"20251110_AdamH_Model4B_AttentionHybrid_v5_ep200_bs128_lr0.0001.keras\"\n",
        "model = keras.models.load_model(best_model_path)\n",
        "print(f\"‚úÖ Mod√®le charg√© : {best_model_path}\")\n",
        "\n",
        "# --- Pr√©parer des donn√©es de test / validation\n",
        "# (ou bien tu utilises le buffer d√©j√† charg√© dans ton notebook)\n",
        "N = 10000\n",
        "planes, moves = 31, 361\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value  = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end    = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "\n",
        "# Optionnel : test avec golois\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "\n",
        "# --- √âvaluer\n",
        "results = model.evaluate(input_data, [policy, value], batch_size=128, verbose=1)\n",
        "\n",
        "# Afficher les m√©triques\n",
        "print(\"\\nüìä R√©sultats du mod√®le best:\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name:35s}: {val:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjm3LB9EHypt",
        "outputId": "f4682596-a1a2-4404-d640-22492e2d8b51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 46 variables whereas the saved optimizer has 94 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© : 20251110_AdamH_Model4B_AttentionHybrid_v5_ep200_bs128_lr0.0001.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - loss: 3.1833 - policy_categorical_accuracy: 0.4087 - policy_loss: 3.0183 - value_loss: 0.1011 - value_mae: 0.2586\n",
            "\n",
            "üìä R√©sultats du mod√®le best:\n",
            "loss                               : 3.212022\n",
            "compile_metrics                    : 3.042224\n",
            "policy_loss                        : 0.100921\n",
            "value_loss                         : 0.404900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ok1K-p3IH-du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import golois\n",
        "\n",
        "# Charger ton mod√®le best\n",
        "best_model_path = \"20251110_AdamH_Model4B_AttentionHybrid_v5_ep200_bs128_lr0.0001_final.keras\"\n",
        "model = keras.models.load_model(best_model_path)\n",
        "print(f\"‚úÖ Mod√®le charg√© : {best_model_path}\")\n",
        "\n",
        "# --- Pr√©parer des donn√©es de test / validation\n",
        "# (ou bien tu utilises le buffer d√©j√† charg√© dans ton notebook)\n",
        "N = 10000\n",
        "planes, moves = 31, 361\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value  = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end    = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "\n",
        "# Optionnel : test avec golois\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "\n",
        "# --- √âvaluer\n",
        "results = model.evaluate(input_data, [policy, value], batch_size=128, verbose=1)\n",
        "\n",
        "# Afficher les m√©triques\n",
        "print(\"\\nüìä R√©sultats du mod√®le best:\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name:35s}: {val:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9sTjQ70IAMo",
        "outputId": "400bdcb0-97bd-4fb7-f2ad-855f84ea7948"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© : 20251110_AdamH_Model4B_AttentionHybrid_v5_ep200_bs128_lr0.0001_final.keras\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - loss: 3.1833 - policy_categorical_accuracy: 0.4087 - policy_loss: 3.0183 - value_loss: 0.1011 - value_mae: 0.2586\n",
            "\n",
            "üìä R√©sultats du mod√®le best:\n",
            "loss                               : 3.212022\n",
            "compile_metrics                    : 3.042224\n",
            "policy_loss                        : 0.100921\n",
            "value_loss                         : 0.404900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-YZMdRqsIO0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Adam_Hannachi_Anael_Ernadote500.h5"
      ],
      "metadata": {
        "id": "JrHix1ydIMRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import golois\n",
        "\n",
        "# Charger ton mod√®le best\n",
        "best_model_path = \"Adam_Hannachi_Anael_Ernadote500.h5\"\n",
        "model = keras.models.load_model(best_model_path)\n",
        "print(f\"‚úÖ Mod√®le charg√© : {best_model_path}\")\n",
        "\n",
        "# --- Pr√©parer des donn√©es de test / validation\n",
        "# (ou bien tu utilises le buffer d√©j√† charg√© dans ton notebook)\n",
        "N = 10000\n",
        "planes, moves = 31, 361\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value  = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end    = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "\n",
        "# Optionnel : test avec golois\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "\n",
        "# --- √âvaluer\n",
        "results = model.evaluate(input_data, [policy, value], batch_size=128, verbose=1)\n",
        "\n",
        "# Afficher les m√©triques\n",
        "print(\"\\nüìä R√©sultats du mod√®le best:\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name:35s}: {val:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtIXITFoIODl",
        "outputId": "0167f82a-6bbb-4354-e99d-90b5dbdaf456"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© : Adam_Hannachi_Anael_Ernadote500.h5\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - loss: 2.4148 - policy_categorical_accuracy: 0.5109 - policy_loss: 2.3049 - policy_top5: 0.7969 - value_loss: 0.0517 - value_mean_absolute_error: 0.2577\n",
            "\n",
            "üìä R√©sultats du mod√®le best:\n",
            "loss                               : 2.442247\n",
            "compile_metrics                    : 2.329152\n",
            "policy_loss                        : 0.052152\n",
            "value_loss                         : 0.500400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import golois\n",
        "\n",
        "# ================================================================\n",
        "# üîπ Chargement du mod√®le best (.h5 ou .keras)\n",
        "# ================================================================\n",
        "best_model_path = \"Adam_Hannachi_Anael_Ernadote500.h5\"\n",
        "model = keras.models.load_model(best_model_path, compile=False)\n",
        "print(f\"‚úÖ Mod√®le charg√© : {best_model_path}\")\n",
        "\n",
        "# ================================================================\n",
        "# ‚öôÔ∏è Recompilation (sinon metrics_names est vide)\n",
        "# ================================================================\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss={'policy': 'categorical_crossentropy', 'value': 'mse'},\n",
        "    metrics={\n",
        "        'policy': [\n",
        "            'categorical_accuracy',\n",
        "            keras.metrics.TopKCategoricalAccuracy(k=5, name='top5')\n",
        "        ],\n",
        "        'value': ['mae']\n",
        "    }\n",
        ")\n",
        "print(\"üîÅ Mod√®le recompil√© avec les bonnes m√©triques.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# üìä Donn√©es de validation factices (ou r√©elles via golois)\n",
        "# ================================================================\n",
        "N = 10_000\n",
        "planes, moves = 31, 361\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "\n",
        "# Optionnel : appel √† golois pour formater les donn√©es\n",
        "print(\"üîç Appel √† golois.getValidation()...\")\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "print(\"‚úÖ Validation pr√™te.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# üß™ √âvaluation du mod√®le\n",
        "# ================================================================\n",
        "results = model.evaluate(input_data, [policy, value], batch_size=128, verbose=1)\n",
        "\n",
        "print(\"\\nüìä R√©sultats du mod√®le best (recompil√©):\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name:35s}: {val:.6f}\")\n",
        "\n",
        "# ================================================================\n",
        "# üíæ Sauvegarde des r√©sultats dans un fichier\n",
        "# ================================================================\n",
        "with open(\"evaluation_best.txt\", \"w\") as f:\n",
        "    f.write(f\"üìä R√©sultats du mod√®le : {best_model_path}\\n\\n\")\n",
        "    for name, val in zip(model.metrics_names, results):\n",
        "        f.write(f\"{name:35s}: {val:.6f}\\n\")\n",
        "\n",
        "print(\"\\nüíæ R√©sultats sauvegard√©s dans evaluation_best.txt ‚úÖ\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2lC0Co0JTjt",
        "outputId": "df4c7e6f-54ca-4525-de5c-84dc810a765c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© : Adam_Hannachi_Anael_Ernadote500.h5\n",
            "üîÅ Mod√®le recompil√© avec les bonnes m√©triques.\n",
            "\n",
            "üîç Appel √† golois.getValidation()...\n",
            "‚úÖ Validation pr√™te.\n",
            "\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 2.1451 - policy_categorical_accuracy: 0.5109 - policy_loss: 1.9835 - policy_top5: 0.7969 - value_loss: 0.1034 - value_mae: 0.2577\n",
            "\n",
            "üìä R√©sultats du mod√®le best (recompil√©):\n",
            "loss                               : 2.174545\n",
            "compile_metrics                    : 2.009520\n",
            "policy_loss                        : 0.104303\n",
            "value_loss                         : 0.500400\n",
            "\n",
            "üíæ R√©sultats sauvegard√©s dans evaluation_best.txt ‚úÖ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import golois\n",
        "\n",
        "# ================================================================\n",
        "# üîπ Chargement du mod√®le best (.h5 ou .keras)\n",
        "# ================================================================\n",
        "best_model_path = \"Adam_Hannachi_Anael_Ernadote120.h5\"\n",
        "model = keras.models.load_model(best_model_path, compile=False)\n",
        "print(f\"‚úÖ Mod√®le charg√© : {best_model_path}\")\n",
        "\n",
        "# ================================================================\n",
        "# ‚öôÔ∏è Recompilation (sinon metrics_names est vide)\n",
        "# ================================================================\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss={'policy': 'categorical_crossentropy', 'value': 'mse'},\n",
        "    metrics={\n",
        "        'policy': [\n",
        "            'categorical_accuracy',\n",
        "            keras.metrics.TopKCategoricalAccuracy(k=5, name='top5')\n",
        "        ],\n",
        "        'value': ['mae']\n",
        "    }\n",
        ")\n",
        "print(\"üîÅ Mod√®le recompil√© avec les bonnes m√©triques.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# üìä Donn√©es de validation factices (ou r√©elles via golois)\n",
        "# ================================================================\n",
        "N = 10_000\n",
        "planes, moves = 31, 361\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "\n",
        "# Optionnel : appel √† golois pour formater les donn√©es\n",
        "print(\"üîç Appel √† golois.getValidation()...\")\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "print(\"‚úÖ Validation pr√™te.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# üß™ √âvaluation du mod√®le\n",
        "# ================================================================\n",
        "results = model.evaluate(input_data, [policy, value], batch_size=128, verbose=1)\n",
        "\n",
        "print(\"\\nüìä R√©sultats du mod√®le best (recompil√©):\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name:35s}: {val:.6f}\")\n",
        "\n",
        "# ================================================================\n",
        "# üíæ Sauvegarde des r√©sultats dans un fichier\n",
        "# ================================================================\n",
        "with open(\"evaluation_best.txt\", \"w\") as f:\n",
        "    f.write(f\"üìä R√©sultats du mod√®le : {best_model_path}\\n\\n\")\n",
        "    for name, val in zip(model.metrics_names, results):\n",
        "        f.write(f\"{name:35s}: {val:.6f}\\n\")\n",
        "\n",
        "print(\"\\nüíæ R√©sultats sauvegard√©s dans evaluation_best.txt ‚úÖ\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBbHyj8UJeH-",
        "outputId": "03d9c697-f60e-43d6-bd6a-83a9bf32f5fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© : Adam_Hannachi_Anael_Ernadote120.h5\n",
            "üîÅ Mod√®le recompil√© avec les bonnes m√©triques.\n",
            "\n",
            "üîç Appel √† golois.getValidation()...\n",
            "‚úÖ Validation pr√™te.\n",
            "\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - loss: 2.7361 - policy_categorical_accuracy: 0.3946 - policy_loss: 2.5545 - policy_top5: 0.6746 - value_loss: 0.1144 - value_mae: 0.2736\n",
            "\n",
            "üìä R√©sultats du mod√®le best (recompil√©):\n",
            "loss                               : 2.768620\n",
            "compile_metrics                    : 2.582088\n",
            "policy_loss                        : 0.115914\n",
            "value_loss                         : 0.384400\n",
            "\n",
            "üíæ R√©sultats sauvegard√©s dans evaluation_best.txt ‚úÖ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import golois\n",
        "\n",
        "# ================================================================\n",
        "# üîπ Chargement du mod√®le best (.h5 ou .keras)\n",
        "# ================================================================\n",
        "best_model_path = \"Adam_Hannachi_Anael_Ernadote.h5\"\n",
        "model = keras.models.load_model(best_model_path, compile=False)\n",
        "print(f\"‚úÖ Mod√®le charg√© : {best_model_path}\")\n",
        "\n",
        "# ================================================================\n",
        "# ‚öôÔ∏è Recompilation (sinon metrics_names est vide)\n",
        "# ================================================================\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss={'policy': 'categorical_crossentropy', 'value': 'mse'},\n",
        "    metrics={\n",
        "        'policy': [\n",
        "            'categorical_accuracy',\n",
        "            keras.metrics.TopKCategoricalAccuracy(k=5, name='top5')\n",
        "        ],\n",
        "        'value': ['mae']\n",
        "    }\n",
        ")\n",
        "print(\"üîÅ Mod√®le recompil√© avec les bonnes m√©triques.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# üìä Donn√©es de validation factices (ou r√©elles via golois)\n",
        "# ================================================================\n",
        "N = 10_000\n",
        "planes, moves = 31, 361\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "\n",
        "# Optionnel : appel √† golois pour formater les donn√©es\n",
        "print(\"üîç Appel √† golois.getValidation()...\")\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "print(\"‚úÖ Validation pr√™te.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# üß™ √âvaluation du mod√®le\n",
        "# ================================================================\n",
        "results = model.evaluate(input_data, [policy, value], batch_size=128, verbose=1)\n",
        "\n",
        "print(\"\\nüìä R√©sultats du mod√®le best (recompil√©):\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name:35s}: {val:.6f}\")\n",
        "\n",
        "# ================================================================\n",
        "# üíæ Sauvegarde des r√©sultats dans un fichier\n",
        "# ================================================================\n",
        "with open(\"evaluation_best.txt\", \"w\") as f:\n",
        "    f.write(f\"üìä R√©sultats du mod√®le : {best_model_path}\\n\\n\")\n",
        "    for name, val in zip(model.metrics_names, results):\n",
        "        f.write(f\"{name:35s}: {val:.6f}\\n\")\n",
        "\n",
        "print(\"\\nüíæ R√©sultats sauvegard√©s dans evaluation_best.txt ‚úÖ\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smb4BXXQJxeA",
        "outputId": "9f9ea4b9-8726-4c26-dc9a-df9dec6b590e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© : Adam_Hannachi_Anael_Ernadote.h5\n",
            "üîÅ Mod√®le recompil√© avec les bonnes m√©triques.\n",
            "\n",
            "üîç Appel √† golois.getValidation()...\n",
            "‚úÖ Validation pr√™te.\n",
            "\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 2.1451 - policy_categorical_accuracy: 0.5109 - policy_loss: 1.9835 - policy_top5: 0.7969 - value_loss: 0.1034 - value_mae: 0.2577\n",
            "\n",
            "üìä R√©sultats du mod√®le best (recompil√©):\n",
            "loss                               : 2.174545\n",
            "compile_metrics                    : 2.009520\n",
            "policy_loss                        : 0.104303\n",
            "value_loss                         : 0.500400\n",
            "\n",
            "üíæ R√©sultats sauvegard√©s dans evaluation_best.txt ‚úÖ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "waEBGOnlTOAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import golois\n",
        "\n",
        "# ================================================================\n",
        "# üîπ Chargement du mod√®le best (.h5 ou .keras)\n",
        "# ================================================================\n",
        "best_model_path = \"/content/output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\"\n",
        "model = keras.models.load_model(best_model_path, compile=False)\n",
        "print(f\"‚úÖ Mod√®le charg√© : {best_model_path}\")\n",
        "\n",
        "# ================================================================\n",
        "# ‚öôÔ∏è Recompilation (sinon metrics_names est vide)\n",
        "# ================================================================\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss={'policy': 'categorical_crossentropy', 'value': 'mse'},\n",
        "    metrics={\n",
        "        'policy': [\n",
        "            'categorical_accuracy',\n",
        "            keras.metrics.TopKCategoricalAccuracy(k=5, name='top5')\n",
        "        ],\n",
        "        'value': ['mae']\n",
        "    }\n",
        ")\n",
        "print(\"üîÅ Mod√®le recompil√© avec les bonnes m√©triques.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# üìä Donn√©es de validation factices (ou r√©elles via golois)\n",
        "# ================================================================\n",
        "N = 10_000\n",
        "planes, moves = 31, 361\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes)).astype('float32')\n",
        "policy = keras.utils.to_categorical(np.random.randint(moves, size=N), num_classes=moves).astype('float32')\n",
        "value = np.random.randint(2, size=(N,)).astype('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2)).astype('float32')\n",
        "\n",
        "# Optionnel : appel √† golois pour formater les donn√©es\n",
        "print(\"üîç Appel √† golois.getValidation()...\")\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "print(\"‚úÖ Validation pr√™te.\\n\")\n",
        "\n",
        "# ================================================================\n",
        "# üß™ √âvaluation du mod√®le\n",
        "# ================================================================\n",
        "results = model.evaluate(input_data, [policy, value], batch_size=128, verbose=1)\n",
        "\n",
        "print(\"\\nüìä R√©sultats du mod√®le best (recompil√©):\")\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name:35s}: {val:.6f}\")\n",
        "\n",
        "# ================================================================\n",
        "# üíæ Sauvegarde des r√©sultats dans un fichier\n",
        "# ================================================================\n",
        "with open(\"evaluation_best.txt\", \"w\") as f:\n",
        "    f.write(f\"üìä R√©sultats du mod√®le : {best_model_path}\\n\\n\")\n",
        "    for name, val in zip(model.metrics_names, results):\n",
        "        f.write(f\"{name:35s}: {val:.6f}\\n\")\n",
        "\n",
        "print(\"\\nüíæ R√©sultats sauvegard√©s dans evaluation_best.txt ‚úÖ\")\n"
      ],
      "metadata": {
        "id": "_nUTLl5mTQuE",
        "outputId": "9cc879c4-769d-430e-9231-9def450e2c60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© : /content/output/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001/20251111_AdamH_ModelDeepResearch_ep200_bs128_lr0.0002_l20.0001_best.keras\n",
            "üîÅ Mod√®le recompil√© avec les bonnes m√©triques.\n",
            "\n",
            "üîç Appel √† golois.getValidation()...\n",
            "‚úÖ Validation pr√™te.\n",
            "\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - loss: 2.8224 - policy_categorical_accuracy: 0.3737 - policy_loss: 2.6529 - policy_top5: 0.6574 - value_loss: 0.1028 - value_mae: 0.2618\n",
            "\n",
            "üìä R√©sultats du mod√®le best (recompil√©):\n",
            "loss                               : 2.849212\n",
            "compile_metrics                    : 2.674228\n",
            "policy_loss                        : 0.102619\n",
            "value_loss                         : 0.363000\n",
            "\n",
            "üíæ R√©sultats sauvegard√©s dans evaluation_best.txt ‚úÖ\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}